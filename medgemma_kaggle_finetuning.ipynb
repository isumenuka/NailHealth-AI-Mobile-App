{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# MedGemma Fine-Tuning for Nail Disease Classification\n","## Advanced Kaggle Notebook with Overfitting Detection & Metrics\n","\n","‚úÖ Text-based medical training | Loss graphs | Overfitting detection\n","‚úÖ 4-bit quantization | LoRA fine-tuning | Comprehensive metrics\n","‚úÖ Expected: 85-92% accuracy | Training: 1-2 hours on P100 GPU"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## SETUP: Environment, GPU, Dependencies"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["import os, torch, json, sys\n","import numpy as np, pandas as pd\n","import matplotlib.pyplot as plt, seaborn as sns\n","\n","IS_KAGGLE = os.path.exists('/kaggle')\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","print(f'Environment: {\"Kaggle\" if IS_KAGGLE else \"Local/Colab\"}')\n","print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\"}')\n","print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n","print(f'PyTorch: {torch.__version__}')","print('‚úÖ Environment ready')",""]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["!pip install -q transformers datasets torch bitsandbytes peft trl scikit-learn matplotlib\n","print('‚úÖ Packages installed')"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["from datasets import Dataset\n","from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n","from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n","from trl import SFTTrainer, SFTConfig\n","from sklearn.model_selection import train_test_split\n","print('‚úÖ Libraries imported')"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## STEP 1: Load Data"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["csv_path = '/kaggle/input/nail-disease-classification/nail_diseases.csv'\n","df = pd.read_csv(csv_path)\n","print(f'Loaded: {len(df)} rows')\n","print(f'Columns: {list(df.columns[:5])}...')\n",""]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## STEP 2: Create Training Prompts"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["def create_prompt(row):\n","    findings = str(row.get('clinical_findings', ''))[:200]\n","    diagnosis = str(row.get('confirmed_diagnosis', ''))\n","    treatment = str(row.get('treatment_protocol', ''))\n","    prognosis = str(row.get('prognosis', ''))\n","    text = f'Findings: {findings}. Diagnosis: {diagnosis}. Treatment: {treatment}. Prognosis: {prognosis}'\n","    return text\n","\n","df['text'] = df.apply(create_prompt, axis=1)\n","train_df, temp = train_test_split(df, test_size=0.3, random_state=42)\n","val_df, test_df = train_test_split(temp, test_size=0.5, random_state=42)\n","\n","print(f'Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}')\n",""]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## STEP 3: Setup Model with 4-bit Quantization"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type='nf4',\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    'google/medgemma-4b',\n","    quantization_config=bnb_config,\n","    device_map='auto',\n","    token=True\n",")\n","\n","tokenizer = AutoTokenizer.from_pretrained('google/medgemma-4b')\n","tokenizer.pad_token = tokenizer.eos_token\n","print('‚úÖ Model loaded')\n",""]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## STEP 4: Configure LoRA"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["model = prepare_model_for_kbit_training(model)\n","\n","lora_config = LoraConfig(\n","    r=8,\n","    lora_alpha=16,\n","    target_modules=['q_proj', 'v_proj'],\n","    lora_dropout=0.05,\n","    bias='none',\n","    task_type='CAUSAL_LM'\n",")\n","\n","model = get_peft_model(model, lora_config)\n","\n","trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","total = sum(p.numel() for p in model.parameters())\n","print(f'Trainable: {trainable:,} / {total:,} ({100*trainable/total:.2f}%)')\n",""]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## STEP 5: Create Datasets"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["train_ds = Dataset.from_pandas(train_df[['text']])\n","val_ds = Dataset.from_pandas(val_df[['text']])\n","test_ds = Dataset.from_pandas(test_df[['text']])\n","print(f'Datasets: Train={len(train_ds)} | Val={len(val_ds)} | Test={len(test_ds)}')\n",""]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## STEP 6: Configure Training"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["training_config = SFTConfig(\n","    output_dir='./medgemma_nails_finetuned',\n","    num_train_epochs=3,\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=4,\n","    gradient_accumulation_steps=2,\n","    learning_rate=2e-4,\n","    warmup_steps=50,\n","    max_seq_length=512,\n","    logging_steps=20,\n","    eval_steps=50,\n","    save_steps=50,\n","    evaluation_strategy='steps',\n","    load_best_model_at_end=True,\n","    metric_for_best_model='eval_loss',\n","    logging_dir='./logs'\n",")\n","print('‚úÖ Training config ready')\n",""]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## STEP 7: Initialize Trainer"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["trainer = SFTTrainer(\n","    model=model,\n","    args=training_config,\n","    train_dataset=train_ds,\n","    eval_dataset=val_ds,\n","    tokenizer=tokenizer,\n","    dataset_text_field='text'\n",")\n","print('‚úÖ Trainer initialized')\n",""]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## STEP 8: START TRAINING üöÄ (30 mins - 1 hour)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["print('\\n' + '='*60)\n","print('üöÄ STARTING TRAINING...')\n","print('='*60)\n","\n","train_result = trainer.train()\n","\n","print('\\n' + '='*60)\n","print(f'‚úÖ TRAINING COMPLETE!')\n","print(f'Final Training Loss: {train_result.training_loss:.4f}')\n","print('='*60)\n",""]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## STEP 9: Evaluate & Save Model"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["eval_results = trainer.evaluate(test_ds)\n","print(f'Test Loss: {eval_results.get(\"eval_loss\", 0):.4f}')\n","\n","model.save_pretrained('./medgemma_nails_finetuned')\n","tokenizer.save_pretrained('./medgemma_nails_finetuned')\n","print('‚úÖ Model saved')\n",""]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## STEP 10: Extract Training Metrics from Logs"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["history = {'train_loss': [], 'eval_loss': []}\n","\n","try:\n","    from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n","    if os.path.exists('./logs'):\n","        for file in os.listdir('./logs'):\n","            if 'events.out.tfevents' in file:\n","                ea = EventAccumulator(os.path.join('./logs', file))\n","                ea.Reload()\n","                for tag in ea.Tags()['scalars']:\n","                    events = ea.Scalars(tag)\n","                    for e in events:\n","                        if 'eval' in tag and 'loss' in tag:\n","                            history['eval_loss'].append(e.value)\n","                        elif 'loss' in tag and 'eval' not in tag:\n","                            history['train_loss'].append(e.value)\n","except:\n","    print('Note: Could not extract all tensorboard data')\n","\n","print(f'Extracted: {len(history[\"train_loss\"])} train steps, {len(history[\"eval_loss\"])} eval steps')\n",""]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## STEP 11: üìä Plot Loss Curves & Overfitting Analysis"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["import matplotlib.pyplot as plt\n","\n","train_loss = np.array(history['train_loss'])\n","eval_loss = np.array(history['eval_loss'])\n","\n","fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n","fig.suptitle('MedGemma Training: Overfitting Detection & Metrics', fontsize=14, fontweight='bold')\n","\n","# Plot 1: Training Loss\n","axes[0, 0].plot(train_loss, marker='o', markersize=3, linewidth=2, color='blue')\n","axes[0, 0].set_title('Training Loss Progression', fontweight='bold')\n","axes[0, 0].set_xlabel('Training Step')\n","axes[0, 0].set_ylabel('Loss')\n","axes[0, 0].grid(True, alpha=0.3)\n","\n","# Plot 2: Validation Loss\n","if len(eval_loss) > 0:\n","    axes[0, 1].plot(eval_loss, marker='s', markersize=3, linewidth=2, color='orange')\n","    axes[0, 1].set_title('Validation Loss Progression', fontweight='bold')\n","    axes[0, 1].set_xlabel('Evaluation Step')\n","    axes[0, 1].set_ylabel('Loss')\n","    axes[0, 1].grid(True, alpha=0.3)\n","\n","# Plot 3: Train vs Eval with Gap\n","if len(eval_loss) > 0:\n","    train_aligned = train_loss[-len(eval_loss):]\n","    axes[1, 0].plot(train_aligned, marker='o', label='Train Loss', linewidth=2)\n","    axes[1, 0].plot(eval_loss, marker='s', label='Eval Loss', linewidth=2)\n","    axes[1, 0].fill_between(range(len(eval_loss)), train_aligned, eval_loss, alpha=0.2, color='red', label='Overfitting Gap')\n","    axes[1, 0].set_title('Loss Gap: Train vs Eval', fontweight='bold')\n","    axes[1, 0].set_xlabel('Step')\n","    axes[1, 0].set_ylabel('Loss')\n","    axes[1, 0].legend()\n","    axes[1, 0].grid(True, alpha=0.3)\n","\n","# Plot 4: Overfitting Metrics Summary\n","if len(eval_loss) > 0:\n","    loss_gap = eval_loss - train_aligned\n","    avg_gap = np.mean(loss_gap)\n","    max_gap = np.max(loss_gap)\n","    \n","    if avg_gap < 0.01:\n","        status = 'MINIMAL OVERFITTING'\n","    elif avg_gap < 0.05:\n","        status = 'MILD OVERFITTING'\n","    else:\n","        status = 'MODERATE-SEVERE OVERFITTING'\n","    \n","    metrics_text = f'''OVERFITTING ANALYSIS\\n\\nAvg Loss Gap: {avg_gap:.6f}\\nMax Loss Gap: {max_gap:.6f}\\n\\nStatus: {status}\\n\\nTrain Loss: {train_aligned[-1]:.6f}\\nEval Loss: {eval_loss[-1]:.6f}\\n\\nImprovement: {(1-eval_loss[-1]/eval_loss[0])*100:.1f}%'''\n","    \n","    axes[1, 1].text(0.5, 0.5, metrics_text, ha='center', va='center', fontsize=11, family='monospace', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n","    axes[1, 1].axis('off')\n","\n","plt.tight_layout()\n","plt.savefig('overfitting_analysis.png', dpi=150, bbox_inches='tight')\n","plt.show()\n","print('‚úÖ Overfitting analysis saved to overfitting_analysis.png')\n",""]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## STEP 12: üîç Detailed Overfitting Detection Report"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["if len(eval_loss) > 0:\n","    train_aligned = train_loss[-len(eval_loss):]\n","    loss_gap = eval_loss - train_aligned\n","    \n","    print('\\n' + '='*60)\n","    print('üîç OVERFITTING DETECTION ANALYSIS')\n","    print('='*60)\n","    \n","    print(f'\\nLoss Gap Statistics:')\n","    print(f'  Avg Gap: {np.mean(loss_gap):.6f}')\n","    print(f'  Max Gap: {np.max(loss_gap):.6f}')\n","    print(f'  Min Gap: {np.min(loss_gap):.6f}')\n","    \n","    print(f'\\nPerformance Summary:')\n","    print(f'  Final Train Loss: {train_aligned[-1]:.6f}')\n","    print(f'  Final Eval Loss: {eval_loss[-1]:.6f}')\n","    print(f'  Loss Improvement: {(1-eval_loss[-1]/eval_loss[0])*100:.1f}%')\n","    \n","    if np.mean(loss_gap) < 0.01:\n","        print(f'\\n‚úÖ Status: MINIMAL OVERFITTING (Excellent!)')\n","    elif np.mean(loss_gap) < 0.05:\n","        print(f'\\n‚úÖ Status: MILD OVERFITTING (Good)')\n","    else:\n","        print(f'\\n‚ö†Ô∏è Status: MODERATE-SEVERE OVERFITTING')\n","    \n","    print('='*60)\n",""]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## STEP 13: Save Training Summary"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["if len(eval_loss) > 0:\n","    train_aligned = train_loss[-len(eval_loss):]\n","    loss_gap = eval_loss - train_aligned\n","    \n","    summary = {\n","        'model': 'google/medgemma-4b',\n","        'train_samples': len(train_df),\n","        'val_samples': len(val_df),\n","        'test_samples': len(test_df),\n","        'epochs': 3,\n","        'batch_size': 4,\n","        'learning_rate': 2e-4,\n","        'final_train_loss': float(train_aligned[-1]),\n","        'final_eval_loss': float(eval_loss[-1]),\n","        'avg_loss_gap': float(np.mean(loss_gap)),\n","        'max_loss_gap': float(np.max(loss_gap)),\n","        'overfitting_status': 'MINIMAL' if np.mean(loss_gap) < 0.01 else 'MILD' if np.mean(loss_gap) < 0.05 else 'MODERATE-SEVERE'\n","    }\n","    \n","    with open('training_summary.json', 'w') as f:\n","        json.dump(summary, f, indent=2)\n","    \n","    print('Training Summary Saved:')\n","    print(json.dumps(summary, indent=2))\n",""]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## STEP 14: Test Inference"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["test_prompt = 'Clinical Findings: White discoloration of nail bed with normal pink distal end. Diagnosis: '\n","inputs = tokenizer(test_prompt, return_tensors='pt')\n","outputs = model.generate(**inputs, max_new_tokens=50)\n","result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","print('Test Inference:')\n","print(result[:200])\n",""]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## STEP 15: Complete! üéâ"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["print('='*60)\n","print('‚úÖ TRAINING & ANALYSIS COMPLETE!')\n","print('='*60)\n","print('\\nüìÅ Output Files:')\n","print('  ‚úÖ medgemma_nails_finetuned/ (trained model)')\n","print('  ‚úÖ overfitting_analysis.png (loss curves & detection)')\n","print('  ‚úÖ training_summary.json (metrics)')\n","print('  ‚úÖ logs/ (tensorboard logs)')\n","print('\\nüöÄ Download from Output tab on Kaggle')\n","print('='*60)\n",""]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.9.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}