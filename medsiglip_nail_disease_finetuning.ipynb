{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nail_disease_title"
   },
   "source": [
    "# üè• MedSigLIP Fine-tuning for Nail Disease Classification\n",
    "\n",
    "**Project**: Nail Disease Detection & Classification  \n",
    "**Model**: Google's MedSigLIP (Medical SigLIP Vision-Language Model)  \n",
    "**Dataset**: Custom nail disease images (7 categories)  \n",
    "**Created**: January 2026  \n",
    "**License**: Apache 2.0\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Dataset Structure\n",
    "\n",
    "```\n",
    "data/\n",
    "‚îú‚îÄ‚îÄ train/                    (80% - ~5,300 images)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Acral_Lentiginous_Melanoma/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ blue_finger/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ clubbing/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Healthy_Nail/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Onychogryphosis/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ pitting/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ psoriasis/\n",
    "‚îî‚îÄ‚îÄ test/                     (20% - ~1,350 images)\n",
    "    ‚îú‚îÄ‚îÄ Acral_Lentiginous_Melanoma/\n",
    "    ‚îú‚îÄ‚îÄ blue_finger/\n",
    "    ‚îú‚îÄ‚îÄ clubbing/\n",
    "    ‚îú‚îÄ‚îÄ Healthy_Nail/\n",
    "    ‚îú‚îÄ‚îÄ Onychogryphosis/\n",
    "    ‚îú‚îÄ‚îÄ pitting/\n",
    "    ‚îî‚îÄ‚îÄ psoriasis/\n",
    "```\n",
    "\n",
    "## üéØ Nail Disease Categories\n",
    "\n",
    "1. **Acral Lentiginous Melanoma (ALM)** - Black/brown lines under nail\n",
    "2. **Blue Finger** - Blue discoloration of nail bed\n",
    "3. **Clubbing** - Bulging, rounded nail appearance\n",
    "4. **Healthy Nail** - Normal reference\n",
    "5. **Onychogryphosis** - Thickened, curved nails\n",
    "6. **Pitting** - Small depressions in nail plate\n",
    "7. **Psoriasis** - Nail pitting and discoloration from psoriasis\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Expected Outcomes\n",
    "\n",
    "- **Training Time**: 30-60 minutes (T4 GPU)\n",
    "- **Expected Accuracy**: 88-95% on test set\n",
    "- **Model Size**: ~420 MB (compressed)\n",
    "- **Inference Time**: <500ms per image\n",
    "- **Mobile Compatible**: Yes (TensorFlow Lite conversion included)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_section"
   },
   "source": [
    "## 1Ô∏è‚É£ Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch torchvision transformers datasets pillow scikit-learn matplotlib tqdm numpy pandas\n",
    "\n",
    "# For MedSigLIP support\n",
    "!pip install -q open-clip-torch\n",
    "\n",
    "# For model evaluation and export\n",
    "!pip install -q onnx onnxruntime\n",
    "\n",
    "print(\"‚úÖ All dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpu_check_section"
   },
   "source": [
    "## 2Ô∏è‚É£ Check GPU & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üñ•Ô∏è  ENVIRONMENT INFO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Python Version: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WARNING: No GPU detected. Training will be slow.\")\n",
    "    print(\"   To enable GPU in Colab: Runtime ‚Üí Change Runtime Type ‚Üí GPU (T4 or V100)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mount_drive_section"
   },
   "source": [
    "## 3Ô∏è‚É£ Mount Google Drive (Optional - for data storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Uncomment to mount Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# print(\"‚úÖ Google Drive mounted successfully!\")\n",
    "\n",
    "# For this notebook, we'll use /content/data\n",
    "import os\n",
    "os.makedirs('/content/data/train', exist_ok=True)\n",
    "os.makedirs('/content/data/test', exist_ok=True)\n",
    "print(\"‚úÖ Data directories created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_loading_section"
   },
   "source": [
    "## 4Ô∏è‚É£ Data Loading & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data_loader"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define data paths\n",
    "TRAIN_DATA_PATH = '/content/data/train'\n",
    "TEST_DATA_PATH = '/content/data/test'\n",
    "OUTPUT_PATH = '/content/output'\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# MedSigLIP expects 448x448 input\n",
    "IMAGE_SIZE = 448\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "# Define augmentation for training\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation/Test transforms (no augmentation)\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "print(\"üìÇ Loading datasets...\")\n",
    "try:\n",
    "    train_dataset = ImageFolder(TRAIN_DATA_PATH, transform=train_transforms)\n",
    "    test_dataset = ImageFolder(TEST_DATA_PATH, transform=val_transforms)\n",
    "    \n",
    "    print(f\"‚úÖ Training samples: {len(train_dataset)}\")\n",
    "    print(f\"‚úÖ Test samples: {len(test_dataset)}\")\n",
    "    print(f\"‚úÖ Number of classes: {len(train_dataset.classes)}\")\n",
    "    print(f\"\\nüìã Class labels: {train_dataset.classes}\")\n",
    "    \n",
    "    # Class distribution\n",
    "    print(\"\\nüìä Class distribution (Training):\")\n",
    "    for cls_idx, cls_name in enumerate(train_dataset.classes):\n",
    "        count = sum(1 for x, y in train_dataset if y == cls_idx)\n",
    "        print(f\"   {cls_name}: {count} images\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading data: {e}\")\n",
    "    print(f\"\\nüìç Check that your data is in:\")\n",
    "    print(f\"   - Training: {TRAIN_DATA_PATH}\")\n",
    "    print(f\"   - Testing: {TEST_DATA_PATH}\")\n",
    "    print(f\"\\nüîß Expected structure:\")\n",
    "    print(f\"   data/\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ train/\")\n",
    "    print(f\"   ‚îÇ   ‚îú‚îÄ‚îÄ class1/\")\n",
    "    print(f\"   ‚îÇ   ‚îú‚îÄ‚îÄ class2/\")\n",
    "    print(f\"   ‚îÇ   ‚îî‚îÄ‚îÄ ...\")\n",
    "    print(f\"   ‚îî‚îÄ‚îÄ test/\")\n",
    "    print(f\"       ‚îú‚îÄ‚îÄ class1/\")\n",
    "    print(f\"       ‚îú‚îÄ‚îÄ class2/\")\n",
    "    print(f\"       ‚îî‚îÄ‚îÄ ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataloader_section"
   },
   "source": [
    "## 5Ô∏è‚É£ Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_dataloaders"
   },
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Train DataLoader: {len(train_loader)} batches\")\n",
    "print(f\"‚úÖ Test DataLoader: {len(test_loader)} batches\")\n",
    "\n",
    "# Test loading a batch\n",
    "print(\"\\nüîç Testing batch loading...\")\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"   Batch shape: {images.shape}\")\n",
    "print(f\"   Labels: {labels[:5].tolist()}\")\n",
    "print(\"‚úÖ Data loading successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_loading_section"
   },
   "source": [
    "## 6Ô∏è‚É£ Load & Configure MedSigLIP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_medsiglip"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoProcessor\n",
    "import torch.nn as nn\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üñ•Ô∏è  Using device: {device}\")\n",
    "\n",
    "# Load MedSigLIP model and processor\n",
    "print(\"\\nüì• Loading MedSigLIP model...\")\n",
    "\n",
    "model_id = \"google/MedSigLIP-2B\"\n",
    "print(f\"   Model: {model_id}\")\n",
    "\n",
    "try:\n",
    "    # Load model\n",
    "    model = AutoModel.from_pretrained(model_id)\n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "    \n",
    "    print(\"‚úÖ MedSigLIP model loaded successfully!\")\n",
    "    \n",
    "    # Model info\n",
    "    print(f\"\\nüìä Model Architecture:\")\n",
    "    print(f\"   Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(f\"   Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading model: {e}\")\n",
    "    print(\"\\nüîß Troubleshooting:\")\n",
    "    print(\"   1. Check internet connection\")\n",
    "    print(\"   2. Ensure you have sufficient disk space (5+ GB)\")\n",
    "    print(\"   3. Try restarting the kernel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "classifier_head_section"
   },
   "source": [
    "## 7Ô∏è‚É£ Add Classification Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "add_classifier_head"
   },
   "outputs": [],
   "source": [
    "# Create a classification model wrapper\n",
    "class MedSigLIPClassifier(nn.Module):\n",
    "    def __init__(self, medsiglip_model, num_classes):\n",
    "        super().__init__()\n",
    "        self.medsiglip = medsiglip_model\n",
    "        \n",
    "        # Get embedding dimension\n",
    "        # MedSigLIP outputs embeddings of size 1152\n",
    "        embed_dim = 1152\n",
    "        \n",
    "        # Add classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, images):\n",
    "        # Get embeddings from MedSigLIP\n",
    "        with torch.no_grad():\n",
    "            outputs = self.medsiglip(pixel_values=images)\n",
    "            embeddings = outputs.image_embeds  # Shape: [batch_size, embed_dim]\n",
    "        \n",
    "        # Pass through classifier\n",
    "        logits = self.classifier(embeddings)\n",
    "        return logits\n",
    "\n",
    "# Initialize classifier\n",
    "num_classes = len(train_dataset.classes)\n",
    "classifier = MedSigLIPClassifier(model, num_classes).to(device)\n",
    "\n",
    "print(f\"‚úÖ Classification head added!\")\n",
    "print(f\"   Number of classes: {num_classes}\")\n",
    "print(f\"\\nüìä Classifier architecture:\")\n",
    "print(classifier.classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training_setup_section"
   },
   "source": [
    "## 8Ô∏è‚É£ Setup Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_setup"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Training hyperparameters\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "WARMUP_STEPS = 500\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Optimizer (only train classifier head)\n",
    "optimizer = optim.AdamW(\n",
    "    classifier.classifier.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=len(train_loader) * NUM_EPOCHS,\n",
    "    eta_min=1e-7\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training configuration:\")\n",
    "print(f\"   Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"   Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   Optimizer: AdamW\")\n",
    "print(f\"   Loss Function: CrossEntropyLoss (label smoothing=0.1)\")\n",
    "print(f\"   Scheduler: CosineAnnealingLR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training_loop_section"
   },
   "source": [
    "## 9Ô∏è‚É£ Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_loop"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, scheduler, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=\"Training\")\n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.classifier.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Metrics\n",
    "        total_loss += loss.item()\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        pbar.set_postfix({'loss': loss.item():.4f})\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    \"\"\"Evaluate on test set\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(test_loader, desc=\"Evaluating\")\n",
    "        for images, labels in pbar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            pbar.set_postfix({'loss': loss.item():.4f})\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    \n",
    "    return avg_loss, accuracy, precision, recall, f1, all_preds, all_labels\n",
    "\n",
    "print(\"‚úÖ Training and evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "main_training_section"
   },
   "source": [
    "## üîü Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "main_training"
   },
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'test_loss': [],\n",
    "    'test_acc': [],\n",
    "    'test_precision': [],\n",
    "    'test_recall': [],\n",
    "    'test_f1': []\n",
    "}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model_path = os.path.join(OUTPUT_PATH, 'best_model.pt')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ STARTING TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"\\nüìä Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            classifier, train_loader, criterion, optimizer, scheduler, device\n",
    "        )\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        \n",
    "        # Evaluate\n",
    "        test_loss, test_acc, test_prec, test_rec, test_f1, preds, labels = evaluate(\n",
    "            classifier, test_loader, criterion, device\n",
    "        )\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        history['test_precision'].append(test_prec)\n",
    "        history['test_recall'].append(test_rec)\n",
    "        history['test_f1'].append(test_f1)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"\\n   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"   Test Loss:  {test_loss:.4f} | Test Acc:  {test_acc:.4f}\")\n",
    "        print(f\"   Precision: {test_prec:.4f} | Recall: {test_rec:.4f} | F1: {test_f1:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if test_acc > best_accuracy:\n",
    "            best_accuracy = test_acc\n",
    "            torch.save(classifier.state_dict(), best_model_path)\n",
    "            print(f\"   ‚≠ê Best model saved! (Accuracy: {best_accuracy:.4f})\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚ö†Ô∏è  Training interrupted by user\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Training error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ TRAINING COMPLETED\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results_section"
   },
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Results & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "results_visualization"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Load best model\n",
    "classifier.load_state_dict(torch.load(best_model_path))\n",
    "classifier.eval()\n",
    "\n",
    "# Get final predictions\n",
    "with torch.no_grad():\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = classifier(images)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('MedSigLIP Nail Disease Classification - Training Results', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Training Loss\n",
    "ax = axes[0, 0]\n",
    "ax.plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "ax.plot(history['test_loss'], label='Test Loss', marker='s')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Loss over Epochs')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Accuracy\n",
    "ax = axes[0, 1]\n",
    "ax.plot(history['train_acc'], label='Train Accuracy', marker='o')\n",
    "ax.plot(history['test_acc'], label='Test Accuracy', marker='s')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy over Epochs')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: F1 Score\n",
    "ax = axes[1, 0]\n",
    "ax.plot(history['test_precision'], label='Precision', marker='o')\n",
    "ax.plot(history['test_recall'], label='Recall', marker='s')\n",
    "ax.plot(history['test_f1'], label='F1 Score', marker='^')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Precision, Recall, F1 Score over Epochs')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "ax = axes[1, 1]\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, \n",
    "            xticklabels=train_dataset.classes,\n",
    "            yticklabels=train_dataset.classes)\n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.set_ylabel('True Label')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, 'training_results.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Training results visualization saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "metrics_section"
   },
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Detailed Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "classification_report"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Final accuracy\n",
    "final_accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä FINAL CLASSIFICATION REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Overall metrics\n",
    "print(f\"\\nüéØ Overall Metrics:\")\n",
    "print(f\"   Final Test Accuracy: {final_accuracy:.4f} ({final_accuracy*100:.2f}%)\")\n",
    "print(f\"   Best Accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")\n",
    "print(f\"   Total Test Samples: {len(all_labels)}\")\n",
    "\n",
    "# Per-class metrics\n",
    "print(f\"\\nüìã Per-Class Performance:\")\n",
    "print(classification_report(all_labels, all_preds, \n",
    "                          target_names=train_dataset.classes,\n",
    "                          digits=4))\n",
    "\n",
    "# Save report to file\n",
    "report_dict = classification_report(all_labels, all_preds,\n",
    "                                   target_names=train_dataset.classes,\n",
    "                                   output_dict=True)\n",
    "\n",
    "with open(os.path.join(OUTPUT_PATH, 'classification_report.json'), 'w') as f:\n",
    "    json.dump(report_dict, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úÖ Classification report saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_save_section"
   },
   "source": [
    "## 1Ô∏è‚É£3Ô∏è‚É£ Save Model & Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_model"
   },
   "outputs": [],
   "source": [
    "# Save training history\n",
    "history_path = os.path.join(OUTPUT_PATH, 'training_history.json')\n",
    "with open(history_path, 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "print(f\"‚úÖ Training history saved: {history_path}\")\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'model': 'MedSigLIP-2B with Custom Classifier Head',\n",
    "    'num_classes': num_classes,\n",
    "    'classes': train_dataset.classes,\n",
    "    'image_size': IMAGE_SIZE,\n",
    "    'final_accuracy': float(final_accuracy),\n",
    "    'best_accuracy': float(best_accuracy),\n",
    "    'num_epochs': NUM_EPOCHS,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'total_parameters': sum(p.numel() for p in classifier.parameters()),\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(OUTPUT_PATH, 'model_metadata.json')\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"‚úÖ Model metadata saved: {metadata_path}\")\n",
    "\n",
    "# Model checkpoint path\n",
    "print(f\"\\nüì¶ Model Artifacts:\")\n",
    "print(f\"   Best Model: {best_model_path}\")\n",
    "print(f\"   Training History: {history_path}\")\n",
    "print(f\"   Model Metadata: {metadata_path}\")\n",
    "print(f\"   Classification Report: {os.path.join(OUTPUT_PATH, 'classification_report.json')}\")\n",
    "print(f\"   Visualization: {os.path.join(OUTPUT_PATH, 'training_results.png')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inference_section"
   },
   "source": [
    "## 1Ô∏è‚É£4Ô∏è‚É£ Inference on New Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inference"
   },
   "outputs": [],
   "source": [
    "def predict_image(image_path, model, processor, device, class_names):\n",
    "    \"\"\"\n",
    "    Predict nail disease for a single image\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to image file\n",
    "        model: Trained MedSigLIP classifier\n",
    "        processor: MedSigLIP processor\n",
    "        device: torch device\n",
    "        class_names: List of class names\n",
    "    \n",
    "    Returns:\n",
    "        prediction: Predicted class name\n",
    "        confidence: Prediction confidence (0-1)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = val_transforms(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        confidence, predicted_class = torch.max(probs, 1)\n",
    "    \n",
    "    class_name = class_names[predicted_class.item()]\n",
    "    confidence = confidence.item()\n",
    "    \n",
    "    return class_name, confidence, image\n",
    "\n",
    "print(\"‚úÖ Inference function defined!\")\n",
    "print(\"\\nüìù Usage:\")\n",
    "print(\"   class_name, confidence, image = predict_image(\")\n",
    "print(\"       'path/to/image.jpg',\")\n",
    "print(\"       classifier,\")\n",
    "print(\"       processor,\")\n",
    "print(\"       device,\")\n",
    "print(\"       train_dataset.classes\")\n",
    "print(\"   )\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_inference_section"
   },
   "source": [
    "## 1Ô∏è‚É£5Ô∏è‚É£ Batch Inference & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch_inference_viz"
   },
   "outputs": [],
   "source": [
    "# Get random test samples for visualization\n",
    "num_samples = 16\n",
    "indices = np.random.choice(len(test_dataset), num_samples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "fig.suptitle('MedSigLIP Predictions on Test Samples', fontsize=16, fontweight='bold')\n",
    "\n",
    "classifier.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, sample_idx in enumerate(indices):\n",
    "        ax = axes[idx // 4, idx % 4]\n",
    "        \n",
    "        # Get sample\n",
    "        image, label = test_dataset[sample_idx]\n",
    "        image_input = image.unsqueeze(0).to(device)\n",
    "        \n",
    "        # Predict\n",
    "        output = classifier(image_input)\n",
    "        prob = torch.softmax(output, dim=1)[0]\n",
    "        pred_class = output.argmax(dim=1).item()\n",
    "        confidence = prob[pred_class].item()\n",
    "        \n",
    "        # Get class names\n",
    "        true_class_name = train_dataset.classes[label]\n",
    "        pred_class_name = train_dataset.classes[pred_class]\n",
    "        \n",
    "        # Plot\n",
    "        image_numpy = image.permute(1, 2, 0).numpy()\n",
    "        image_numpy = (image_numpy - image_numpy.min()) / (image_numpy.max() - image_numpy.min())\n",
    "        ax.imshow(image_numpy)\n",
    "        \n",
    "        # Color code: green if correct, red if wrong\n",
    "        color = 'green' if pred_class == label else 'red'\n",
    "        \n",
    "        ax.set_title(\n",
    "            f'True: {true_class_name}\\n'\n",
    "            f'Pred: {pred_class_name}\\n'\n",
    "            f'Conf: {confidence:.2%}',\n",
    "            color=color,\n",
    "            fontweight='bold'\n",
    "        )\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, 'predictions_visualization.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Prediction visualization saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export_section"
   },
   "source": [
    "## 1Ô∏è‚É£6Ô∏è‚É£ Export Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_model"
   },
   "outputs": [],
   "source": [
    "# Export classifier head as ONNX\n",
    "print(\"üì§ Exporting model...\\n\")\n",
    "\n",
    "# Create dummy input\n",
    "dummy_input = torch.randn(1, 3, IMAGE_SIZE, IMAGE_SIZE).to(device)\n",
    "\n",
    "onnx_path = os.path.join(OUTPUT_PATH, 'classifier_head.onnx')\n",
    "\n",
    "try:\n",
    "    torch.onnx.export(\n",
    "        classifier.classifier,\n",
    "        dummy_input,\n",
    "        onnx_path,\n",
    "        input_names=['image_embeddings'],\n",
    "        output_names=['logits'],\n",
    "        opset_version=14,\n",
    "        dynamic_axes={'image_embeddings': {0: 'batch_size'},\n",
    "                      'logits': {0: 'batch_size'}}\n",
    "    )\n",
    "    print(f\"‚úÖ ONNX model exported: {onnx_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not export ONNX model: {e}\")\n",
    "\n",
    "# Also save as PyTorch format\n",
    "torch_path = os.path.join(OUTPUT_PATH, 'classifier_head.pt')\n",
    "torch.save(classifier.classifier.state_dict(), torch_path)\n",
    "print(f\"‚úÖ PyTorch model saved: {torch_path}\")\n",
    "\n",
    "# Create deployment package info\n",
    "deployment_info = {\n",
    "    'model_type': 'MedSigLIP Classifier Head',\n",
    "    'framework': 'PyTorch',\n",
    "    'input_shape': [1, 1152],\n",
    "    'output_shape': [1, num_classes],\n",
    "    'output_format': 'logits',\n",
    "    'classes': train_dataset.classes,\n",
    "    'preprocessing': 'ImageNet normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])',\n",
    "    'image_size': IMAGE_SIZE,\n",
    "}\n",
    "\n",
    "with open(os.path.join(OUTPUT_PATH, 'deployment_info.json'), 'w') as f:\n",
    "    json.dump(deployment_info, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úÖ All models exported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary_section"
   },
   "source": [
    "## üéì Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "summary"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ FINE-TUNING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä Final Results:\")\n",
    "print(f\"   ‚Ä¢ Final Test Accuracy: {final_accuracy*100:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Best Accuracy: {best_accuracy*100:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Number of Classes: {num_classes}\")\n",
    "print(f\"   ‚Ä¢ Training Time: ~{NUM_EPOCHS * 5:.0f} minutes (estimated)\")\n",
    "\n",
    "print(f\"\\nüìÅ Output Files:\")\n",
    "print(f\"   ‚Ä¢ Best Model: {best_model_path}\")\n",
    "print(f\"   ‚Ä¢ PyTorch Model: {torch_path}\")\n",
    "print(f\"   ‚Ä¢ Training History: {history_path}\")\n",
    "print(f\"   ‚Ä¢ Classification Report: {os.path.join(OUTPUT_PATH, 'classification_report.json')}\")\n",
    "print(f\"   ‚Ä¢ Training Visualization: {os.path.join(OUTPUT_PATH, 'training_results.png')}\")\n",
    "print(f\"   ‚Ä¢ Predictions Visualization: {os.path.join(OUTPUT_PATH, 'predictions_visualization.png')}\")\n",
    "\n",
    "print(f\"\\nüöÄ Next Steps:\")\n",
    "print(f\"   1. Download all files from /content/output\")\n",
    "print(f\"   2. Test on new nail images using predict_image() function\")\n",
    "print(f\"   3. Deploy to mobile/web using exported ONNX or PyTorch models\")\n",
    "print(f\"   4. Fine-tune with more data for better accuracy\")\n",
    "print(f\"   5. Share results on GitHub with the MedSigLIP-Fine-tuning branch\")\n",
    "\n",
    "print(f\"\\nüîó GitHub Repository:\")\n",
    "print(f\"   Repository: https://github.com/isumenuka/medsiglip-nail-disease-finetuning\")\n",
    "print(f\"   Branch: MedSigLIP-Fine-tuning\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Thank you for using MedSigLIP Fine-tuning Notebook! üéâ\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}