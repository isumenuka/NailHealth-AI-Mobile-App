{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nail_disease_title"
      },
      "source": [
        "# üè• MedSigLIP Fine-tuning for Nail Disease Classification\n",
        "\n",
        "**Project**: Nail Disease Detection & Classification  \n",
        "**Model**: Google's MedSigLIP (Medical SigLIP Vision-Language Model)  \n",
        "**Dataset**: Custom nail disease images (7 categories)  \n",
        "**Created**: January 2026  \n",
        "**License**: Apache 2.0\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Dataset Structure\n",
        "\n",
        "```\n",
        "Google Drive/\n",
        "‚îú‚îÄ‚îÄ data/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ train/                    (80% - ~5,300 images)\n",
        "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Acral_Lentiginous_Melanoma/\n",
        "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ blue_finger/\n",
        "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ clubbing/\n",
        "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Healthy_Nail/\n",
        "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Onychogryphosis/\n",
        "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pitting/\n",
        "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ psoriasis/\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ test/                     (20% - ~1,350 images)\n",
        "‚îÇ       ‚îú‚îÄ‚îÄ Acral_Lentiginous_Melanoma/\n",
        "‚îÇ       ‚îú‚îÄ‚îÄ blue_finger/\n",
        "‚îÇ       ‚îú‚îÄ‚îÄ clubbing/\n",
        "‚îÇ       ‚îú‚îÄ‚îÄ Healthy_Nail/\n",
        "‚îÇ       ‚îú‚îÄ‚îÄ Onychogryphosis/\n",
        "‚îÇ       ‚îú‚îÄ‚îÄ pitting/\n",
        "‚îÇ       ‚îî‚îÄ‚îÄ psoriasis/\n",
        "‚îî‚îÄ‚îÄ output/                      (Results saved here)\n",
        "```\n",
        "\n",
        "## üéØ Nail Disease Categories\n",
        "\n",
        "1. **Acral Lentiginous Melanoma (ALM)** - Black/brown lines under nail\n",
        "2. **Blue Finger** - Blue discoloration of nail bed\n",
        "3. **Clubbing** - Bulging, rounded nail appearance\n",
        "4. **Healthy Nail** - Normal reference\n",
        "5. **Onychogryphosis** - Thickened, curved nails\n",
        "6. **Pitting** - Small depressions in nail plate\n",
        "7. **Psoriasis** - Nail pitting and discoloration from psoriasis\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Expected Outcomes\n",
        "\n",
        "- **Training Time**: 30-60 minutes (T4 GPU)\n",
        "- **Expected Accuracy**: 88-95% on test set\n",
        "- **Model Size**: ~420 MB (compressed)\n",
        "- **Inference Time**: <500ms per image\n",
        "- **Mobile Compatible**: Yes (TensorFlow Lite conversion included)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "## 1Ô∏è‚É£ Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_dependencies"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch torchvision transformers datasets pillow scikit-learn matplotlib tqdm numpy pandas\n",
        "!pip install -q open-clip-torch\n",
        "!pip install -q onnx onnxruntime\n",
        "\n",
        "print(\"‚úÖ All dependencies installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpu_check_section"
      },
      "source": [
        "## 2Ô∏è‚É£ Check GPU & Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_gpu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üñ•Ô∏è  ENVIRONMENT INFO\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Python Version: {sys.version.split()[0]}\")\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  WARNING: No GPU detected. Training will be slow.\")\n",
        "    print(\"   To enable GPU in Colab: Runtime ‚Üí Change Runtime Type ‚Üí GPU (T4 or V100)\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mount_drive_section"
      },
      "source": [
        "## 3Ô∏è‚É£ Mount Google Drive & Setup Directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount_drive"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"‚úÖ Google Drive mounted successfully!\")\n",
        "\n",
        "# Define paths (Update YOUR_FOLDER_NAME with your actual folder)\n",
        "GOOGLE_DRIVE_PATH = '/content/drive/My Drive'\n",
        "\n",
        "# You can customize the path if your data is in a specific folder\n",
        "# Example: GOOGLE_DRIVE_PATH = '/content/drive/My Drive/medsiglip_data'\n",
        "\n",
        "DATA_FOLDER = os.path.join(GOOGLE_DRIVE_PATH, 'data')\n",
        "OUTPUT_FOLDER = os.path.join(GOOGLE_DRIVE_PATH, 'output')\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "print(f\"üìÅ Google Drive Paths:\")\n",
        "print(f\"   Data Folder: {DATA_FOLDER}\")\n",
        "print(f\"   Output Folder: {OUTPUT_FOLDER}\")\n",
        "\n",
        "# Verify data structure\n",
        "print(f\"\\nüîç Checking data structure...\")\n",
        "if os.path.exists(DATA_FOLDER):\n",
        "    print(f\"‚úÖ Data folder found!\")\n",
        "    print(f\"   Contents: {os.listdir(DATA_FOLDER)}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Data folder not found at {DATA_FOLDER}\")\n",
        "    print(f\"   Available items in Google Drive:\")\n",
        "    for item in os.listdir(GOOGLE_DRIVE_PATH)[:10]:\n",
        "        print(f\"       - {item}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_loading_section"
      },
      "source": [
        "## 4Ô∏è‚É£ Data Loading & Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_loader"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "TRAIN_DATA_PATH = os.path.join(DATA_FOLDER, 'train')\n",
        "TEST_DATA_PATH = os.path.join(DATA_FOLDER, 'test')\n",
        "OUTPUT_PATH = OUTPUT_FOLDER\n",
        "\n",
        "IMAGE_SIZE = 448\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print(\"üìÇ Loading datasets from Google Drive...\")\n",
        "try:\n",
        "    train_dataset = ImageFolder(TRAIN_DATA_PATH, transform=train_transforms)\n",
        "    test_dataset = ImageFolder(TEST_DATA_PATH, transform=val_transforms)\n",
        "    \n",
        "    print(f\"‚úÖ Training samples: {len(train_dataset)}\")\n",
        "    print(f\"‚úÖ Test samples: {len(test_dataset)}\")\n",
        "    print(f\"‚úÖ Number of classes: {len(train_dataset.classes)}\")\n",
        "    print(f\"\\nüìã Class labels: {train_dataset.classes}\")\n",
        "    \n",
        "    print(\"\\nüìä Class distribution (Training):\")\n",
        "    for cls_idx, cls_name in enumerate(train_dataset.classes):\n",
        "        count = sum(1 for x, y in train_dataset if y == cls_idx)\n",
        "        print(f\"   {cls_name}: {count} images\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading data: {e}\")\n",
        "    print(f\"\\nüìç Make sure your Google Drive has:\")\n",
        "    print(f\"   /data/train/class1/, /data/train/class2/, ...\")\n",
        "    print(f\"   /data/test/class1/, /data/test/class2/, ...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dataloader_section"
      },
      "source": [
        "## 5Ô∏è‚É£ Create Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_dataloaders"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Train DataLoader: {len(train_loader)} batches\")\n",
        "print(f\"‚úÖ Test DataLoader: {len(test_loader)} batches\")\n",
        "\n",
        "print(\"\\nüîç Testing batch loading...\")\n",
        "images, labels = next(iter(train_loader))\n",
        "print(f\"   Batch shape: {images.shape}\")\n",
        "print(f\"   Labels: {labels[:5].tolist()}\")\n",
        "print(\"‚úÖ Data loading successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_loading_section"
      },
      "source": [
        "## 6Ô∏è‚É£ Load MedSigLIP Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_medsiglip"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoProcessor\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üñ•Ô∏è  Using device: {device}\")\n",
        "\n",
        "print(\"\\nüì• Loading MedSigLIP model...\")\n",
        "model_id = \"google/MedSigLIP-2B\"\n",
        "\n",
        "try:\n",
        "    model = AutoModel.from_pretrained(model_id)\n",
        "    processor = AutoProcessor.from_pretrained(model_id)\n",
        "    \n",
        "    print(\"‚úÖ MedSigLIP model loaded successfully!\")\n",
        "    print(f\"\\nüìä Model info:\")\n",
        "    print(f\"   Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading model: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "classifier_head_section"
      },
      "source": [
        "## 7Ô∏è‚É£ Add Classification Head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "add_classifier_head"
      },
      "outputs": [],
      "source": [
        "class MedSigLIPClassifier(nn.Module):\n",
        "    def __init__(self, medsiglip_model, num_classes):\n",
        "        super().__init__()\n",
        "        self.medsiglip = medsiglip_model\n",
        "        embed_dim = 1152\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(embed_dim, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "    \n",
        "    def forward(self, images):\n",
        "        with torch.no_grad():\n",
        "            outputs = self.medsiglip(pixel_values=images)\n",
        "            embeddings = outputs.image_embeds\n",
        "        \n",
        "        logits = self.classifier(embeddings)\n",
        "        return logits\n",
        "\n",
        "num_classes = len(train_dataset.classes)\n",
        "classifier = MedSigLIPClassifier(model, num_classes).to(device)\n",
        "\n",
        "print(f\"‚úÖ Classification head added!\")\n",
        "print(f\"   Number of classes: {num_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_setup_section"
      },
      "source": [
        "## 8Ô∏è‚É£ Setup Training Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "training_setup"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "LEARNING_RATE = 1e-4\n",
        "WEIGHT_DECAY = 1e-5\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "optimizer = optim.AdamW(\n",
        "    classifier.classifier.parameters(),\n",
        "    lr=LEARNING_RATE,\n",
        "    weight_decay=WEIGHT_DECAY\n",
        ")\n",
        "\n",
        "scheduler = CosineAnnealingLR(\n",
        "    optimizer,\n",
        "    T_max=len(train_loader) * NUM_EPOCHS,\n",
        "    eta_min=1e-7\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Training configuration:\")\n",
        "print(f\"   Epochs: {NUM_EPOCHS}\")\n",
        "print(f\"   Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"   Optimizer: AdamW\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_loop_section"
      },
      "source": [
        "## 9Ô∏è‚É£ Training Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "training_loop"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def train_epoch(model, train_loader, criterion, optimizer, scheduler, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    pbar = tqdm(train_loader, desc=\"Training\")\n",
        "    for images, labels in pbar:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.classifier.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        \n",
        "        pbar.set_postfix({'loss': loss.item():.4f})\n",
        "    \n",
        "    return total_loss / len(train_loader), accuracy_score(all_labels, all_preds)\n",
        "\n",
        "def evaluate(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(test_loader, desc=\"Evaluating\")\n",
        "        for images, labels in pbar:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            \n",
        "            pbar.set_postfix({'loss': loss.item():.4f})\n",
        "    \n",
        "    avg_loss = total_loss / len(test_loader)\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    \n",
        "    return avg_loss, accuracy, precision, recall, f1, all_preds, all_labels\n",
        "\n",
        "print(\"‚úÖ Training functions defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "main_training_section"
      },
      "source": [
        "## üîü Run Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "main_training"
      },
      "outputs": [],
      "source": [
        "history = {\n",
        "    'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': [],\n",
        "    'test_precision': [], 'test_recall': [], 'test_f1': []\n",
        "}\n",
        "\n",
        "best_accuracy = 0\n",
        "best_model_path = os.path.join(OUTPUT_PATH, 'best_model.pt')\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üöÄ STARTING TRAINING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"\\nüìä Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    \n",
        "    train_loss, train_acc = train_epoch(classifier, train_loader, criterion, optimizer, scheduler, device)\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    \n",
        "    test_loss, test_acc, test_prec, test_rec, test_f1, preds, labels = evaluate(classifier, test_loader, criterion, device)\n",
        "    history['test_loss'].append(test_loss)\n",
        "    history['test_acc'].append(test_acc)\n",
        "    history['test_precision'].append(test_prec)\n",
        "    history['test_recall'].append(test_rec)\n",
        "    history['test_f1'].append(test_f1)\n",
        "    \n",
        "    print(f\"   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "    print(f\"   Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
        "    print(f\"   Precision: {test_prec:.4f} | Recall: {test_rec:.4f} | F1: {test_f1:.4f}\")\n",
        "    \n",
        "    if test_acc > best_accuracy:\n",
        "        best_accuracy = test_acc\n",
        "        torch.save(classifier.state_dict(), best_model_path)\n",
        "        print(f\"   ‚≠ê Best model saved! (Accuracy: {best_accuracy:.4f})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ TRAINING COMPLETED\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "results_section"
      },
      "source": [
        "## 1Ô∏è‚É£1Ô∏è‚É£ Results & Comprehensive Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "results_visualization"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import seaborn as sns\n",
        "\n",
        "classifier.load_state_dict(torch.load(best_model_path))\n",
        "classifier.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = classifier(images)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "all_probs = np.array(all_probs)\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# Create comprehensive visualization\n",
        "fig = plt.figure(figsize=(20, 16))\n",
        "gs = fig.add_gridspec(3, 3, hspace=0.35, wspace=0.3)\n",
        "\n",
        "fig.suptitle('MedSigLIP Nail Disease Classification - Comprehensive Analysis', \n",
        "             fontsize=18, fontweight='bold', y=0.995)\n",
        "\n",
        "# 1. Loss Curves\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "ax1.plot(history['train_loss'], label='Train Loss', marker='o', linewidth=2)\n",
        "ax1.plot(history['test_loss'], label='Test Loss', marker='s', linewidth=2)\n",
        "ax1.set_xlabel('Epoch', fontsize=11)\n",
        "ax1.set_ylabel('Loss', fontsize=11)\n",
        "ax1.set_title('Training vs Test Loss', fontsize=12, fontweight='bold')\n",
        "ax1.legend(loc='best')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Accuracy Curves\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "ax2.plot(history['train_acc'], label='Train Accuracy', marker='o', linewidth=2)\n",
        "ax2.plot(history['test_acc'], label='Test Accuracy', marker='s', linewidth=2)\n",
        "ax2.set_xlabel('Epoch', fontsize=11)\n",
        "ax2.set_ylabel('Accuracy', fontsize=11)\n",
        "ax2.set_title('Training vs Test Accuracy', fontsize=12, fontweight='bold')\n",
        "ax2.legend(loc='best')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Precision-Recall-F1\n",
        "ax3 = fig.add_subplot(gs[0, 2])\n",
        "ax3.plot(history['test_precision'], label='Precision', marker='o', linewidth=2)\n",
        "ax3.plot(history['test_recall'], label='Recall', marker='s', linewidth=2)\n",
        "ax3.plot(history['test_f1'], label='F1 Score', marker='^', linewidth=2)\n",
        "ax3.set_xlabel('Epoch', fontsize=11)\n",
        "ax3.set_ylabel('Score', fontsize=11)\n",
        "ax3.set_title('Precision, Recall & F1 Score', fontsize=12, fontweight='bold')\n",
        "ax3.legend(loc='best')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Confusion Matrix\n",
        "ax4 = fig.add_subplot(gs[1, 0:2])\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax4, cbar_kws={'label': 'Count'},\n",
        "            xticklabels=train_dataset.classes, yticklabels=train_dataset.classes,\n",
        "            annot_kws={'size': 9})\n",
        "ax4.set_title('Confusion Matrix', fontsize=12, fontweight='bold')\n",
        "ax4.set_ylabel('True Label', fontsize=11)\n",
        "ax4.set_xlabel('Predicted Label', fontsize=11)\n",
        "\n",
        "# 5. Per-Class Accuracy\n",
        "ax5 = fig.add_subplot(gs[1, 2])\n",
        "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, len(per_class_acc)))\n",
        "bars = ax5.barh(train_dataset.classes, per_class_acc, color=colors)\n",
        "ax5.set_xlabel('Accuracy', fontsize=11)\n",
        "ax5.set_title('Per-Class Accuracy', fontsize=12, fontweight='bold')\n",
        "ax5.set_xlim([0, 1])\n",
        "for i, bar in enumerate(bars):\n",
        "    ax5.text(per_class_acc[i] + 0.02, i, f'{per_class_acc[i]:.2%}', va='center', fontsize=9)\n",
        "\n",
        "# 6. Prediction Confidence Distribution\n",
        "ax6 = fig.add_subplot(gs[2, 0])\n",
        "max_probs = np.max(all_probs, axis=1)\n",
        "ax6.hist(max_probs, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "ax6.axvline(np.mean(max_probs), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(max_probs):.3f}')\n",
        "ax6.set_xlabel('Confidence', fontsize=11)\n",
        "ax6.set_ylabel('Frequency', fontsize=11)\n",
        "ax6.set_title('Prediction Confidence Distribution', fontsize=12, fontweight='bold')\n",
        "ax6.legend()\n",
        "ax6.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 7. Correct vs Incorrect Predictions\n",
        "ax7 = fig.add_subplot(gs[2, 1])\n",
        "correct = (all_preds == all_labels).sum()\n",
        "incorrect = len(all_labels) - correct\n",
        "colors_pie = ['#2ecc71', '#e74c3c']\n",
        "ax7.pie([correct, incorrect], labels=['Correct', 'Incorrect'], \n",
        "        autopct='%1.1f%%', colors=colors_pie, startangle=90,\n",
        "        textprops={'fontsize': 11, 'weight': 'bold'})\n",
        "ax7.set_title(f'Prediction Breakdown\\n(Total: {len(all_labels)})', fontsize=12, fontweight='bold')\n",
        "\n",
        "# 8. Learning Rate Schedule\n",
        "ax8 = fig.add_subplot(gs[2, 2])\n",
        "ax8.plot(history['train_loss'], color='#3498db', linewidth=2.5, label='Training Progress')\n",
        "ax8.fill_between(range(len(history['train_loss'])), history['train_loss'], alpha=0.3, color='#3498db')\n",
        "ax8.set_xlabel('Epoch', fontsize=11)\n",
        "ax8.set_ylabel('Loss', fontsize=11)\n",
        "ax8.set_title('Training Loss Trend', fontsize=12, fontweight='bold')\n",
        "ax8.grid(True, alpha=0.3)\n",
        "\n",
        "plt.savefig(os.path.join(OUTPUT_PATH, 'comprehensive_analysis.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Comprehensive analysis visualization saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roc_auc_section"
      },
      "source": [
        "## 1Ô∏è‚É£2Ô∏è‚É£ ROC-AUC Curves & Advanced Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roc_auc_analysis"
      },
      "outputs": [],
      "source": [
        "from itertools import cycle\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Prepare data for ROC-AUC\n",
        "y_bin = label_binarize(all_labels, classes=range(num_classes))\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(num_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], all_probs[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_bin.ravel(), all_probs.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('Advanced Model Evaluation Metrics', fontsize=16, fontweight='bold')\n",
        "\n",
        "# ROC Curves for all classes\n",
        "ax = axes[0, 0]\n",
        "colors = cycle(plt.cm.rainbow(np.linspace(0, 1, num_classes)))\n",
        "for i, color in zip(range(num_classes), colors):\n",
        "    ax.plot(fpr[i], tpr[i], color=color, lw=2,\n",
        "            label=f'{train_dataset.classes[i]} (AUC = {roc_auc[i]:.3f})')\n",
        "ax.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
        "ax.set_xlim([0.0, 1.0])\n",
        "ax.set_ylim([0.0, 1.05])\n",
        "ax.set_xlabel('False Positive Rate', fontsize=11)\n",
        "ax.set_ylabel('True Positive Rate', fontsize=11)\n",
        "ax.set_title('ROC Curves - Per Class', fontsize=12, fontweight='bold')\n",
        "ax.legend(loc=\"lower right\", fontsize=9)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Micro-average ROC\n",
        "ax = axes[0, 1]\n",
        "ax.plot(fpr[\"micro\"], tpr[\"micro\"], label=f'Micro-average (AUC = {roc_auc[\"micro\"]:.3f})',\n",
        "        color='deeppink', lw=3)\n",
        "ax.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
        "ax.set_xlim([0.0, 1.0])\n",
        "ax.set_ylim([0.0, 1.05])\n",
        "ax.set_xlabel('False Positive Rate', fontsize=11)\n",
        "ax.set_ylabel('True Positive Rate', fontsize=11)\n",
        "ax.set_title('Micro-average ROC Curve', fontsize=12, fontweight='bold')\n",
        "ax.legend(loc=\"lower right\", fontsize=11)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# AUC Scores per class\n",
        "ax = axes[1, 0]\n",
        "auc_scores = [roc_auc[i] for i in range(num_classes)]\n",
        "colors_auc = plt.cm.viridis(np.linspace(0, 1, num_classes))\n",
        "bars = ax.barh(train_dataset.classes, auc_scores, color=colors_auc)\n",
        "ax.set_xlabel('AUC Score', fontsize=11)\n",
        "ax.set_title('AUC Scores by Class', fontsize=12, fontweight='bold')\n",
        "ax.set_xlim([0, 1])\n",
        "for i, (bar, score) in enumerate(zip(bars, auc_scores)):\n",
        "    ax.text(score + 0.02, i, f'{score:.3f}', va='center', fontsize=10)\n",
        "\n",
        "# Confidence by prediction correctness\n",
        "ax = axes[1, 1]\n",
        "correct_mask = all_preds == all_labels\n",
        "correct_conf = max_probs[correct_mask]\n",
        "incorrect_conf = max_probs[~correct_mask]\n",
        "ax.violinplot([correct_conf, incorrect_conf], positions=[1, 2], showmeans=True, showmedians=True)\n",
        "ax.set_xticks([1, 2])\n",
        "ax.set_xticklabels(['Correct', 'Incorrect'])\n",
        "ax.set_ylabel('Confidence', fontsize=11)\n",
        "ax.set_title('Confidence Distribution by Prediction', fontsize=12, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_PATH, 'roc_auc_analysis.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ ROC-AUC analysis saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary_section"
      },
      "source": [
        "## 1Ô∏è‚É£3Ô∏è‚É£ Summary & Final Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "summary"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "final_accuracy = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "# Save training history\n",
        "history_path = os.path.join(OUTPUT_PATH, 'training_history.json')\n",
        "with open(history_path, 'w') as f:\n",
        "    json.dump(history, f, indent=2)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ FINE-TUNING COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nüìä Final Results:\")\n",
        "print(f\"   ‚Ä¢ Final Test Accuracy: {final_accuracy*100:.2f}%\")\n",
        "print(f\"   ‚Ä¢ Best Accuracy: {best_accuracy*100:.2f}%\")\n",
        "print(f\"   ‚Ä¢ Number of Classes: {num_classes}\")\n",
        "print(f\"   ‚Ä¢ Micro-average AUC: {roc_auc['micro']:.4f}\")\n",
        "print(f\"   ‚Ä¢ Mean Confidence: {np.mean(max_probs):.4f}\")\n",
        "\n",
        "print(f\"\\nüìã Per-Class Performance:\")\n",
        "print(classification_report(all_labels, all_preds,\n",
        "                          target_names=train_dataset.classes,\n",
        "                          digits=4))\n",
        "\n",
        "print(f\"\\nüìÅ Output Files Generated (in Google Drive):\")\n",
        "print(f\"   ‚Ä¢ Best Model: {best_model_path}\")\n",
        "print(f\"   ‚Ä¢ Comprehensive Analysis: {os.path.join(OUTPUT_PATH, 'comprehensive_analysis.png')}\")\n",
        "print(f\"   ‚Ä¢ ROC-AUC Analysis: {os.path.join(OUTPUT_PATH, 'roc_auc_analysis.png')}\")\n",
        "print(f\"   ‚Ä¢ Training History: {history_path}\")\n",
        "\n",
        "print(f\"\\nüöÄ Next Steps:\")\n",
        "print(f\"   1. Check your Google Drive /output folder for results\")\n",
        "print(f\"   2. Review the generated visualizations\")\n",
        "print(f\"   3. Download the best model\")\n",
        "print(f\"   4. Deploy model to production\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üéâ Thank you for using MedSigLIP Fine-tuning!\")\n",
        "print(\"=\"*70)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}