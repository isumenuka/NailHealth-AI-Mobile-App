{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 14674312,
          "sourceType": "datasetVersion",
          "datasetId": 9374868
        }
      ],
      "dockerImageVersionId": 31260,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "gpuType": "T4",
      "name": "notebookc4efb879ae",
      "provenance": []
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# ü©∫ Building Accessible AI: Nail Disease Detection with MedGemma\n\n**The Challenge**: \"How can we make expert-level dermatology accessible to everyone, everywhere?\"\n\nIn many parts of the world, access to a dermatologist is a luxury. Early detection of conditions like melanoma or signs of systemic disease in nails can save lives. This project leverages **Google's MedSigLIP (Medical SigLIP Vision-Language Model)** to build a highly accurate, efficient, and mobile-ready nail disease classifier. \n\nOur goal isn't just to build a model; it's to build a tool that can be deployed on a smartphone to help community health workers and individuals make informed decisions.\n\n---\n\n### üåü Why This Matters\n\nThis notebook represents a submission to the **MedGemma Impact Challenge**, focusing on human-centered AI. We are:\n- **Democratizing Access**: Using open-source medical models to bring specialist knowledge to the edge.\n- **Prioritizing Privacy**: Designing for efficient edge deployment so data can stay on the device.\n- **Optimizing for Real Performance**: Not just chasing accuracy, but ensuring the model is robust and fast.\n\n---\n\n### üöÄ Key Capabilities\n\n- **Seamless Integration**: Directly connects to our curated Kaggle dataset.\n- **Smart Processing**: Auto-magically handles train/test splits and image augmentation.\n- **Advanced Fine-Tuning**: We don't just retrain the top layer; we carefully unfreeze deeper layers to let the model \"learn\" the texture of nails.\n- **Safety Nets**: Built-in overfitting detection to ensure our model generalizes well to new patients.\n\n---\n\n### ü¶† The Conditions We Detect\n\nWe are training our digital assistant to recognize 7 specific categories:\n1. **Acral Lentiginous Melanoma (ALM)**: A dangerous form of skin cancer that can mimic a bruise.\n2. **Blue Finger**: Often a sign of poor oxygenation or circulation issues.\n3. **Clubbing**: A classic sign of chronic heart or lung conditions.\n4. **Onychogryphosis**: \"Ram's horn nails,\" common in elderly populations, needing specific care.\n5. **Pitting**: Often the first sign of Psoriasis or other autoimmune issues.\n6. **Psoriasis**: A chronic condition that frequently affects nails first.\n7. **Healthy Nail**: The baseline for normal.\n\nLet's build something that matters. üëá",
      "metadata": {
        "_uuid": "496eacb8-7277-4524-8de0-6e6d92618f82",
        "_cell_guid": "2ab2f2f1-892e-4d39-89c2-91a032590fb1",
        "trusted": true,
        "collapsed": false,
        "id": "nail_disease_title_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 1Ô∏è‚É£ Setting Up Access to Medical Intelligence\n\n**Ethics First**: DeepMind's MedSigLIP is a powerful tool trained on diverse medical data. To ensure responsible use, we need to authenticate with Hugging Face.\n\n1. **Get your Key**: If you haven't, grab a token from [Hugging Face Settings](https://huggingface.co/settings/tokens).\n2. **Request Access**: Ensure you've approved the terms at [google/medsiglip-448](https://huggingface.co/google/medsiglip-448).\n3. **Authenticate below**: Paste your token when prompted to unlock the model.",
      "metadata": {
        "_uuid": "8fab7aba-25fa-4ed7-8883-cc2f993ddfba",
        "_cell_guid": "83f6d7f5-b164-4b57-bdfc-6a58d619f88c",
        "trusted": true,
        "collapsed": false,
        "id": "hf_login_section",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "from huggingface_hub import notebook_login\n\nprint(\"=\"*70)\nprint(\"üîê HUGGING FACE LOGIN\")\nprint(\"=\"*70)\nprint(\"\\nYou'll be prompted to enter your Hugging Face token.\")\nprint(\"Get your token: https://huggingface.co/settings/tokens\\n\")\n\nnotebook_login()\n\nprint(\"\\n‚úÖ Login successful!\")",
      "metadata": {
        "_uuid": "5f483859-7a12-45ba-93eb-a1e8fd31379c",
        "_cell_guid": "08043a60-8459-4da7-9772-704727b5bdfb",
        "trusted": true,
        "collapsed": false,
        "id": "hf_login",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 2Ô∏è‚É£ Install Dependencies",
      "metadata": {
        "_uuid": "d00e8c1e-dcbf-4935-aee3-0991d5bb25bb",
        "_cell_guid": "b5838788-1771-41a8-af83-e9bd77b117ae",
        "trusted": true,
        "collapsed": false,
        "id": "setup_section_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "!pip install -q torch torchvision transformers datasets pillow scikit-learn matplotlib tqdm numpy pandas\n!pip install -q open-clip-torch\n!pip install -q onnx onnxruntime\n!pip install -q huggingface_hub\n!pip install -q timm\n\nprint(\"‚úÖ Medical AI Toolkit ready! All systems go.\")",
      "metadata": {
        "_uuid": "e73e082e-dab8-4419-b281-0831b67a8dd9",
        "_cell_guid": "78eb02b4-87c7-4fdb-9644-12014cbbc9ba",
        "trusted": true,
        "collapsed": false,
        "id": "install_dependencies_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 3Ô∏è‚É£ Verifying Our Computational Engine",
      "metadata": {
        "_uuid": "6288c814-23f8-4c65-8d94-955fd6a954db",
        "_cell_guid": "dcd9202e-d9f9-4e91-9d7f-527557c1e8e7",
        "trusted": true,
        "collapsed": false,
        "id": "gpu_check_section_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "import torch\nimport sys\nfrom pathlib import Path\n\nprint(\"=\"*70)\nprint(\"üñ•Ô∏è ENVIRONMENT INFO\")\nprint(\"=\"*70)\nprint(f\"Python Version: {sys.version.split()[0]}\")\nprint(f\"PyTorch Version: {torch.__version__}\")\nprint(f\"GPU Available: {torch.cuda.is_available()}\")\n\nif torch.cuda.is_available():\n    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n    for i in range(torch.cuda.device_count()):\n        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n        print(f\"    Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} GB\")\n    print(f\"CUDA Version: {torch.version.cuda}\")\nelse:\n    print(\"‚ö†Ô∏è WARNING: No GPU detected. Training will be very slow.\")\nprint(\"=\"*70)",
      "metadata": {
        "_uuid": "faecd726-4777-4430-bf8f-24cb94eb8a23",
        "_cell_guid": "0813eee6-63bd-43da-b8be-77895c1456ae",
        "trusted": true,
        "collapsed": false,
        "id": "check_gpu_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 4Ô∏è‚É£ Connecting to the Patient Database",
      "metadata": {
        "_uuid": "94823f1e-9ca6-4896-8892-f8f620edd9f2",
        "_cell_guid": "c89a2610-382d-41c9-88b6-093767baa12d",
        "trusted": true,
        "collapsed": false,
        "id": "kaggle_setup_section",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "import os\nfrom pathlib import Path\n\nKAGGLE_DATASET_PATH = '/kaggle/input/nail-disease-dataset-medsiglip'\nOUTPUT_PATH = '/kaggle/working/output'\n\nos.makedirs(OUTPUT_PATH, exist_ok=True)\n\nprint(\"=\"*70)\nprint(\"üìÇ CONNECTING TO MEDICAL DATABASE\")\nprint(\"=\"*70)\n\nif not os.path.exists(KAGGLE_DATASET_PATH):\n    print(f\"\\n‚ùå ERROR: Database connection failed at {KAGGLE_DATASET_PATH}\")\n    print(\"\\nüìã SOLUTION:\")\n    print(\"   1. Add 'nail-disease-dataset' as an input to this notebook\")\n    print(\"   2. Go to notebook settings ‚Üí Add data\")\n    print(\"   3. Search for 'nail-disease-dataset' and add it\")\n    print(\"   4. Re-run this cell\")\n    raise FileNotFoundError(f\"Dataset not found at {KAGGLE_DATASET_PATH}\")\n\nprint(f\"‚úÖ Dataset path found: {KAGGLE_DATASET_PATH}\")\n\nprint(f\"\\nüìç Available Kaggle Inputs:\")\nfor item in os.listdir('/kaggle/input'):\n    print(f\"   ‚Ä¢ {item}\")\n\nprint(f\"\\nüîç Looking for train/test directories...\")\ndataset_contents = os.listdir(KAGGLE_DATASET_PATH)\nprint(f\"\\nüìÇ Dataset contents:\")\nfor item in dataset_contents:\n    item_path = os.path.join(KAGGLE_DATASET_PATH, item)\n    if os.path.isdir(item_path):\n        file_count = len([f for f in os.listdir(item_path) if os.path.isfile(os.path.join(item_path, f))])\n        dir_count = len([d for d in os.listdir(item_path) if os.path.isdir(os.path.join(item_path, d))])\n        print(f\"   üìÅ {item}/ ({dir_count} subdirs, {file_count} files)\")\n\nTRAIN_DATA_PATH = os.path.join(KAGGLE_DATASET_PATH, 'train')\nTEST_DATA_PATH = os.path.join(KAGGLE_DATASET_PATH, 'test')\n\nif not os.path.exists(TRAIN_DATA_PATH) or not os.path.exists(TEST_DATA_PATH):\n    print(f\"\\n‚ùå ERROR: train/ or test/ directories not found!\")\n    print(f\"   Expected structure:\")\n    print(f\"   /kaggle/input/nail-disease-dataset/\")\n    print(f\"   ‚îú‚îÄ‚îÄ train/ (with class folders)\")\n    print(f\"   ‚îî‚îÄ‚îÄ test/ (with class folders)\")\n    raise FileNotFoundError(\"train/ or test/ directories not found\")\n\nprint(f\"\\n‚úÖ Dataset paths configured:\")\nprint(f\"   TRAIN: {TRAIN_DATA_PATH}\")\nprint(f\"   TEST: {TEST_DATA_PATH}\")\nprint(f\"   OUTPUT: {OUTPUT_PATH}\")\nprint(\"=\"*70)",
      "metadata": {
        "_uuid": "8036c9b1-9887-4f3e-b1af-bad4df8a8fd6",
        "_cell_guid": "809183b0-6bbc-45f2-a346-82354dbbd46a",
        "trusted": true,
        "collapsed": false,
        "id": "kaggle_dataset_setup",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 5Ô∏è‚É£ Examining the Medical Imagery",
      "metadata": {
        "_uuid": "30b8f7ae-f935-46b4-9eed-3201ecd70f2c",
        "_cell_guid": "68c3f16b-9a98-45e8-a1aa-e55d0491ea16",
        "trusted": true,
        "collapsed": false,
        "id": "data_loading_section_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "from torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nIMAGE_SIZE = 448\nBATCH_SIZE = 16\nNUM_WORKERS = 2\n\ntrain_transforms = transforms.Compose([\n    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.8, 1.0)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.3),\n    transforms.RandomRotation(30),\n    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.3, hue=0.15),\n    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n    transforms.RandomPerspective(distortion_scale=0.2, p=0.3),\n    transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    transforms.RandomErasing(p=0.3, scale=(0.02, 0.15), ratio=(0.3, 3.3), value='random')\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nprint(\"üìÇ Loading datasets...\")\ntry:\n    train_dataset = ImageFolder(TRAIN_DATA_PATH, transform=train_transforms)\n    test_dataset = ImageFolder(TEST_DATA_PATH, transform=val_transforms)\n\n    print(f\"‚úÖ Training samples: {len(train_dataset)}\")\n    print(f\"‚úÖ Test samples: {len(test_dataset)}\")\n    print(f\"‚úÖ Number of classes: {len(train_dataset.classes)}\")\n    print(f\"\\nüìã Class labels: {train_dataset.classes}\")\n\n    print(\"\\nüìä Class distribution (Training):\")\n    for cls_idx, cls_name in enumerate(train_dataset.classes):\n        count = sum(1 for x, y in train_dataset if y == cls_idx)\n        print(f\"   {cls_name}: {count} images\")\n\nexcept Exception as e:\n    print(f\"‚ùå Error loading data: {e}\")\n    print(f\"\\nüìç Please verify dataset structure:\")\n    print(f\"   ‚îú‚îÄ‚îÄ train/class1/, class2/, ...\")\n    print(f\"   ‚îî‚îÄ‚îÄ test/class1/, class2/, ...\")\n    raise",
      "metadata": {
        "_uuid": "c081cdeb-3237-41de-b3b9-1b4fbdddbb80",
        "_cell_guid": "ed83f6bc-0d67-423e-82f2-ab9eb40b4a1a",
        "trusted": true,
        "collapsed": false,
        "id": "data_loader_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 6Ô∏è‚É£ Create Data Loaders",
      "metadata": {
        "_uuid": "7f356438-e803-4975-af48-efe743da874a",
        "_cell_guid": "573022ab-bd88-4a20-887f-9c0a6628fa87",
        "trusted": true,
        "collapsed": false,
        "id": "dataloader_section_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "from torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nIMAGE_SIZE = 448\nBATCH_SIZE = 8  # REDUCED from 16 for multi-GPU\nNUM_WORKERS = 0  # Set to 0 for stability\n\ntrain_transforms = transforms.Compose([\n    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.8, 1.0)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.3),\n    transforms.RandomRotation(30),\n    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.3, hue=0.15),\n    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n    transforms.RandomPerspective(distortion_scale=0.2, p=0.3),\n    transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    transforms.RandomErasing(p=0.3, scale=(0.02, 0.15), ratio=(0.3, 3.3), value='random')\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nprint(\"üìÇ Loading datasets...\")\ntry:\n    train_dataset = ImageFolder(TRAIN_DATA_PATH, transform=train_transforms)\n    test_dataset = ImageFolder(TEST_DATA_PATH, transform=val_transforms)\n\n    print(f\"‚úÖ Training samples: {len(train_dataset)}\")\n    print(f\"‚úÖ Test samples: {len(test_dataset)}\")\n    print(f\"‚úÖ Number of classes: {len(train_dataset.classes)}\")\n    print(f\"\\nüìã Class labels: {train_dataset.classes}\")\n\n    print(\"\\nüìä Class distribution (Training):\")\n    for cls_idx, cls_name in enumerate(train_dataset.classes):\n        count = sum(1 for x, y in train_dataset if y == cls_idx)\n        print(f\"   {cls_name}: {count} images\")\n\nexcept Exception as e:\n    print(f\"‚ùå Error loading data: {e}\")\n    raise\n\n# DataLoader with reduced batch size\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=NUM_WORKERS,\n    pin_memory=True\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=NUM_WORKERS,\n    pin_memory=True\n)\n\nprint(f\"\\n‚úÖ Train DataLoader: {len(train_loader)} batches\")\nprint(f\"‚úÖ Test DataLoader: {len(test_loader)} batches\")\n\nprint(\"\\nüîç Testing batch loading...\")\nimages, labels = next(iter(train_loader))\nprint(f\"   Batch shape: {images.shape}\")\nprint(f\"   Labels: {labels[:5].tolist()}\")\nprint(\"‚úÖ Data loading successful!\")",
      "metadata": {
        "_uuid": "9e5be109-507f-4659-8428-b1d30b2bd887",
        "_cell_guid": "b6c2e931-4c97-4226-b6aa-c88ddf468fcc",
        "trusted": true,
        "collapsed": false,
        "id": "create_dataloaders_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 7Ô∏è‚É£ Initializing MedGemma (MedSigLIP)",
      "metadata": {
        "_uuid": "ad750cc7-9c2e-494e-ac89-f56af57643ad",
        "_cell_guid": "2460cf46-fa45-471d-8377-2420f1eabcbb",
        "trusted": true,
        "collapsed": false,
        "id": "model_loading_section_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "from transformers import AutoModel, AutoProcessor\nimport torch.nn as nn\nimport gc\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"üñ•Ô∏è Using device: {device}\")\n\ntorch.cuda.empty_cache()\ngc.collect()\n\nprint(\"\\nüì• Waking up the AI Assistant...\")\nmodel_id = \"google/medsiglip-448\"\n\ntry:\n    model = AutoModel.from_pretrained(\n        model_id,\n        torch_dtype=torch.float32\n    )\n    processor = AutoProcessor.from_pretrained(model_id)\n\n    print(\"‚úÖ MedSigLIP model loaded successfully!\")\n    print(f\"\\nüìä Model info:\")\n    print(f\"   Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n\nexcept Exception as e:\n    print(f\"‚ùå Error loading model: {e}\")\n    raise\n\nclass_prompts = {\n    0: \"A medical image of acral lentiginous melanoma with black lines under the nail.\",\n    1: \"A medical image showing blue discoloration of the fingernail bed.\",\n    2: \"A medical image of nail clubbing with bulging and rounded nail appearance.\",\n    3: \"A medical image of a healthy normal nail.\",\n    4: \"A medical image of onychogryphosis with thickened and curved nails.\",\n    5: \"A medical image of nail pitting with small depressions in the nail plate.\",\n    6: \"A medical image of psoriatic nails with pitting and discoloration.\"\n}\n\nprint(\"\\nüìù Generated text prompts for classes:\")\nfor class_idx, prompt in class_prompts.items():\n    print(f\"   {class_idx}. {prompt[:60]}...\")",
      "metadata": {
        "_uuid": "e2884612-2844-4656-920e-290f702d71c1",
        "_cell_guid": "b3a66a2a-9d20-4550-a470-1941f6350de9",
        "trusted": true,
        "collapsed": false,
        "id": "load_medsiglip_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 8Ô∏è‚É£ Adapting the AI for Dermatology (Specialized Fine-Tuning)",
      "metadata": {
        "_uuid": "a4e99b27-0a7a-40c8-8d98-938f5ddcaa9e",
        "_cell_guid": "ff1035cc-3d4b-4162-9b06-c43aa7dcbc83",
        "trusted": true,
        "collapsed": false,
        "id": "classifier_head_section_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "class MedSigLIPClassifier(nn.Module):\n    def __init__(self, medsiglip_model, num_classes, device0='cuda:0', device1='cuda:1'):\n        super().__init__()\n        self.medsiglip = medsiglip_model.to(device0)\n        self.device0 = device0\n        self.device1 = device1\n\n        embed_dim = 1152\n\n        self.classifier = nn.Sequential(\n            nn.Linear(embed_dim, 768),\n            nn.LayerNorm(768),\n            nn.GELU(),\n            nn.Dropout(0.4),\n            \n            nn.Linear(768, 512),\n            nn.LayerNorm(512),\n            nn.GELU(),\n            nn.Dropout(0.4),\n            \n            nn.Linear(512, 256),\n            nn.LayerNorm(256),\n            nn.GELU(),\n            nn.Dropout(0.3),\n            \n            nn.Linear(256, num_classes)\n        ).to(device1)\n\n        # FREEZE ALL MedSigLIP layers to save memory\n        for param in self.medsiglip.parameters():\n            param.requires_grad = False\n\n    def forward(self, images):\n        # Images on GPU 0\n        images = images.to(self.device0)\n        \n        # Get embeddings on GPU 0\n        with torch.no_grad():\n            outputs = self.medsiglip.vision_model(pixel_values=images)\n            embeddings = outputs.pooler_output\n        \n        # Move embeddings to GPU 1 and cast to FP32\n        embeddings = embeddings.to(self.device1).float()\n        \n        # Classifier on GPU 1\n        logits = self.classifier(embeddings)\n        return logits\n\n\nnum_classes = len(train_dataset.classes)\n\n# Check available GPUs\nnum_gpus = torch.cuda.device_count()\nif num_gpus >= 2:\n    print(f\"üöÄ Using 2 GPUs for Model Parallel!\")\n    device0 = 'cuda:0'\n    device1 = 'cuda:1'\n    classifier = MedSigLIPClassifier(\n        medsiglip_model=model,\n        num_classes=num_classes,\n        device0=device0,\n        device1=device1\n    )\nelse:\n    print(f\"‚ö†Ô∏è Only {num_gpus} GPU(s) detected. Using single GPU.\")\n    device0 = 'cuda:0'\n    classifier = MedSigLIPClassifier(\n        medsiglip_model=model,\n        num_classes=num_classes,\n        device0=device0,\n        device1=device0\n    )\n\nprint(f\"‚úÖ Classifier ready! Classes: {num_classes}\")\nprint(f\"   MedSigLIP (Feature Extractor): {device0}\")\nprint(f\"   Classification Head: {device1 if num_gpus >= 2 else device0}\")\nprint(f\"   Optimized classifier: 1152‚Üí768‚Üí512‚Üí256‚Üí{num_classes}\")",
      "metadata": {
        "_uuid": "dd962261-bf14-4f7e-a4aa-38433da8036c",
        "_cell_guid": "42c76610-beb7-4365-8a96-c62c6d8b615b",
        "trusted": true,
        "collapsed": false,
        "id": "add_classifier_head_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 9Ô∏è‚É£ Configuring the Learning Process",
      "metadata": {
        "_uuid": "8d4e1345-a0c0-4085-b25d-9f983eda5373",
        "_cell_guid": "c690ce16-4143-4969-9f73-65a3711fe04c",
        "trusted": true,
        "collapsed": false,
        "id": "training_setup_section_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "import torch.optim as optim\nfrom torch.optim.lr_scheduler import OneCycleLR\nfrom tqdm import tqdm\nimport json\n\nNUM_EPOCHS = 10\nLEARNING_RATE = 1e-3  # Increased since we're only training classifier\nWEIGHT_DECAY = 1e-4\nGRADIENT_ACCUMULATION_STEPS = 1\n\ncriterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n\n# Only optimize classifier (MedSigLIP is frozen)\nclassifier_params = list(classifier.classifier.parameters())\n\noptimizer = optim.AdamW(classifier_params, lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY, betas=(0.9, 0.999))\n\ntotal_steps = len(train_loader) * NUM_EPOCHS // GRADIENT_ACCUMULATION_STEPS\nscheduler = OneCycleLR(\n    optimizer,\n    max_lr=LEARNING_RATE,\n    total_steps=total_steps,\n    pct_start=0.3,\n    anneal_strategy='cos',\n    div_factor=25.0,\n    final_div_factor=1000.0\n)\n\nprint(\"‚úÖ Advanced training configuration (Classifier-Only Fine-Tuning):\")\nprint(f\"   üìç Epochs: {NUM_EPOCHS}\")\nprint(f\"   üìç Learning Rate: {LEARNING_RATE}\")\nprint(f\"   üìç Batch Size: {BATCH_SIZE}\")\nprint(f\"   üìç Gradient Accumulation: {GRADIENT_ACCUMULATION_STEPS}\")\nprint(f\"   üìç Optimizer: AdamW with OneCycleLR\")\nprint(f\"   üìç Weight Decay: {WEIGHT_DECAY}\")\nprint(f\"   üìç Label Smoothing: 0.1\")\nprint(f\"   üìç MedSigLIP: FROZEN (memory efficient)\")\nprint(f\"   üìç GPU Strategy: Model Parallel (GPU 0 + GPU 1)\")",
      "metadata": {
        "_uuid": "09c60dd0-8f18-40e1-9ddd-217ab223a6b0",
        "_cell_guid": "6bafccea-0e1e-42fb-acfe-e7df5fc41019",
        "trusted": true,
        "collapsed": false,
        "id": "training_setup_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 1Ô∏è‚É£0Ô∏è‚É£ The Learning Loop (Training)",
      "metadata": {
        "_uuid": "e0ecf9e8-1192-42b5-b1da-cf59ab9cd766",
        "_cell_guid": "3bfe8e05-49dd-4abe-9795-892e55ef311b",
        "trusted": true,
        "collapsed": false,
        "id": "training_loop_section_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom tqdm import tqdm\nimport math\n\ndef train_epoch(model, train_loader, criterion, optimizer, scheduler, accumulation_steps=1):\n    model.train()\n    total_loss = 0\n    all_preds = []\n    all_labels = []\n    optimizer.zero_grad()\n\n    pbar = tqdm(train_loader, desc=\"Learning from patients\")\n    for step, (images, labels) in enumerate(pbar):\n        labels = labels.to('cuda:1' if torch.cuda.device_count() >= 2 else 'cuda:0')\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        if math.isnan(loss.item()):\n            print(f\"   ‚ö†Ô∏è NaN loss at step {step}, skipping\")\n            optimizer.zero_grad()\n            continue\n            \n        loss = loss / accumulation_steps\n        loss.backward()\n        \n        if (step + 1) % accumulation_steps == 0:\n            torch.nn.utils.clip_grad_norm_(model.classifier.parameters(), max_norm=1.0)\n            optimizer.step()\n            scheduler.step()\n            optimizer.zero_grad()\n\n        total_loss += loss.item() * accumulation_steps\n        preds = outputs.argmax(dim=1)\n        all_preds.extend(preds.detach().cpu().numpy())\n        all_labels.extend(labels.detach().cpu().numpy())\n\n        pbar.set_postfix({'loss': f'{loss.item()*accumulation_steps:.4f}'})\n\n    avg_loss = total_loss / len(train_loader)\n    accuracy = accuracy_score(all_labels, all_preds) if len(all_labels) > 0 else 0\n    return avg_loss, accuracy\n\ndef evaluate(model, test_loader, criterion):\n    model.eval()\n    total_loss = 0\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        pbar = tqdm(test_loader, desc=\"Validating performance\")\n        for images, labels in pbar:\n            labels = labels.to('cuda:1' if torch.cuda.device_count() >= 2 else 'cuda:0')\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            total_loss += loss.item()\n            preds = outputs.argmax(dim=1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n\n    avg_loss = total_loss / len(test_loader)\n    accuracy = accuracy_score(all_labels, all_preds)\n    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n\n    return avg_loss, accuracy, precision, recall, f1, all_preds, all_labels\n\nprint(\"‚úÖ Advanced training functions defined!\")",
      "metadata": {
        "_uuid": "6983bdff-7a0b-417e-8ec6-73cd581d47c3",
        "_cell_guid": "3fcc7a84-ad84-4ee5-9b88-a6fe807bbf19",
        "trusted": true,
        "collapsed": false,
        "id": "training_loop_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 1Ô∏è‚É£1Ô∏è‚É£ Run ADVANCED Training (10 Epochs)",
      "metadata": {
        "_uuid": "4e59c6b7-d86a-422a-bc00-5fd4efb11762",
        "_cell_guid": "0f3929bf-449b-41fb-85f2-8fdc2e4eedbc",
        "trusted": true,
        "collapsed": false,
        "id": "main_training_section_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "history = {\n    'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': [],\n    'test_precision': [], 'test_recall': [], 'test_f1': [], 'learning_rate': []\n}\n\nbest_accuracy = 0\nbest_epoch = 0\npatience_counter = 0\nmax_patience = 5\nbest_model_path = os.path.join(OUTPUT_PATH, 'best_model.pt')\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"üöÄ COMMENCING MEDICAL AI TRAINING\")\nprint(f\"üöÄ Using {torch.cuda.device_count()} GPUs (Model Parallel)\")\nprint(\"=\"*70)\n\nfor epoch in range(NUM_EPOCHS):\n    print(f\"\\nüìä Epoch {epoch+1}/{NUM_EPOCHS}\")\n\n    train_loss, train_acc = train_epoch(classifier, train_loader, criterion, optimizer, scheduler, GRADIENT_ACCUMULATION_STEPS)\n    history['train_loss'].append(train_loss)\n    history['train_acc'].append(train_acc)\n    history['learning_rate'].append(optimizer.param_groups[0]['lr'])\n\n    test_loss, test_acc, test_prec, test_rec, test_f1, preds, labels = evaluate(classifier, test_loader, criterion)\n    history['test_loss'].append(test_loss)\n    history['test_acc'].append(test_acc)\n    history['test_precision'].append(test_prec)\n    history['test_recall'].append(test_rec)\n    history['test_f1'].append(test_f1)\n\n    print(f\"   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n    print(f\"   Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n    print(f\"   Precision: {test_prec:.4f} | Recall: {test_rec:.4f} | F1: {test_f1:.4f}\")\n    print(f\"   LR: {optimizer.param_groups[0]['lr']:.6f}\")\n\n    if test_acc > best_accuracy:\n        best_accuracy = test_acc\n        best_epoch = epoch + 1\n        torch.save(classifier.state_dict(), best_model_path)\n        patience_counter = 0\n        print(f\"   ‚≠ê BEST model saved! (Accuracy: {best_accuracy:.4f})\")\n    else:\n        patience_counter += 1\n\n    torch.cuda.empty_cache()\n    gc.collect()\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"‚úÖ TRAINING COMPLETED\")\nprint(f\"   Best Accuracy: {best_accuracy:.4f} at Epoch {best_epoch}\")\nprint(\"=\"*70)\n\nhistory_path = os.path.join(OUTPUT_PATH, 'training_history.json')\nwith open(history_path, 'w') as f:\n    json.dump(history, f, indent=4)\nprint(f\"\\nüíæ Training history saved to: {history_path}\")",
      "metadata": {
        "_uuid": "a6654985-194d-45e8-857b-745ca3dd6910",
        "_cell_guid": "a8b6c247-6a59-44b8-a692-aa9bf07986ee",
        "trusted": true,
        "collapsed": false,
        "id": "main_training_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 1Ô∏è‚É£2Ô∏è‚É£ Validating Our Diagnostics (Results)",
      "metadata": {
        "_uuid": "cb9af2aa-4de6-4c9e-a40d-671e664710b4",
        "_cell_guid": "50254f7e-76b2-46bf-81d2-82c713efd17a",
        "trusted": true,
        "collapsed": false,
        "id": "results_section_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\nclassifier.load_state_dict(torch.load(best_model_path))\nclassifier.eval()\n\nwith torch.no_grad():\n    all_preds = []\n    all_labels = []\n    for images, labels in test_loader:\n        images = images.to(device)\n        if torch.cuda.is_available():\n            with autocast():\n                outputs = classifier(images)\n        else:\n            outputs = classifier(images)\n        preds = outputs.argmax(dim=1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\nfig.suptitle('MedSigLIP Nail Disease Classification - Advanced Results', fontsize=16, fontweight='bold')\n\naxes[0, 0].plot(history['train_loss'], label='Train Loss', marker='o')\naxes[0, 0].plot(history['test_loss'], label='Test Loss', marker='s')\naxes[0, 0].axvline(x=best_epoch-1, color='red', linestyle='--', label=f'Best Epoch {best_epoch}')\naxes[0, 0].set_xlabel('Epoch')\naxes[0, 0].set_ylabel('Loss')\naxes[0, 0].set_title('Loss over Epochs')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\naxes[0, 1].plot(history['train_acc'], label='Train Accuracy', marker='o')\naxes[0, 1].plot(history['test_acc'], label='Test Accuracy', marker='s')\naxes[0, 1].axvline(x=best_epoch-1, color='red', linestyle='--', label=f'Best Epoch {best_epoch}')\naxes[0, 1].axhline(y=0.9, color='green', linestyle=':', alpha=0.5, label='90% Target')\naxes[0, 1].set_xlabel('Epoch')\naxes[0, 1].set_ylabel('Accuracy')\naxes[0, 1].set_title('Accuracy over Epochs')\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\n\naxes[1, 0].plot(history['test_precision'], label='Precision', marker='o')\naxes[1, 0].plot(history['test_recall'], label='Recall', marker='s')\naxes[1, 0].plot(history['test_f1'], label='F1 Score', marker='^')\naxes[1, 0].axhline(y=0.9, color='green', linestyle=':', alpha=0.5, label='90% Target')\naxes[1, 0].set_xlabel('Epoch')\naxes[1, 0].set_ylabel('Score')\naxes[1, 0].set_title('Precision, Recall, F1 Score')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\ncm = confusion_matrix(all_labels, all_preds)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 1],\n            xticklabels=train_dataset.classes, yticklabels=train_dataset.classes)\naxes[1, 1].set_title('Confusion Matrix')\naxes[1, 1].set_ylabel('True Label')\naxes[1, 1].set_xlabel('Predicted Label')\n\nplt.tight_layout()\nplt.savefig(os.path.join(OUTPUT_PATH, 'training_results.png'), dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"‚úÖ Training results visualization saved!\")\nprint(f\"üìÅ Saved to: {os.path.join(OUTPUT_PATH, 'training_results.png')}\")",
      "metadata": {
        "_uuid": "f380b6bb-bcdf-4c9e-a5e7-cee6909657c2",
        "_cell_guid": "b1fb12ed-a42e-4bd6-b0c5-9f3ee277b347",
        "trusted": true,
        "collapsed": false,
        "id": "results_visualization_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 1Ô∏è‚É£2Ô∏è‚É£A - üîç Safety Check: Is the Answer Memorized? (Overfitting Analysis)",
      "metadata": {
        "_uuid": "0221b60f-bbf1-438b-8acf-988fc538afd6",
        "_cell_guid": "9e96b3cb-52e5-47c7-bd75-148e0e32a1cb",
        "trusted": true,
        "collapsed": false,
        "id": "overfitting_analysis_section",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom scipy import stats\n\ntrain_losses = np.array(history['train_loss'])\ntest_losses = np.array(history['test_loss'])\ntrain_accs = np.array(history['train_acc'])\ntest_accs = np.array(history['test_acc'])\n\nloss_gap = test_losses - train_losses\nacc_gap = train_accs - test_accs\noverfitting_coeff = acc_gap / (train_accs + 1e-6)\n\nmetrics_df = pd.DataFrame({\n    'Epoch': np.arange(1, NUM_EPOCHS + 1),\n    'Train_Loss': train_losses,\n    'Test_Loss': test_losses,\n    'Loss_Gap': loss_gap,\n    'Train_Accuracy': train_accs,\n    'Test_Accuracy': test_accs,\n    'Accuracy_Gap': acc_gap,\n    'Overfitting_Coefficient': overfitting_coeff,\n    'Test_Precision': np.array(history['test_precision']),\n    'Test_Recall': np.array(history['test_recall']),\n    'Test_F1': np.array(history['test_f1']),\n    'Learning_Rate': np.array(history['learning_rate'])\n})\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"üìä DETAILED OVERFITTING ANALYSIS\")\nprint(\"=\"*80)\nprint(\"\\nüîç Per-Epoch Metrics:\")\nprint(metrics_df.to_string(index=False))\n\nprint(\"\\n\\nüìà OVERFITTING SUMMARY STATISTICS:\")\nprint(\"-\" * 80)\nprint(f\"\\n1Ô∏è‚É£ Loss Gap Analysis:\")\nprint(f\"   ‚Ä¢ Average Loss Gap: {loss_gap.mean():.4f}\")\nprint(f\"   ‚Ä¢ Max Loss Gap: {loss_gap.max():.4f} (Epoch {loss_gap.argmax() + 1})\")\nprint(f\"   ‚Ä¢ Min Loss Gap: {loss_gap.min():.4f} (Epoch {loss_gap.argmin() + 1})\")\nprint(f\"   ‚Ä¢ Loss Gap Trend: {'üü¢ DECREASING (Improving)' if np.polyfit(range(len(loss_gap)), loss_gap, 1)[0] < 0 else 'üî¥ INCREASING (Worsening)'}\")\n\nprint(f\"\\n2Ô∏è‚É£ Accuracy Gap Analysis:\")\nprint(f\"   ‚Ä¢ Average Acc Gap: {acc_gap.mean():.4f}\")\nprint(f\"   ‚Ä¢ Max Acc Gap: {acc_gap.max():.4f} (Epoch {acc_gap.argmax() + 1})\")\nprint(f\"   ‚Ä¢ Min Acc Gap: {acc_gap.min():.4f} (Epoch {acc_gap.argmin() + 1})\")\nprint(f\"   ‚Ä¢ Final Acc Gap: {acc_gap[-1]:.4f}\")\n\nprint(f\"\\n3Ô∏è‚É£ Overfitting Coefficient:\")\nprint(f\"   ‚Ä¢ Average Coefficient: {overfitting_coeff.mean():.4f}\")\nprint(f\"   ‚Ä¢ Max Coefficient: {overfitting_coeff.max():.4f} (Epoch {overfitting_coeff.argmax() + 1})\")\nprint(f\"   ‚Ä¢ Overfitting Level: \", end=\"\")\nif overfitting_coeff.mean() < 0.05:\n    print(\"üü¢ MINIMAL (Excellent)\")\nelif overfitting_coeff.mean() < 0.15:\n    print(\"üü° MILD (Good)\")\nelif overfitting_coeff.mean() < 0.30:\n    print(\"üü† MODERATE (Fair)\")\nelse:\n    print(\"üî¥ SEVERE (Poor)\")\n\nprint(f\"\\n4Ô∏è‚É£ Final Performance:\")\nprint(f\"   ‚Ä¢ Final Train Acc: {train_accs[-1]:.4f}\")\nprint(f\"   ‚Ä¢ Final Test Acc: {test_accs[-1]:.4f}\")\nprint(f\"   ‚Ä¢ Best Test Acc: {test_accs.max():.4f} (Epoch {test_accs.argmax() + 1})\")\nprint(f\"   ‚Ä¢ Model Status: \", end=\"\")\nif test_accs.max() >= 0.90:\n    print(\"‚úÖ‚úÖ EXCELLENT PERFORMANCE (>=90%)\")\nelif test_accs.max() >= 0.85:\n    print(\"‚úÖ VERY GOOD PERFORMANCE (>=85%)\")\nelif test_accs.max() >= 0.80:\n    print(\"‚úÖ GOOD PERFORMANCE (>=80%)\")\nelif test_accs.max() >= 0.70:\n    print(\"‚ö†Ô∏è ACCEPTABLE PERFORMANCE (>=70%)\")\nelse:\n    print(\"‚ùå POOR PERFORMANCE (<70%)\")\n\ncsv_path = os.path.join(OUTPUT_PATH, 'overfitting_metrics.csv')\nmetrics_df.to_csv(csv_path, index=False)\nprint(f\"\\nüíæ Detailed metrics saved to: {csv_path}\")\nprint(\"=\"*80)",
      "metadata": {
        "_uuid": "43bafc17-25fe-49ef-aad8-66d415afce19",
        "_cell_guid": "99da5299-f701-4bab-8fcf-74db2f40c803",
        "trusted": true,
        "collapsed": false,
        "id": "overfitting_analysis_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 1Ô∏è‚É£2Ô∏è‚É£B - üìä Visualizing the Learning Curve",
      "metadata": {
        "_uuid": "0b773055-8123-4050-a843-f95da6ee1bd8",
        "_cell_guid": "2cf52448-b909-41a4-a05d-f9544145a70d",
        "trusted": true,
        "collapsed": false,
        "id": "overfitting_viz_section",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(18, 12))\ngs = fig.add_gridspec(3, 3, hspace=0.35, wspace=0.3)\n\nfig.suptitle('üîç Advanced Overfitting Detection & Analysis', fontsize=18, fontweight='bold', y=0.995)\n\nax1 = fig.add_subplot(gs[0, 0])\nepochs = np.arange(1, NUM_EPOCHS + 1)\nax1.bar(epochs, loss_gap, color=['red' if gap > loss_gap.mean() else 'green' for gap in loss_gap], alpha=0.7)\nax1.axhline(y=loss_gap.mean(), color='red', linestyle='--', linewidth=2, label=f'Avg: {loss_gap.mean():.4f}')\nax1.set_xlabel('Epoch', fontweight='bold')\nax1.set_ylabel('Loss Gap (Test - Train)', fontweight='bold')\nax1.set_title('Loss Gap Per Epoch\\\\n(Larger = More Overfitting)', fontweight='bold')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\nax2 = fig.add_subplot(gs[0, 1])\nax2.bar(epochs, acc_gap, color='coral', alpha=0.7)\nax2.axhline(y=acc_gap.mean(), color='darkred', linestyle='--', linewidth=2, label=f'Avg: {acc_gap.mean():.4f}')\nax2.set_xlabel('Epoch', fontweight='bold')\nax2.set_ylabel('Accuracy Gap (Train - Test)', fontweight='bold')\nax2.set_title('Accuracy Gap Per Epoch\\\\n(Smaller = Better)', fontweight='bold')\nax2.legend()\nax2.grid(True, alpha=0.3)\n\nax3 = fig.add_subplot(gs[0, 2])\ncolors = ['red' if coeff > 0.15 else 'orange' if coeff > 0.05 else 'green' for coeff in overfitting_coeff]\nax3.plot(epochs, overfitting_coeff, marker='o', linewidth=2, markersize=8, color='purple')\nax3.axhline(y=0.05, color='green', linestyle=':', linewidth=2, alpha=0.5, label='Minimal (0.05)')\nax3.axhline(y=0.15, color='orange', linestyle=':', linewidth=2, alpha=0.5, label='Moderate (0.15)')\nax3.set_xlabel('Epoch', fontweight='bold')\nax3.set_ylabel('Overfitting Coefficient', fontweight='bold')\nax3.set_title('Overfitting Coefficient Trend', fontweight='bold')\nax3.legend()\nax3.grid(True, alpha=0.3)\n\nax4 = fig.add_subplot(gs[1, 0])\nax4.plot(epochs, train_losses, marker='o', label='Train Loss', linewidth=2.5, markersize=6)\nax4.plot(epochs, test_losses, marker='s', label='Test Loss', linewidth=2.5, markersize=6)\nax4.fill_between(epochs, train_losses, test_losses, alpha=0.2, color='red', label='Overfitting Gap')\nax4.set_xlabel('Epoch', fontweight='bold')\nax4.set_ylabel('Loss', fontweight='bold')\nax4.set_title('Train vs Test Loss with Gap', fontweight='bold')\nax4.legend()\nax4.grid(True, alpha=0.3)\n\nax5 = fig.add_subplot(gs[1, 1])\nax5.plot(epochs, train_accs, marker='o', label='Train Accuracy', linewidth=2.5, markersize=6, color='green')\nax5.plot(epochs, test_accs, marker='s', label='Test Accuracy', linewidth=2.5, markersize=6, color='blue')\nax5.fill_between(epochs, train_accs, test_accs, alpha=0.2, color='red')\nax5.axhline(y=0.9, color='green', linestyle=':', alpha=0.5, label='90% Target')\nax5.set_xlabel('Epoch', fontweight='bold')\nax5.set_ylabel('Accuracy', fontweight='bold')\nax5.set_title('Train vs Test Accuracy', fontweight='bold')\nax5.legend()\nax5.grid(True, alpha=0.3)\n\nax6 = fig.add_subplot(gs[1, 2])\nax6.plot(epochs, history['learning_rate'], marker='o', linewidth=2.5, markersize=6, color='purple')\nax6.set_xlabel('Epoch', fontweight='bold')\nax6.set_ylabel('Learning Rate', fontweight='bold')\nax6.set_title('Learning Rate Schedule', fontweight='bold')\nax6.grid(True, alpha=0.3)\nax6.set_yscale('log')\n\nax7 = fig.add_subplot(gs[2, :])\nheatmap_data = np.array([\n    train_losses / train_losses.max(),\n    test_losses / test_losses.max(),\n    train_accs,\n    test_accs,\n    history['test_precision'],\n    history['test_recall'],\n    history['test_f1']\n])\nim = ax7.imshow(heatmap_data, cmap='RdYlGn', aspect='auto')\nax7.set_yticks(range(7))\nax7.set_yticklabels(['Train Loss (norm)', 'Test Loss (norm)', 'Train Acc', 'Test Acc', 'Precision', 'Recall', 'F1 Score'])\nax7.set_xticks(range(NUM_EPOCHS))\nax7.set_xticklabels(epochs)\nax7.set_xlabel('Epoch', fontweight='bold')\nax7.set_title('All Metrics Heatmap (Green=Better, Red=Worse)', fontweight='bold')\nplt.colorbar(im, ax=ax7, label='Normalized Value')\n\nplt.savefig(os.path.join(OUTPUT_PATH, 'overfitting_analysis.png'), dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"‚úÖ Overfitting analysis visualization saved!\")\nprint(f\"üìÅ Saved to: {os.path.join(OUTPUT_PATH, 'overfitting_analysis.png')}\")",
      "metadata": {
        "_uuid": "089e5b2f-38cd-4c20-a996-0c66ad364a89",
        "_cell_guid": "0f02417d-b987-413d-a52d-e4062940f877",
        "trusted": true,
        "collapsed": false,
        "id": "overfitting_viz_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 1Ô∏è‚É£3Ô∏è‚É£ Final Report & Next Steps",
      "metadata": {
        "_uuid": "5cb7c12a-3d8a-4fdf-9efb-d0cb78932d1c",
        "_cell_guid": "4bf08377-762f-436b-b59c-4ab6f2869e02",
        "trusted": true,
        "collapsed": false,
        "id": "summary_section_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report, accuracy_score\n\nfinal_accuracy = accuracy_score(all_labels, all_preds)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"‚úÖ TRAINING COMPLETE: Model Ready for Deployment\")\nprint(\"=\"*70)\n\nprint(f\"\\nüìä Final Results:\")\nprint(f\"   ‚Ä¢ Final Test Accuracy: {final_accuracy*100:.2f}%\")\nprint(f\"   ‚Ä¢ Best Accuracy: {best_accuracy*100:.2f}% (Epoch {best_epoch})\")\nprint(f\"   ‚Ä¢ Number of Classes: {num_classes}\")\nprint(f\"   ‚Ä¢ Training Epochs: {NUM_EPOCHS}\")\nprint(f\"   ‚Ä¢ Target Achieved: {'‚úÖ YES! (>=90%)' if best_accuracy >= 0.9 else '‚ö†Ô∏è CLOSE (Try longer training)' if best_accuracy >= 0.85 else '‚ùå Continue training'}\")\n\nprint(f\"\\nüìã Per-Class Performance:\")\nprint(classification_report(all_labels, all_preds,\n                          target_names=train_dataset.classes,\n                          digits=4))\n\nprint(f\"\\nüìÅ Output Files (in /kaggle/working/output/):\")\noutput_files = os.listdir(OUTPUT_PATH)\nfor file in sorted(output_files):\n    file_path = os.path.join(OUTPUT_PATH, file)\n    file_size = os.path.getsize(file_path) / (1024*1024)\n    print(f\"   ‚Ä¢ {file} ({file_size:.2f} MB)\")\n\nprint(f\"\\nüöÄ Next Steps:\")\nprint(f\"   1. ‚úÖ Model is saved in /kaggle/working/output/\")\nprint(f\"   2. üì• Download files via 'Output' tab\")\nprint(f\"   3. üîç Review overfitting_metrics.csv for detailed analysis\")\nprint(f\"   4. üìä Check overfitting_analysis.png for visual insights\")\nprint(f\"   5. üß™ Test on new images\")\nprint(f\"   6. üöÄ Deploy to production\")\n\nif best_accuracy < 0.90:\n    print(f\"\\nüí° TIPS TO IMPROVE ACCURACY:\")\n    print(f\"   ‚Ä¢ Try increase epochs from {NUM_EPOCHS} to 15-20\")\n    print(f\"   ‚Ä¢ Reduce batch size to 8 for more frequent updates\")\n    print(f\"   ‚Ä¢ Check for class imbalance in your dataset\")\n    print(f\"   ‚Ä¢ Ensure high-quality training data\")\n    print(f\"   ‚Ä¢ Consider test-time augmentation\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"üéâ MedGemma is ready to help patients! Download your model from the Output tab.\")\nprint(\"MedGemma Impact Challenge Submission - January 2026\")\nprint(\"=\"*70)",
      "metadata": {
        "_uuid": "1336cff6-d371-4e32-a22e-b4d4e9fd0972",
        "_cell_guid": "59ada6f8-29d7-45d7-a05a-ab5f9fdd75cd",
        "trusted": true,
        "collapsed": false,
        "id": "summary_kaggle",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}