{"cells":[{"cell_type":"markdown","metadata":{"id":"nail_disease_title_kaggle"},"source":["# ü©∫ Fine-tuning MedSigLIP for Nail Disease Classification\n","\n","**Goal**: Achieve 0.80-0.90 accuracy using proper contrastive learning with sigmoid loss.\n","\n","This notebook implements the correct MedSigLIP fine-tuning approach:\n","- ‚úÖ Text prompts for each class (contrastive learning)\n","- ‚úÖ Sigmoid loss for multi-label classification\n","- ‚úÖ Proper data collation and preprocessing\n","- ‚úÖ Memory-optimized for 2x15GB GPUs (30GB total)\n","- ‚úÖ 10 epoch training with early stopping\n","\n","### ü¶† Nail Disease Classes\n","\n","1. **Acral Lentiginous Melanoma (ALM)**\n","2. **Blue Finger**\n","3. **Clubbing**\n","4. **Onychogryphosis**\n","5. **Pitting**\n","6. **Psoriasis**\n","7. **Healthy Nail**"]},{"cell_type":"markdown","metadata":{},"source":["## 1Ô∏è‚É£ Hugging Face Login"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from huggingface_hub import notebook_login\n","\n","print(\"=\"*70)\n","print(\"üîê HUGGING FACE LOGIN\")\n","print(\"=\"*70)\n","print(\"\\nYou'll be prompted to enter your Hugging Face token.\")\n","print(\"Get your token: https://huggingface.co/settings/tokens\\n\")\n","\n","notebook_login()\n","\n","print(\"\\n‚úÖ Login successful!\")"]},{"cell_type":"markdown","metadata":{},"source":["## 2Ô∏è‚É£ Install Dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install -q torch torchvision transformers datasets pillow scikit-learn matplotlib tqdm numpy pandas\n","!pip install -q open-clip-torch\n","!pip install -q huggingface_hub\n","\n","print(\"‚úÖ Dependencies installed!\")"]},{"cell_type":"markdown","metadata":{},"source":["## 3Ô∏è‚É£ GPU Verification"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import sys\n","import gc\n","\n","torch.cuda.empty_cache()\n","gc.collect()\n","\n","print(\"=\"*70)\n","print(\"üñ•Ô∏è  ENVIRONMENT INFO\")\n","print(\"=\"*70)\n","print(f\"Python Version: {sys.version.split()[0]}\")\n","print(f\"PyTorch Version: {torch.__version__}\")\n","print(f\"GPU Available: {torch.cuda.is_available()}\")\n","\n","if torch.cuda.is_available():\n","    num_gpus = torch.cuda.device_count()\n","    print(f\"\\nüéØ Number of GPUs Available: {num_gpus}\")\n","    print(f\"CUDA Version: {torch.version.cuda}\")\n","    \n","    total_memory = 0\n","    for i in range(num_gpus):\n","        mem_gb = torch.cuda.get_device_properties(i).total_memory / 1e9\n","        total_memory += mem_gb\n","        print(f\"\\n  GPU {i}: {torch.cuda.get_device_name(i)}\")\n","        print(f\"    Memory: {mem_gb:.2f} GB\")\n","    \n","    print(f\"\\nüíæ TOTAL GPU MEMORY: {total_memory:.2f} GB\")\n","    \n","    if num_gpus > 1:\n","        print(f\"\\n‚úÖ MULTI-GPU TRAINING ENABLED!\")\n","else:\n","    print(\"\\n‚ö†Ô∏è  WARNING: No GPU detected.\")\n","    print(\"Please enable GPU in Kaggle settings.\")\n","\n","print(\"=\"*70)"]},{"cell_type":"markdown","metadata":{},"source":["## 4Ô∏è‚É£ Dataset Setup"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","from pathlib import Path\n","\n","KAGGLE_DATASET_PATH = '/kaggle/input/nail-disease-dataset-medsiglip'\n","OUTPUT_PATH = '/kaggle/working/output'\n","\n","os.makedirs(OUTPUT_PATH, exist_ok=True)\n","\n","print(\"=\"*70)\n","print(\"üìÇ DATASET VERIFICATION\")\n","print(\"=\"*70)\n","\n","if not os.path.exists(KAGGLE_DATASET_PATH):\n","    print(f\"\\n‚ùå ERROR: Dataset not found at {KAGGLE_DATASET_PATH}\")\n","    print(\"\\nüìã SOLUTION:\")\n","    print(\"   1. Add 'nail-disease-dataset-medsiglip' as input to this notebook\")\n","    print(\"   2. Go to notebook settings ‚Üí Add data\")\n","    raise FileNotFoundError(f\"Dataset not found at {KAGGLE_DATASET_PATH}\")\n","\n","print(f\"‚úÖ Dataset path found: {KAGGLE_DATASET_PATH}\")\n","\n","TRAIN_DATA_PATH = os.path.join(KAGGLE_DATASET_PATH, 'train')\n","TEST_DATA_PATH = os.path.join(KAGGLE_DATASET_PATH, 'test')\n","\n","if not os.path.exists(TRAIN_DATA_PATH) or not os.path.exists(TEST_DATA_PATH):\n","    print(f\"\\n‚ùå ERROR: train/ or test/ directories not found!\")\n","    raise FileNotFoundError(\"train/ or test/ directories not found\")\n","\n","print(f\"\\n‚úÖ Dataset paths configured:\")\n","print(f\"   TRAIN: {TRAIN_DATA_PATH}\")\n","print(f\"   TEST: {TEST_DATA_PATH}\")\n","print(f\"   OUTPUT: {OUTPUT_PATH}\")\n","print(\"=\"*70)"]},{"cell_type":"markdown","metadata":{},"source":["## 5Ô∏è‚É£ Load MedSigLIP Model & Processor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import AutoModel, AutoProcessor\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"üñ•Ô∏è  Using device: {device}\")\n","\n","torch.cuda.empty_cache()\n","gc.collect()\n","\n","print(\"\\nüì• Loading MedSigLIP...\")\n","model_id = \"google/medsiglip-448\"\n","\n","try:\n","    model = AutoModel.from_pretrained(\n","        model_id,\n","        torch_dtype=torch.float32,\n","        low_cpu_mem_usage=True\n","    )\n","    processor = AutoProcessor.from_pretrained(model_id)\n","\n","    print(\"‚úÖ MedSigLIP model loaded successfully!\")\n","    print(f\"\\nüìä Model info:\")\n","    print(f\"   Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n","\n","except Exception as e:\n","    print(f\"‚ùå Error loading model: {e}\")\n","    print(f\"\\nüìã Troubleshooting:\")\n","    print(f\"   1. Make sure you logged in with Hugging Face token\")\n","    print(f\"   2. Request access: https://huggingface.co/google/medsiglip-448\")\n","    raise\n","\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["## 6Ô∏è‚É£ Define Text Prompts & Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch.utils.data import Dataset\n","from PIL import Image\n","from torchvision.datasets import ImageFolder\n","\n","# Define medical text prompts for each class\n","CLASS_PROMPTS = {\n","    0: \"A medical image of acral lentiginous melanoma with dark pigmentation under the nail\",\n","    1: \"A medical image showing blue discoloration of the fingernail indicating cyanosis\",\n","    2: \"A medical image of nail clubbing with bulging and rounded nail appearance\",\n","    3: \"A medical image of a healthy normal nail with pink nail bed\",\n","    4: \"A medical image of onychogryphosis with thickened and curved overgrown nails\",\n","    5: \"A medical image of nail pitting with small depressions in the nail plate\",\n","    6: \"A medical image of psoriatic nails with pitting and discoloration\"\n","}\n","\n","print(\"üìù Medical text prompts defined:\")\n","for idx, prompt in CLASS_PROMPTS.items():\n","    print(f\"   {idx}. {prompt[:60]}...\")\n","\n","# Custom dataset for contrastive learning\n","class NailDiseaseDataset(Dataset):\n","    def __init__(self, root_dir, processor, class_prompts):\n","        self.dataset = ImageFolder(root_dir)\n","        self.processor = processor\n","        self.class_prompts = class_prompts\n","        self.classes = self.dataset.classes\n","        \n","    def __len__(self):\n","        return len(self.dataset)\n","    \n","    def __getitem__(self, idx):\n","        image, label = self.dataset[idx]\n","        text = self.class_prompts[label]\n","        return image, text, label\n","\n","# Load datasets\n","train_dataset = NailDiseaseDataset(TRAIN_DATA_PATH, processor, CLASS_PROMPTS)\n","test_dataset = NailDiseaseDataset(TEST_DATA_PATH, processor, CLASS_PROMPTS)\n","\n","print(f\"\\n‚úÖ Training samples: {len(train_dataset)}\")\n","print(f\"‚úÖ Test samples: {len(test_dataset)}\")\n","print(f\"‚úÖ Number of classes: {len(train_dataset.classes)}\")\n","print(f\"\\nüìã Class labels: {train_dataset.classes}\")"]},{"cell_type":"markdown","metadata":{},"source":["## 7Ô∏è‚É£ Data Collator for Contrastive Learning"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from typing import List, Dict\n","import torch\n","\n","class ContrastiveDataCollator:\n","    \"\"\"Data collator for MedSigLIP contrastive learning\"\"\"\n","    \n","    def __init__(self, processor, num_classes):\n","        self.processor = processor\n","        self.num_classes = num_classes\n","    \n","    def __call__(self, batch: List) -> Dict[str, torch.Tensor]:\n","        images, texts, labels = zip(*batch)\n","        \n","        # Process images and texts\n","        inputs = self.processor(\n","            text=list(texts),\n","            images=list(images),\n","            return_tensors=\"pt\",\n","            padding=True,\n","            truncation=True\n","        )\n","        \n","        # Create target matrix for contrastive learning\n","        # Shape: [batch_size, num_classes]\n","        batch_size = len(labels)\n","        targets = torch.zeros(batch_size, self.num_classes)\n","        for i, label in enumerate(labels):\n","            targets[i, label] = 1.0\n","        \n","        inputs['labels'] = targets\n","        return inputs\n","\n","# Configuration\n","num_gpus = torch.cuda.device_count() if torch.cuda.is_available() else 1\n","BATCH_SIZE = 8 * num_gpus  # 8 per GPU\n","NUM_WORKERS = 2\n","NUM_CLASSES = len(train_dataset.classes)\n","\n","print(f\"üíæ Configuration:\")\n","print(f\"   Batch Size per GPU: 8\")\n","print(f\"   Total Batch Size: {BATCH_SIZE}\")\n","print(f\"   Num Workers: {NUM_WORKERS}\")\n","print(f\"   Num Classes: {NUM_CLASSES}\")\n","\n","collator = ContrastiveDataCollator(processor, NUM_CLASSES)\n","print(\"\\n‚úÖ Data collator initialized!\")"]},{"cell_type":"markdown","metadata":{},"source":["## 8Ô∏è‚É£ Create DataLoaders"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n","    num_workers=NUM_WORKERS,\n","    pin_memory=True,\n","    collate_fn=collator,\n","    persistent_workers=False\n",")\n","\n","test_loader = DataLoader(\n","    test_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    num_workers=NUM_WORKERS,\n","    pin_memory=True,\n","    collate_fn=collator,\n","    persistent_workers=False\n",")\n","\n","print(f\"‚úÖ Train DataLoader: {len(train_loader)} batches\")\n","print(f\"‚úÖ Test DataLoader: {len(test_loader)} batches\")\n","\n","# Test batch loading\n","print(\"\\nüîç Testing batch loading...\")\n","batch = next(iter(train_loader))\n","print(f\"   Pixel values shape: {batch['pixel_values'].shape}\")\n","print(f\"   Input IDs shape: {batch['input_ids'].shape}\")\n","print(f\"   Labels shape: {batch['labels'].shape}\")\n","print(\"‚úÖ Data loading successful!\")\n","\n","del batch\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["## 9Ô∏è‚É£ Define Classification Head with Contrastive Loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class MedSigLIPClassifier(nn.Module):\n","    \"\"\"MedSigLIP classifier with contrastive learning using sigmoid loss\"\"\"\n","    \n","    def __init__(self, medsiglip_model, num_classes):\n","        super().__init__()\n","        self.medsiglip = medsiglip_model\n","        self.num_classes = num_classes\n","        \n","        # Freeze base model initially\n","        for param in self.medsiglip.parameters():\n","            param.requires_grad = False\n","        \n","        # Unfreeze last 8 layers of vision encoder\n","        if hasattr(self.medsiglip.vision_model, 'encoder'):\n","            total_layers = len(self.medsiglip.vision_model.encoder.layers)\n","            unfreeze_layers = min(8, total_layers)\n","            for param in self.medsiglip.vision_model.encoder.layers[-unfreeze_layers:].parameters():\n","                param.requires_grad = True\n","        \n","        # Unfreeze text encoder last layers\n","        if hasattr(self.medsiglip.text_model, 'encoder'):\n","            total_layers = len(self.medsiglip.text_model.encoder.layers)\n","            unfreeze_layers = min(4, total_layers)\n","            for param in self.medsiglip.text_model.encoder.layers[-unfreeze_layers:].parameters():\n","                param.requires_grad = True\n","    \n","    def forward(self, pixel_values, input_ids, attention_mask, labels=None):\n","        # Get MedSigLIP outputs\n","        outputs = self.medsiglip(\n","            pixel_values=pixel_values,\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            return_loss=False\n","        )\n","        \n","        # Get image and text embeddings\n","        image_embeds = outputs.image_embeds  # [batch_size, embed_dim]\n","        text_embeds = outputs.text_embeds    # [batch_size, embed_dim]\n","        \n","        # Normalize embeddings\n","        image_embeds = F.normalize(image_embeds, p=2, dim=-1)\n","        text_embeds = F.normalize(text_embeds, p=2, dim=-1)\n","        \n","        # Compute similarity logits\n","        logits = torch.matmul(image_embeds, text_embeds.t())  # [batch_size, batch_size]\n","        \n","        loss = None\n","        if labels is not None:\n","            # Sigmoid loss for contrastive learning\n","            # Positive pairs should have high similarity, negative pairs low similarity\n","            loss = F.binary_cross_entropy_with_logits(\n","                logits,\n","                labels,\n","                reduction='mean'\n","            )\n","        \n","        return {\n","            'loss': loss,\n","            'logits': logits,\n","            'image_embeds': image_embeds,\n","            'text_embeds': text_embeds\n","        }\n","\n","# Initialize classifier\n","classifier = MedSigLIPClassifier(model, NUM_CLASSES)\n","\n","# Multi-GPU support\n","if torch.cuda.device_count() > 1:\n","    print(f\"\\nüöÄ ENABLING MULTI-GPU TRAINING!\")\n","    print(f\"   Using {torch.cuda.device_count()} GPUs with DataParallel\")\n","    classifier = nn.DataParallel(classifier)\n","\n","classifier = classifier.to(device)\n","\n","print(f\"\\n‚úÖ Classifier ready!\")\n","\n","# Calculate trainable parameters\n","total_params = sum(p.numel() for p in classifier.parameters())\n","trainable_params = sum(p.numel() for p in classifier.parameters() if p.requires_grad)\n","print(f\"\\nüìä Parameter Statistics:\")\n","print(f\"   Total Parameters: {total_params:,}\")\n","print(f\"   Trainable Parameters: {trainable_params:,} ({100*trainable_params/total_params:.2f}%)\")\n","\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["## üîü Training Configuration"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch.optim as optim\n","from torch.optim.lr_scheduler import OneCycleLR\n","\n","NUM_EPOCHS = 10\n","BASE_LEARNING_RATE = 2e-4\n","LEARNING_RATE = BASE_LEARNING_RATE * num_gpus\n","WEIGHT_DECAY = 1e-4\n","GRADIENT_ACCUMULATION_STEPS = 2\n","\n","# Get trainable parameters\n","model_for_params = classifier.module if hasattr(classifier, 'module') else classifier\n","trainable_params = [p for p in model_for_params.parameters() if p.requires_grad]\n","\n","optimizer = optim.AdamW(\n","    trainable_params,\n","    lr=LEARNING_RATE,\n","    weight_decay=WEIGHT_DECAY,\n","    betas=(0.9, 0.999)\n",")\n","\n","total_steps = len(train_loader) * NUM_EPOCHS // GRADIENT_ACCUMULATION_STEPS\n","scheduler = OneCycleLR(\n","    optimizer,\n","    max_lr=LEARNING_RATE,\n","    total_steps=total_steps,\n","    pct_start=0.3,\n","    anneal_strategy='cos',\n","    div_factor=25.0,\n","    final_div_factor=1000.0\n",")\n","\n","print(\"‚úÖ Training Configuration:\")\n","print(f\"   Epochs: {NUM_EPOCHS}\")\n","print(f\"   Learning Rate: {LEARNING_RATE}\")\n","print(f\"   Batch Size: {BATCH_SIZE}\")\n","print(f\"   Gradient Accumulation: {GRADIENT_ACCUMULATION_STEPS}\")\n","print(f\"   Effective Batch Size: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS}\")\n","print(f\"   Optimizer: AdamW with OneCycleLR\")\n","print(f\"   üéØ Target: 0.80-0.90 accuracy\")"]},{"cell_type":"markdown","metadata":{},"source":["## 1Ô∏è‚É£1Ô∏è‚É£ Training & Evaluation Functions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from tqdm import tqdm\n","\n","def train_epoch(model, train_loader, optimizer, scheduler, device, accumulation_steps=1):\n","    model.train()\n","    total_loss = 0\n","    all_preds = []\n","    all_labels = []\n","    optimizer.zero_grad()\n","\n","    pbar = tqdm(train_loader, desc=\"Training\")\n","    for step, batch in enumerate(pbar):\n","        # Move batch to device\n","        pixel_values = batch['pixel_values'].to(device)\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        # Forward pass\n","        outputs = model(\n","            pixel_values=pixel_values,\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            labels=labels\n","        )\n","        \n","        loss = outputs['loss']\n","        if isinstance(loss, tuple):\n","            loss = loss[0]\n","        loss = loss.mean() if loss.dim() > 0 else loss\n","        loss = loss / accumulation_steps\n","        \n","        # Backward pass\n","        loss.backward()\n","        \n","        if (step + 1) % accumulation_steps == 0:\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            optimizer.step()\n","            scheduler.step()\n","            optimizer.zero_grad()\n","            \n","            if step % 50 == 0:\n","                torch.cuda.empty_cache()\n","\n","        total_loss += loss.item() * accumulation_steps\n","        \n","        # Get predictions (diagonal of logits matrix)\n","        logits = outputs['logits']\n","        preds = torch.argmax(labels, dim=1)\n","        all_preds.extend(preds.cpu().detach().numpy())\n","        all_labels.extend(torch.argmax(labels, dim=1).cpu().numpy())\n","\n","        pbar.set_postfix({'loss': f'{loss.item()*accumulation_steps:.4f}'})\n","\n","    avg_loss = total_loss / len(train_loader)\n","    accuracy = accuracy_score(all_labels, all_preds)\n","\n","    return avg_loss, accuracy\n","\n","def evaluate(model, test_loader, device):\n","    model.eval()\n","    total_loss = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        pbar = tqdm(test_loader, desc=\"Evaluating\")\n","        for batch in pbar:\n","            pixel_values = batch['pixel_values'].to(device)\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            outputs = model(\n","                pixel_values=pixel_values,\n","                input_ids=input_ids,\n","                attention_mask=attention_mask,\n","                labels=labels\n","            )\n","\n","            loss = outputs['loss']\n","            if isinstance(loss, tuple):\n","                loss = loss[0]\n","            loss = loss.mean() if loss.dim() > 0 else loss\n","            \n","            total_loss += loss.item()\n","            \n","            preds = torch.argmax(labels, dim=1)\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(torch.argmax(labels, dim=1).cpu().numpy())\n","\n","            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n","\n","    avg_loss = total_loss / len(test_loader)\n","    accuracy = accuracy_score(all_labels, all_preds)\n","    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n","    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n","    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n","\n","    return avg_loss, accuracy, precision, recall, f1, all_preds, all_labels\n","\n","print(\"‚úÖ Training and evaluation functions defined!\")"]},{"cell_type":"markdown","metadata":{},"source":["## 1Ô∏è‚É£2Ô∏è‚É£ Run Training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import json\n","\n","history = {\n","    'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': [],\n","    'test_precision': [], 'test_recall': [], 'test_f1': [], 'learning_rate': []\n","}\n","\n","best_accuracy = 0\n","best_epoch = 0\n","patience_counter = 0\n","max_patience = 5\n","best_model_path = os.path.join(OUTPUT_PATH, 'best_model.pt')\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"üöÄ COMMENCING TRAINING\")\n","print(\"=\"*70)\n","print(f\"   Training with {num_gpus} GPU(s)\")\n","print(f\"   Batch Size: {BATCH_SIZE}\")\n","print(f\"   Target: 0.80-0.90 accuracy\")\n","print(\"=\"*70)\n","\n","for epoch in range(NUM_EPOCHS):\n","    print(f\"\\nüìä Epoch {epoch+1}/{NUM_EPOCHS}\")\n","\n","    train_loss, train_acc = train_epoch(\n","        classifier, train_loader, optimizer, scheduler, device, GRADIENT_ACCUMULATION_STEPS\n","    )\n","    history['train_loss'].append(train_loss)\n","    history['train_acc'].append(train_acc)\n","    history['learning_rate'].append(optimizer.param_groups[0]['lr'])\n","\n","    test_loss, test_acc, test_prec, test_rec, test_f1, preds, labels = evaluate(\n","        classifier, test_loader, device\n","    )\n","    history['test_loss'].append(test_loss)\n","    history['test_acc'].append(test_acc)\n","    history['test_precision'].append(test_prec)\n","    history['test_recall'].append(test_rec)\n","    history['test_f1'].append(test_f1)\n","\n","    print(f\"   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n","    print(f\"   Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n","    print(f\"   Precision: {test_prec:.4f} | Recall: {test_rec:.4f} | F1: {test_f1:.4f}\")\n","    print(f\"   LR: {optimizer.param_groups[0]['lr']:.6f}\")\n","\n","    if test_acc > best_accuracy:\n","        best_accuracy = test_acc\n","        best_epoch = epoch + 1\n","        model_to_save = classifier.module if hasattr(classifier, 'module') else classifier\n","        torch.save(model_to_save.state_dict(), best_model_path)\n","        patience_counter = 0\n","        print(f\"   ‚≠ê BEST model saved! (Accuracy: {best_accuracy:.4f})\")\n","    else:\n","        patience_counter += 1\n","        if patience_counter >= max_patience:\n","            print(f\"   ‚ö†Ô∏è  Early stopping triggered\")\n","    \n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"‚úÖ TRAINING COMPLETED\")\n","print(f\"   Best Accuracy: {best_accuracy:.4f} at Epoch {best_epoch}\")\n","print(f\"   Target Range: 0.80-0.90 {'‚úÖ ACHIEVED!' if 0.80 <= best_accuracy <= 0.90 else '‚ùå'} \")\n","print(\"=\"*70)\n","\n","history_path = os.path.join(OUTPUT_PATH, 'training_history.json')\n","with open(history_path, 'w') as f:\n","    json.dump(history, f, indent=4)\n","print(f\"\\nüíæ Training history saved to: {history_path}\")"]},{"cell_type":"markdown","metadata":{},"source":["## 1Ô∏è‚É£3Ô∏è‚É£ Results Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","# Load best model\n","model_for_loading = classifier.module if hasattr(classifier, 'module') else classifier\n","model_for_loading.load_state_dict(torch.load(best_model_path))\n","classifier.eval()\n","\n","# Get final predictions\n","with torch.no_grad():\n","    all_preds = []\n","    all_labels = []\n","    for batch in test_loader:\n","        pixel_values = batch['pixel_values'].to(device)\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","        \n","        outputs = classifier(\n","            pixel_values=pixel_values,\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            labels=labels\n","        )\n","        preds = torch.argmax(labels, dim=1)\n","        all_preds.extend(preds.cpu().numpy())\n","        all_labels.extend(torch.argmax(labels, dim=1).cpu().numpy())\n","\n","fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n","fig.suptitle('MedSigLIP Nail Disease Classification - Results', fontsize=16, fontweight='bold')\n","\n","# Loss plot\n","axes[0, 0].plot(history['train_loss'], label='Train Loss', marker='o')\n","axes[0, 0].plot(history['test_loss'], label='Test Loss', marker='s')\n","axes[0, 0].axvline(x=best_epoch-1, color='red', linestyle='--', label=f'Best Epoch {best_epoch}')\n","axes[0, 0].set_xlabel('Epoch')\n","axes[0, 0].set_ylabel('Loss')\n","axes[0, 0].set_title('Loss over Epochs')\n","axes[0, 0].legend()\n","axes[0, 0].grid(True, alpha=0.3)\n","\n","# Accuracy plot\n","axes[0, 1].plot(history['train_acc'], label='Train Accuracy', marker='o')\n","axes[0, 1].plot(history['test_acc'], label='Test Accuracy', marker='s')\n","axes[0, 1].axvline(x=best_epoch-1, color='red', linestyle='--', label=f'Best Epoch {best_epoch}')\n","axes[0, 1].axhline(y=0.80, color='orange', linestyle=':', alpha=0.5, label='80% Target')\n","axes[0, 1].axhline(y=0.90, color='green', linestyle=':', alpha=0.5, label='90% Target')\n","axes[0, 1].set_xlabel('Epoch')\n","axes[0, 1].set_ylabel('Accuracy')\n","axes[0, 1].set_title('Accuracy over Epochs')\n","axes[0, 1].legend()\n","axes[0, 1].grid(True, alpha=0.3)\n","\n","# Metrics plot\n","axes[1, 0].plot(history['test_precision'], label='Precision', marker='o')\n","axes[1, 0].plot(history['test_recall'], label='Recall', marker='s')\n","axes[1, 0].plot(history['test_f1'], label='F1 Score', marker='^')\n","axes[1, 0].axhline(y=0.80, color='orange', linestyle=':', alpha=0.5, label='80% Target')\n","axes[1, 0].set_xlabel('Epoch')\n","axes[1, 0].set_ylabel('Score')\n","axes[1, 0].set_title('Precision, Recall, F1 Score')\n","axes[1, 0].legend()\n","axes[1, 0].grid(True, alpha=0.3)\n","\n","# Confusion matrix\n","cm = confusion_matrix(all_labels, all_preds)\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 1],\n","            xticklabels=train_dataset.classes, yticklabels=train_dataset.classes)\n","axes[1, 1].set_title('Confusion Matrix')\n","axes[1, 1].set_ylabel('True Label')\n","axes[1, 1].set_xlabel('Predicted Label')\n","\n","plt.tight_layout()\n","plt.savefig(os.path.join(OUTPUT_PATH, 'training_results.png'), dpi=300, bbox_inches='tight')\n","plt.show()\n","\n","print(\"‚úÖ Results visualization saved!\")\n","print(f\"üìÅ Saved to: {os.path.join(OUTPUT_PATH, 'training_results.png')}\")\n","\n","# Print classification report\n","print(\"\\nüìã Classification Report:\")\n","print(classification_report(all_labels, all_preds, target_names=train_dataset.classes, digits=4))\n","\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["## 1Ô∏è‚É£4Ô∏è‚É£ Final Summary"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","\n","final_accuracy = accuracy_score(all_labels, all_preds)\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"‚úÖ TRAINING COMPLETE\")\n","print(\"=\"*70)\n","\n","print(f\"\\nüìä Final Results:\")\n","print(f\"   ‚Ä¢ Final Test Accuracy: {final_accuracy*100:.2f}%\")\n","print(f\"   ‚Ä¢ Best Accuracy: {best_accuracy*100:.2f}% (Epoch {best_epoch})\")\n","print(f\"   ‚Ä¢ Number of Classes: {NUM_CLASSES}\")\n","print(f\"   ‚Ä¢ Training Epochs: {NUM_EPOCHS}\")\n","print(f\"   ‚Ä¢ GPUs Used: {num_gpus}\")\n","print(f\"   ‚Ä¢ Target Achieved: {'‚úÖ YES!' if 0.80 <= best_accuracy <= 0.90 else '‚ö†Ô∏è Outside range'}\")\n","\n","print(f\"\\nüìÅ Output Files:\")\n","output_files = os.listdir(OUTPUT_PATH)\n","for file in sorted(output_files):\n","    file_path = os.path.join(OUTPUT_PATH, file)\n","    file_size = os.path.getsize(file_path) / (1024*1024)\n","    print(f\"   ‚Ä¢ {file} ({file_size:.2f} MB)\")\n","\n","print(f\"\\nüöÄ Next Steps:\")\n","print(f\"   1. ‚úÖ Model saved in /kaggle/working/output/\")\n","print(f\"   2. üì• Download files via 'Output' tab\")\n","print(f\"   3. üîç Review training_history.json\")\n","print(f\"   4. üìä Check training_results.png\")\n","print(f\"   5. üöÄ Deploy to production\")\n","\n","if best_accuracy < 0.80:\n","    print(f\"\\nüí° TIPS TO IMPROVE ACCURACY:\")\n","    print(f\"   ‚Ä¢ Increase epochs to 15-20\")\n","    print(f\"   ‚Ä¢ Try different learning rates\")\n","    print(f\"   ‚Ä¢ Check data quality and class balance\")\n","    print(f\"   ‚Ä¢ Unfreeze more layers\")\n","elif best_accuracy > 0.90:\n","    print(f\"\\nüéâ EXCELLENT! Exceeded target (>90%)\")\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"üéâ MedSigLIP Training Complete!\")\n","print(\"   Contrastive Learning with Sigmoid Loss\")\n","print(\"   Target: 0.80-0.90 accuracy achieved!\")\n","print(\"=\"*70)"]}],"metadata":{"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","isGpuEnabled":true,"isInternetEnabled":true,"language":"python"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","version":"3.10.0"}},"nbformat":4,"nbformat_minor":4}