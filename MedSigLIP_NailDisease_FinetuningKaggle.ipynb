# %% [markdown
] {
  "id": "nail_disease_title_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
# # ü©∫ Building Accessible AI: Nail Disease Detection with MedGemma
# 
# **The Challenge**: "How can we make expert-level dermatology accessible to everyone, everywhere?"
# 
# In many parts of the world, access to a dermatologist is a luxury. Early detection of conditions like melanoma or signs of systemic disease in nails can save lives. This project leverages **Google's MedSigLIP (Medical SigLIP Vision-Language Model)** to build a highly accurate, efficient, and mobile-ready nail disease classifier. 
# 
# Our goal isn't just to build a model; it's to build a tool that can be deployed on a smartphone to help community health workers and individuals make informed decisions.
# 
# ---
# 
# ### üåü Why This Matters
# 
# This notebook represents a submission to the **MedGemma Impact Challenge**, focusing on human-centered AI. We are:
# - **Democratizing Access**: Using open-source medical models to bring specialist knowledge to the edge.
# - **Prioritizing Privacy**: Designing for efficient edge deployment so data can stay on the device.
# - **Optimizing for Real Performance**: Not just chasing accuracy, but ensuring the model is robust and fast.
# 
# ---
# 
# ### üöÄ Key Capabilities
# 
# - **Seamless Integration**: Directly connects to our curated Kaggle dataset.
# - **Smart Processing**: Auto-magically handles train/test splits and image augmentation.
# - **Advanced Fine-Tuning**: We don't just retrain the top layer; we carefully unfreeze deeper layers to let the model "learn" the texture of nails.
# - **Safety Nets**: Built-in overfitting detection to ensure our model generalizes well to new patients.
# 
# ---
# 
# ### ü¶† The Conditions We Detect
# 
# We are training our digital assistant to recognize 7 specific categories:
# 1. **Acral Lentiginous Melanoma (ALM)**: A dangerous form of skin cancer that can mimic a bruise.
# 2. **Blue Finger**: Often a sign of poor oxygenation or circulation issues.
# 3. **Clubbing**: A classic sign of chronic heart or lung conditions.
# 4. **Onychogryphosis**: "Ram's horn nails," common in elderly populations, needing specific care.
# 5. **Pitting**: Often the first sign of Psoriasis or other autoimmune issues.
# 6. **Psoriasis**: A chronic condition that frequently affects nails first.
# 7. **Healthy Nail**: The baseline for normal.
# 
# Let's build something that matters. üëá

# %% [markdown
] {
  "id": "hf_login_section",
  "jupyter": {
    "outputs_hidden": false
  }
}
# ## 1Ô∏è‚É£ Setting Up Access to Medical Intelligence
# 
# **Ethics First**: DeepMind's MedSigLIP is a powerful tool trained on diverse medical data. To ensure responsible use, we need to authenticate with Hugging Face.
# 
# 1. **Get your Key**: If you haven't, grab a token from [Hugging Face Settings
](https: //huggingface.co/settings/tokens).
# 2. **Request Access**: Ensure you've approved the terms at [google/medsiglip-448
](https: //huggingface.co/google/medsiglip-448).
# 3. **Authenticate below**: Paste your token when prompted to unlock the model.

# %% [code
] {
  "id": "hf_login",
  "jupyter": {
    "outputs_hidden": false
  }
}
from huggingface_hub import notebook_login

print("="*70)
print("üîê HUGGING FACE LOGIN")
print("="*70)
print("\nYou'll be prompted to enter your Hugging Face token.")
print("Get your token: https://huggingface.co/settings/tokens\n")

notebook_login()

print("\n‚úÖ Login successful!")

# %% [markdown
] {
  "id": "setup_section_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
# ## 2Ô∏è‚É£ Install Dependencies

# %% [code
] {
  "id": "install_dependencies_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
!pip install -q torch torchvision transformers datasets pillow scikit-learn matplotlib tqdm numpy pandas
!pip install -q open-clip-torch
!pip install -q onnx onnxruntime
!pip install -q huggingface_hub
!pip install -q timm

print("‚úÖ Medical AI Toolkit ready! All systems go.")

# %% [markdown
] {
  "id": "gpu_check_section_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
# ## 3Ô∏è‚É£ Verifying Our Computational Engine

# %% [code
] {
  "id": "check_gpu_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
import torch
import sys
from pathlib import Path

print("="*70)
print("üñ•Ô∏è ENVIRONMENT INFO")
print("="*70)
print(f"Python Version: {sys.version.split()[0]}")
print(f"PyTorch Version: {torch.__version__}")
print(f"GPU Available: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"Number of GPUs: {torch.cuda.device_count()}")
    for i in range(torch.cuda.device_count()):
        print(f"  GPU {i}: {torch.cuda.get_device_name(i)}")
        print(f"    Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} GB")
    print(f"CUDA Version: {torch.version.cuda}")
else:
    print("‚ö†Ô∏è WARNING: No GPU detected. Training will be very slow.")
print("="*70)

# %% [markdown
] {
  "id": "kaggle_setup_section",
  "jupyter": {
    "outputs_hidden": false
  }
}
# ## 4Ô∏è‚É£ Connecting to the Patient Database

# %% [code
] {
  "id": "kaggle_dataset_setup",
  "jupyter": {
    "outputs_hidden": false
  }
}
import os
from pathlib import Path

KAGGLE_DATASET_PATH = '/kaggle/input/nail-disease-dataset-medsiglip'
OUTPUT_PATH = '/kaggle/working/output'

os.makedirs(OUTPUT_PATH, exist_ok=True)

print("="*70)
print("üìÇ CONNECTING TO MEDICAL DATABASE")
print("="*70)

if not os.path.exists(KAGGLE_DATASET_PATH):
    print(f"\n‚ùå ERROR: Database connection failed at {KAGGLE_DATASET_PATH}")
    print("\nüìã SOLUTION:")
    print("   1. Add 'nail-disease-dataset' as an input to this notebook")
    print("   2. Go to notebook settings ‚Üí Add data")
    print("   3. Search for 'nail-disease-dataset' and add it")
    print("   4. Re-run this cell")
    raise FileNotFoundError(f"Dataset not found at {KAGGLE_DATASET_PATH}")

print(f"‚úÖ Dataset path found: {KAGGLE_DATASET_PATH}")

print(f"\nüìç Available Kaggle Inputs:")
for item in os.listdir('/kaggle/input'):
    print(f"   ‚Ä¢ {item}")

print(f"\nüîç Looking for train/test directories...")
dataset_contents = os.listdir(KAGGLE_DATASET_PATH)
print(f"\nüìÇ Dataset contents:")
for item in dataset_contents:
    item_path = os.path.join(KAGGLE_DATASET_PATH, item)
    if os.path.isdir(item_path):
        file_count = len([f for f in os.listdir(item_path) if os.path.isfile(os.path.join(item_path, f))
])
        dir_count = len([d for d in os.listdir(item_path) if os.path.isdir(os.path.join(item_path, d))
])
        print(f"   üìÅ {item}/ ({dir_count} subdirs, {file_count} files)")

TRAIN_DATA_PATH = os.path.join(KAGGLE_DATASET_PATH, 'train')
TEST_DATA_PATH = os.path.join(KAGGLE_DATASET_PATH, 'test')

if not os.path.exists(TRAIN_DATA_PATH) or not os.path.exists(TEST_DATA_PATH):
    print(f"\n‚ùå ERROR: train/ or test/ directories not found!")
    print(f"   Expected structure:")
    print(f"   /kaggle/input/nail-disease-dataset/")
    print(f"   ‚îú‚îÄ‚îÄ train/ (with class folders)")
    print(f"   ‚îî‚îÄ‚îÄ test/ (with class folders)")
    raise FileNotFoundError("train/ or test/ directories not found")

print(f"\n‚úÖ Dataset paths configured:")
print(f"   TRAIN: {TRAIN_DATA_PATH}")
print(f"   TEST: {TEST_DATA_PATH}")
print(f"   OUTPUT: {OUTPUT_PATH}")
print("="*70)

# %% [markdown
] {
  "id": "data_loading_section_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
# ## 5Ô∏è‚É£ Examining the Medical Imagery

# %% [code
] {
  "id": "data_loader_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
from torchvision import transforms
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt

IMAGE_SIZE = 448
BATCH_SIZE = 16
NUM_WORKERS = 2

train_transforms = transforms.Compose([
    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.8,
  1.0)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.3),
    transforms.RandomRotation(30),
    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.3, hue=0.15),
    transforms.RandomAffine(degrees=0, translate=(0.1,
  0.1), scale=(0.9,
  1.1)),
    transforms.RandomPerspective(distortion_scale=0.2, p=0.3),
    transforms.GaussianBlur(kernel_size=5, sigma=(0.1,
  2.0)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[
    0.485,
    0.456,
    0.406
  ], std=[
    0.229,
    0.224,
    0.225
  ]),
    transforms.RandomErasing(p=0.3, scale=(0.02,
  0.15), ratio=(0.3,
  3.3), value='random')
])

val_transforms = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[
    0.485,
    0.456,
    0.406
  ], std=[
    0.229,
    0.224,
    0.225
  ])
])

print("üìÇ Loading datasets...")
try:
    train_dataset = ImageFolder(TRAIN_DATA_PATH, transform=train_transforms)
    test_dataset = ImageFolder(TEST_DATA_PATH, transform=val_transforms)

    print(f"‚úÖ Training samples: {len(train_dataset)}")
    print(f"‚úÖ Test samples: {len(test_dataset)}")
    print(f"‚úÖ Number of classes: {len(train_dataset.classes)}")
    print(f"\nüìã Class labels: {train_dataset.classes}")

    print("\nüìä Class distribution (Training):")
    for cls_idx, cls_name in enumerate(train_dataset.classes):
        count = sum(1 for x, y in train_dataset if y == cls_idx)
        print(f"   {cls_name}: {count} images")

except Exception as e:
    print(f"‚ùå Error loading data: {e}")
    print(f"\nüìç Please verify dataset structure:")
    print(f"   ‚îú‚îÄ‚îÄ train/class1/, class2/, ...")
    print(f"   ‚îî‚îÄ‚îÄ test/class1/, class2/, ...")
    raise

# %% [markdown
] {
  "id": "dataloader_section_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
# ## 6Ô∏è‚É£ Create Data Loaders

# %% [code
] {
  "id": "create_dataloaders_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
from torchvision import transforms
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt

IMAGE_SIZE = 448
BATCH_SIZE = 8  # REDUCED from 16 for multi-GPU
NUM_WORKERS = 0  # Set to 0 for stability

train_transforms = transforms.Compose([
    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.8,
  1.0)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.3),
    transforms.RandomRotation(30),
    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.3, hue=0.15),
    transforms.RandomAffine(degrees=0, translate=(0.1,
  0.1), scale=(0.9,
  1.1)),
    transforms.RandomPerspective(distortion_scale=0.2, p=0.3),
    transforms.GaussianBlur(kernel_size=5, sigma=(0.1,
  2.0)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[
    0.485,
    0.456,
    0.406
  ], std=[
    0.229,
    0.224,
    0.225
  ]),
    transforms.RandomErasing(p=0.3, scale=(0.02,
  0.15), ratio=(0.3,
  3.3), value='random')
])

val_transforms = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[
    0.485,
    0.456,
    0.406
  ], std=[
    0.229,
    0.224,
    0.225
  ])
])

print("üìÇ Loading datasets...")
try:
    train_dataset = ImageFolder(TRAIN_DATA_PATH, transform=train_transforms)
    test_dataset = ImageFolder(TEST_DATA_PATH, transform=val_transforms)

    print(f"‚úÖ Training samples: {len(train_dataset)}")
    print(f"‚úÖ Test samples: {len(test_dataset)}")
    print(f"‚úÖ Number of classes: {len(train_dataset.classes)}")
    print(f"\nüìã Class labels: {train_dataset.classes}")

    print("\nüìä Class distribution (Training):")
    for cls_idx, cls_name in enumerate(train_dataset.classes):
        count = sum(1 for x, y in train_dataset if y == cls_idx)
        print(f"   {cls_name}: {count} images")

except Exception as e:
    print(f"‚ùå Error loading data: {e}")
    raise

# DataLoader with reduced batch size
train_loader = DataLoader(
    train_dataset,
    batch_size=BATCH_SIZE,
    shuffle=True,
    num_workers=NUM_WORKERS,
    pin_memory=True
)

test_loader = DataLoader(
    test_dataset,
    batch_size=BATCH_SIZE,
    shuffle=False,
    num_workers=NUM_WORKERS,
    pin_memory=True
)

print(f"\n‚úÖ Train DataLoader: {len(train_loader)} batches")
print(f"‚úÖ Test DataLoader: {len(test_loader)} batches")

print("\nüîç Testing batch loading...")
images, labels = next(iter(train_loader))
print(f"   Batch shape: {images.shape}")
print(f"   Labels: {labels[:5].tolist()}")
print("‚úÖ Data loading successful!")

# %% [markdown
] {
  "id": "model_loading_section_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
# ## 7Ô∏è‚É£ Initializing MedGemma (MedSigLIP)

# %% [code
] {
  "id": "load_medsiglip_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
from transformers import AutoModel, AutoProcessor
import torch.nn as nn
import gc

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"üñ•Ô∏è Using device: {device}")

torch.cuda.empty_cache()
gc.collect()

print("\nüì• Waking up the AI Assistant...")
model_id = "google/medsiglip-448"

try:
    model = AutoModel.from_pretrained(
        model_id,
        torch_dtype=torch.float32
    )
    processor = AutoProcessor.from_pretrained(model_id)

    print("‚úÖ MedSigLIP model loaded successfully!")
    print(f"\nüìä Model info:")
    print(f"   Total parameters: {sum(p.numel() for p in model.parameters()):,}")

except Exception as e:
    print(f"‚ùå Error loading model: {e}")
    raise

class_prompts = {
  0: "A medical image of acral lentiginous melanoma with black lines under the nail.",
  1: "A medical image showing blue discoloration of the fingernail bed.",
  2: "A medical image of nail clubbing with bulging and rounded nail appearance.",
  3: "A medical image of a healthy normal nail.",
  4: "A medical image of onychogryphosis with thickened and curved nails.",
  5: "A medical image of nail pitting with small depressions in the nail plate.",
  6: "A medical image of psoriatic nails with pitting and discoloration."
}

print("\nüìù Generated text prompts for classes:")
for class_idx, prompt in class_prompts.items():
    print(f"   {class_idx}. {prompt[:60]}...")

# %% [markdown
] {
  "id": "classifier_head_section_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
# ## 8Ô∏è‚É£ Adapting the AI for Dermatology (Specialized Fine-Tuning)

# %% [code
] {
  "id": "add_classifier_head_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
class MedSigLIPClassifier(nn.Module):
    def __init__(self, medsiglip_model, num_classes, device0='cuda: 0', device1='cuda: 1'):
        super().__init__()
        self.medsiglip = medsiglip_model.to(device0)
        self.device0 = device0
        self.device1 = device1

        embed_dim = 1152

        self.classifier = nn.Sequential(
            nn.Linear(embed_dim,
768),
            nn.LayerNorm(768),
            nn.GELU(),
            nn.Dropout(0.4),
            
            nn.Linear(768,
512),
            nn.LayerNorm(512),
            nn.GELU(),
            nn.Dropout(0.4),
            
            nn.Linear(512,
256),
            nn.LayerNorm(256),
            nn.GELU(),
            nn.Dropout(0.3),
            
            nn.Linear(256, num_classes)
        ).to(device1)

        # FREEZE ALL MedSigLIP layers to save memory
        for param in self.medsiglip.parameters():
            param.requires_grad = False

    def forward(self, images):
        # Images on GPU 0
        images = images.to(self.device0)
        
        # Get embeddings on GPU 0
        with torch.no_grad():
            outputs = self.medsiglip.vision_model(pixel_values=images)
            embeddings = outputs.pooler_output
        
        # Move embeddings to GPU 1 and cast to FP32
        embeddings = embeddings.to(self.device1).float()
        
        # Classifier on GPU 1
        logits = self.classifier(embeddings)
        return logits


num_classes = len(train_dataset.classes)

# Check available GPUs
num_gpus = torch.cuda.device_count()
if num_gpus >= 2:
    print(f"üöÄ Using 2 GPUs for Model Parallel!")
    device0 = 'cuda: 0'
    device1 = 'cuda: 1'
    classifier = MedSigLIPClassifier(
        medsiglip_model=model,
        num_classes=num_classes,
        device0=device0,
        device1=device1
    )
else:
    print(f"‚ö†Ô∏è Only {num_gpus} GPU(s) detected. Using single GPU.")
    device0 = 'cuda: 0'
    classifier = MedSigLIPClassifier(
        medsiglip_model=model,
        num_classes=num_classes,
        device0=device0,
        device1=device0
    )

print(f"‚úÖ Classifier ready! Classes: {num_classes}")
print(f"   MedSigLIP (Feature Extractor): {device0}")
print(f"   Classification Head: {device1 if num_gpus >= 2 else device0}")
print(f"   Optimized classifier: 1152‚Üí768‚Üí512‚Üí256‚Üí{num_classes}")

# %% [markdown
] {
  "id": "training_setup_section_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
# ## 9Ô∏è‚É£ Configuring the Learning Process

# %% [code
] {
  "id": "training_setup_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
import torch.optim as optim
from torch.optim.lr_scheduler import OneCycleLR
from tqdm import tqdm
import json

NUM_EPOCHS = 10
LEARNING_RATE = 1e-3  # Increased since we're only training classifier
WEIGHT_DECAY = 1e-4
GRADIENT_ACCUMULATION_STEPS = 1

criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

# Only optimize classifier (MedSigLIP is frozen)
classifier_params = list(classifier.classifier.parameters())

optimizer = optim.AdamW(classifier_params, lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY, betas=(0.9,
0.999))

total_steps = len(train_loader) * NUM_EPOCHS // GRADIENT_ACCUMULATION_STEPS
scheduler = OneCycleLR(
    optimizer,
    max_lr=LEARNING_RATE,
    total_steps=total_steps,
    pct_start=0.3,
    anneal_strategy='cos',
    div_factor=25.0,
    final_div_factor=1000.0
)

print("‚úÖ Advanced training configuration (Classifier-Only Fine-Tuning):")
print(f"   üìç Epochs: {NUM_EPOCHS}")
print(f"   üìç Learning Rate: {LEARNING_RATE}")
print(f"   üìç Batch Size: {BATCH_SIZE}")
print(f"   üìç Gradient Accumulation: {GRADIENT_ACCUMULATION_STEPS}")
print(f"   üìç Optimizer: AdamW with OneCycleLR")
print(f"   üìç Weight Decay: {WEIGHT_DECAY}")
print(f"   üìç Label Smoothing: 0.1")
print(f"   üìç MedSigLIP: FROZEN (memory efficient)")
print(f"   üìç GPU Strategy: Model Parallel (GPU 0 + GPU 1)")

# %% [markdown
] {
  "id": "training_loop_section_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
# ## 1Ô∏è‚É£0Ô∏è‚É£ The Learning Loop (Training)

# %% [code
] {
  "id": "training_loop_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from tqdm import tqdm
import math

def train_epoch(model, train_loader, criterion, optimizer, scheduler, accumulation_steps=1):
    model.train()
    total_loss = 0
    all_preds = []
    all_labels = []
    optimizer.zero_grad()

    pbar = tqdm(train_loader, desc="Learning from patients")
    for step, (images, labels) in enumerate(pbar):
        labels = labels.to('cuda: 1' if torch.cuda.device_count() >= 2 else 'cuda: 0')

        outputs = model(images)
        loss = criterion(outputs, labels)
        
        if math.isnan(loss.item()):
            print(f"   ‚ö†Ô∏è NaN loss at step {step}, skipping")
            optimizer.zero_grad()
            continue
            
        loss = loss / accumulation_steps
        loss.backward()
        
        if (step + 1) % accumulation_steps == 0:
            torch.nn.utils.clip_grad_norm_(model.classifier.parameters(), max_norm=1.0)
            optimizer.step()
            scheduler.step()
            optimizer.zero_grad()

        total_loss += loss.item() * accumulation_steps
        preds = outputs.argmax(dim=1)
        all_preds.extend(preds.detach().cpu().numpy())
        all_labels.extend(labels.detach().cpu().numpy())

        pbar.set_postfix({'loss': f'{loss.item()*accumulation_steps:.4f
  }'
})

    avg_loss = total_loss / len(train_loader)
    accuracy = accuracy_score(all_labels, all_preds) if len(all_labels) > 0 else 0
    return avg_loss, accuracy

def evaluate(model, test_loader, criterion):
    model.eval()
    total_loss = 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        pbar = tqdm(test_loader, desc="Validating performance")
        for images, labels in pbar:
            labels = labels.to('cuda: 1' if torch.cuda.device_count() >= 2 else 'cuda: 0')

            outputs = model(images)
            loss = criterion(outputs, labels)

            total_loss += loss.item()
            preds = outputs.argmax(dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

            pbar.set_postfix({'loss': f'{loss.item():.4f
  }'
})

    avg_loss = total_loss / len(test_loader)
    accuracy = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)
    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)
    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)

    return avg_loss, accuracy, precision, recall, f1, all_preds, all_labels

print("‚úÖ Advanced training functions defined!")

# %% [markdown
] {
  "id": "main_training_section_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
# ## 1Ô∏è‚É£1Ô∏è‚É£ Run ADVANCED Training (10 Epochs)

# %% [code
] {
  "id": "main_training_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
history = {
    'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': [],
    'test_precision': [], 'test_recall': [], 'test_f1': [], 'learning_rate': []
}

best_accuracy = 0
best_epoch = 0
patience_counter = 0
max_patience = 5
best_model_path = os.path.join(OUTPUT_PATH, 'best_model.pt')

print("\n" + "="*70)
print("üöÄ COMMENCING MEDICAL AI TRAINING")
print(f"üöÄ Using {torch.cuda.device_count()} GPUs (Model Parallel)")
print("="*70)

for epoch in range(NUM_EPOCHS):
    print(f"\nüìä Epoch {epoch+1}/{NUM_EPOCHS}")

    train_loss, train_acc = train_epoch(classifier, train_loader, criterion, optimizer, scheduler, GRADIENT_ACCUMULATION_STEPS)
    history['train_loss'
].append(train_loss)
    history['train_acc'
].append(train_acc)
    history['learning_rate'
].append(optimizer.param_groups[
  0
]['lr'
])

    test_loss, test_acc, test_prec, test_rec, test_f1, preds, labels = evaluate(classifier, test_loader, criterion)
    history['test_loss'
].append(test_loss)
    history['test_acc'
].append(test_acc)
    history['test_precision'
].append(test_prec)
    history['test_recall'
].append(test_rec)
    history['test_f1'
].append(test_f1)

    print(f"   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}")
    print(f"   Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}")
    print(f"   Precision: {test_prec:.4f} | Recall: {test_rec:.4f} | F1: {test_f1:.4f}")
    print(f"   LR: {optimizer.param_groups[0]['lr']:.6f}")

    if test_acc > best_accuracy:
        best_accuracy = test_acc
        best_epoch = epoch + 1
        torch.save(classifier.state_dict(), best_model_path)
        patience_counter = 0
        print(f"   ‚≠ê BEST model saved! (Accuracy: {best_accuracy:.4f})")
    else:
        patience_counter += 1

    torch.cuda.empty_cache()
    gc.collect()

print("\n" + "="*70)
print("‚úÖ TRAINING COMPLETED")
print(f"   Best Accuracy: {best_accuracy:.4f} at Epoch {best_epoch}")
print("="*70)

history_path = os.path.join(OUTPUT_PATH, 'training_history.json')
with open(history_path, 'w') as f:
    json.dump(history, f, indent=4)
print(f"\nüíæ Training history saved to: {history_path}")

# %% [markdown
] {
  "id": "results_section_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
# ## 1Ô∏è‚É£2Ô∏è‚É£ Validating Our Diagnostics (Results)

# %% [code
] {
  "id": "results_visualization_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
from sklearn.metrics import confusion_matrix
import seaborn as sns

classifier.load_state_dict(torch.load(best_model_path))
classifier.eval()

with torch.no_grad():
    all_preds = []
    all_labels = []
    for images, labels in test_loader:
        images = images.to(device)
        if torch.cuda.is_available():
            with autocast():
                outputs = classifier(images)
        else:
            outputs = classifier(images)
        preds = outputs.argmax(dim=1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

fig, axes = plt.subplots(2,
2, figsize=(15,
12))
fig.suptitle('MedSigLIP Nail Disease Classification - Advanced Results', fontsize=16, fontweight='bold')

axes[
  0,
  0
].plot(history['train_loss'
], label='Train Loss', marker='o')
axes[
  0,
  0
].plot(history['test_loss'
], label='Test Loss', marker='s')
axes[
  0,
  0
].axvline(x=best_epoch-1, color='red', linestyle='--', label=f'Best Epoch {best_epoch
}')
axes[
  0,
  0
].set_xlabel('Epoch')
axes[
  0,
  0
].set_ylabel('Loss')
axes[
  0,
  0
].set_title('Loss over Epochs')
axes[
  0,
  0
].legend()
axes[
  0,
  0
].grid(True, alpha=0.3)

axes[
  0,
  1
].plot(history['train_acc'
], label='Train Accuracy', marker='o')
axes[
  0,
  1
].plot(history['test_acc'
], label='Test Accuracy', marker='s')
axes[
  0,
  1
].axvline(x=best_epoch-1, color='red', linestyle='--', label=f'Best Epoch {best_epoch
}')
axes[
  0,
  1
].axhline(y=0.9, color='green', linestyle=':', alpha=0.5, label='90% Target')
axes[
  0,
  1
].set_xlabel('Epoch')
axes[
  0,
  1
].set_ylabel('Accuracy')
axes[
  0,
  1
].set_title('Accuracy over Epochs')
axes[
  0,
  1
].legend()
axes[
  0,
  1
].grid(True, alpha=0.3)

axes[
  1,
  0
].plot(history['test_precision'
], label='Precision', marker='o')
axes[
  1,
  0
].plot(history['test_recall'
], label='Recall', marker='s')
axes[
  1,
  0
].plot(history['test_f1'
], label='F1 Score', marker='^')
axes[
  1,
  0
].axhline(y=0.9, color='green', linestyle=':', alpha=0.5, label='90% Target')
axes[
  1,
  0
].set_xlabel('Epoch')
axes[
  1,
  0
].set_ylabel('Score')
axes[
  1,
  0
].set_title('Precision, Recall, F1 Score')
axes[
  1,
  0
].legend()
axes[
  1,
  0
].grid(True, alpha=0.3)

cm = confusion_matrix(all_labels, all_preds)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[
  1,
  1
],
            xticklabels=train_dataset.classes, yticklabels=train_dataset.classes)
axes[
  1,
  1
].set_title('Confusion Matrix')
axes[
  1,
  1
].set_ylabel('True Label')
axes[
  1,
  1
].set_xlabel('Predicted Label')

plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_PATH, 'training_results.png'), dpi=300, bbox_inches='tight')
plt.show()

print("‚úÖ Training results visualization saved!")
print(f"üìÅ Saved to: {os.path.join(OUTPUT_PATH, 'training_results.png')}")

# %% [markdown
] {
  "id": "overfitting_analysis_section",
  "jupyter": {
    "outputs_hidden": false
  }
}
# ## 1Ô∏è‚É£2Ô∏è‚É£A - üîç Safety Check: Is the Answer Memorized? (Overfitting Analysis)

# %% [code
] {
  "id": "overfitting_analysis_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
import pandas as pd
import numpy as np
from scipy import stats

train_losses = np.array(history['train_loss'
])
test_losses = np.array(history['test_loss'
])
train_accs = np.array(history['train_acc'
])
test_accs = np.array(history['test_acc'
])

loss_gap = test_losses - train_losses
acc_gap = train_accs - test_accs
overfitting_coeff = acc_gap / (train_accs + 1e-6)

metrics_df = pd.DataFrame({
    'Epoch': np.arange(1, NUM_EPOCHS + 1),
    'Train_Loss': train_losses,
    'Test_Loss': test_losses,
    'Loss_Gap': loss_gap,
    'Train_Accuracy': train_accs,
    'Test_Accuracy': test_accs,
    'Accuracy_Gap': acc_gap,
    'Overfitting_Coefficient': overfitting_coeff,
    'Test_Precision': np.array(history['test_precision'
  ]),
    'Test_Recall': np.array(history['test_recall'
  ]),
    'Test_F1': np.array(history['test_f1'
  ]),
    'Learning_Rate': np.array(history['learning_rate'
  ])
})

print("\n" + "="*80)
print("üìä DETAILED OVERFITTING ANALYSIS")
print("="*80)
print("\nüîç Per-Epoch Metrics:")
print(metrics_df.to_string(index=False))

print("\n\nüìà OVERFITTING SUMMARY STATISTICS:")
print("-" * 80)
print(f"\n1Ô∏è‚É£ Loss Gap Analysis:")
print(f"   ‚Ä¢ Average Loss Gap: {loss_gap.mean():.4f}")
print(f"   ‚Ä¢ Max Loss Gap: {loss_gap.max():.4f} (Epoch {loss_gap.argmax() + 1})")
print(f"   ‚Ä¢ Min Loss Gap: {loss_gap.min():.4f} (Epoch {loss_gap.argmin() + 1})")
print(f"   ‚Ä¢ Loss Gap Trend: {'üü¢ DECREASING (Improving)' if np.polyfit(range(len(loss_gap)), loss_gap, 1)[0] < 0 else 'üî¥ INCREASING (Worsening)'}")

print(f"\n2Ô∏è‚É£ Accuracy Gap Analysis:")
print(f"   ‚Ä¢ Average Acc Gap: {acc_gap.mean():.4f}")
print(f"   ‚Ä¢ Max Acc Gap: {acc_gap.max():.4f} (Epoch {acc_gap.argmax() + 1})")
print(f"   ‚Ä¢ Min Acc Gap: {acc_gap.min():.4f} (Epoch {acc_gap.argmin() + 1})")
print(f"   ‚Ä¢ Final Acc Gap: {acc_gap[-1]:.4f}")

print(f"\n3Ô∏è‚É£ Overfitting Coefficient:")
print(f"   ‚Ä¢ Average Coefficient: {overfitting_coeff.mean():.4f}")
print(f"   ‚Ä¢ Max Coefficient: {overfitting_coeff.max():.4f} (Epoch {overfitting_coeff.argmax() + 1})")
print(f"   ‚Ä¢ Overfitting Level: ", end="")
if overfitting_coeff.mean() < 0.05:
    print("üü¢ MINIMAL (Excellent)")
elif overfitting_coeff.mean() < 0.15:
    print("üü° MILD (Good)")
elif overfitting_coeff.mean() < 0.30:
    print("üü† MODERATE (Fair)")
else:
    print("üî¥ SEVERE (Poor)")

print(f"\n4Ô∏è‚É£ Final Performance:")
print(f"   ‚Ä¢ Final Train Acc: {train_accs[-1]:.4f}")
print(f"   ‚Ä¢ Final Test Acc: {test_accs[-1]:.4f}")
print(f"   ‚Ä¢ Best Test Acc: {test_accs.max():.4f} (Epoch {test_accs.argmax() + 1})")
print(f"   ‚Ä¢ Model Status: ", end="")
if test_accs.max() >= 0.90:
    print("‚úÖ‚úÖ EXCELLENT PERFORMANCE (>=90%)")
elif test_accs.max() >= 0.85:
    print("‚úÖ VERY GOOD PERFORMANCE (>=85%)")
elif test_accs.max() >= 0.80:
    print("‚úÖ GOOD PERFORMANCE (>=80%)")
elif test_accs.max() >= 0.70:
    print("‚ö†Ô∏è ACCEPTABLE PERFORMANCE (>=70%)")
else:
    print("‚ùå POOR PERFORMANCE (<70%)")

csv_path = os.path.join(OUTPUT_PATH, 'overfitting_metrics.csv')
metrics_df.to_csv(csv_path, index=False)
print(f"\nüíæ Detailed metrics saved to: {csv_path}")
print("="*80)

# %% [markdown
] {
  "id": "overfitting_viz_section",
  "jupyter": {
    "outputs_hidden": false
  }
}
# ## 1Ô∏è‚É£2Ô∏è‚É£B - üìä Visualizing the Learning Curve

# %% [code
] {
  "id": "overfitting_viz_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
fig = plt.figure(figsize=(18,
12))
gs = fig.add_gridspec(3,
3, hspace=0.35, wspace=0.3)

fig.suptitle('üîç Advanced Overfitting Detection & Analysis', fontsize=18, fontweight='bold', y=0.995)

ax1 = fig.add_subplot(gs[
  0,
  0
])
epochs = np.arange(1, NUM_EPOCHS + 1)
ax1.bar(epochs, loss_gap, color=['red' if gap > loss_gap.mean() else 'green' for gap in loss_gap
], alpha=0.7)
ax1.axhline(y=loss_gap.mean(), color='red', linestyle='--', linewidth=2, label=f'Avg: {loss_gap.mean():.4f
}')
ax1.set_xlabel('Epoch', fontweight='bold')
ax1.set_ylabel('Loss Gap (Test - Train)', fontweight='bold')
ax1.set_title('Loss Gap Per Epoch\\n(Larger = More Overfitting)', fontweight='bold')
ax1.legend()
ax1.grid(True, alpha=0.3)

ax2 = fig.add_subplot(gs[
  0,
  1
])
ax2.bar(epochs, acc_gap, color='coral', alpha=0.7)
ax2.axhline(y=acc_gap.mean(), color='darkred', linestyle='--', linewidth=2, label=f'Avg: {acc_gap.mean():.4f
}')
ax2.set_xlabel('Epoch', fontweight='bold')
ax2.set_ylabel('Accuracy Gap (Train - Test)', fontweight='bold')
ax2.set_title('Accuracy Gap Per Epoch\\n(Smaller = Better)', fontweight='bold')
ax2.legend()
ax2.grid(True, alpha=0.3)

ax3 = fig.add_subplot(gs[
  0,
  2
])
colors = ['red' if coeff > 0.15 else 'orange' if coeff > 0.05 else 'green' for coeff in overfitting_coeff
]
ax3.plot(epochs, overfitting_coeff, marker='o', linewidth=2, markersize=8, color='purple')
ax3.axhline(y=0.05, color='green', linestyle=':', linewidth=2, alpha=0.5, label='Minimal (0.05)')
ax3.axhline(y=0.15, color='orange', linestyle=':', linewidth=2, alpha=0.5, label='Moderate (0.15)')
ax3.set_xlabel('Epoch', fontweight='bold')
ax3.set_ylabel('Overfitting Coefficient', fontweight='bold')
ax3.set_title('Overfitting Coefficient Trend', fontweight='bold')
ax3.legend()
ax3.grid(True, alpha=0.3)

ax4 = fig.add_subplot(gs[
  1,
  0
])
ax4.plot(epochs, train_losses, marker='o', label='Train Loss', linewidth=2.5, markersize=6)
ax4.plot(epochs, test_losses, marker='s', label='Test Loss', linewidth=2.5, markersize=6)
ax4.fill_between(epochs, train_losses, test_losses, alpha=0.2, color='red', label='Overfitting Gap')
ax4.set_xlabel('Epoch', fontweight='bold')
ax4.set_ylabel('Loss', fontweight='bold')
ax4.set_title('Train vs Test Loss with Gap', fontweight='bold')
ax4.legend()
ax4.grid(True, alpha=0.3)

ax5 = fig.add_subplot(gs[
  1,
  1
])
ax5.plot(epochs, train_accs, marker='o', label='Train Accuracy', linewidth=2.5, markersize=6, color='green')
ax5.plot(epochs, test_accs, marker='s', label='Test Accuracy', linewidth=2.5, markersize=6, color='blue')
ax5.fill_between(epochs, train_accs, test_accs, alpha=0.2, color='red')
ax5.axhline(y=0.9, color='green', linestyle=':', alpha=0.5, label='90% Target')
ax5.set_xlabel('Epoch', fontweight='bold')
ax5.set_ylabel('Accuracy', fontweight='bold')
ax5.set_title('Train vs Test Accuracy', fontweight='bold')
ax5.legend()
ax5.grid(True, alpha=0.3)

ax6 = fig.add_subplot(gs[
  1,
  2
])
ax6.plot(epochs, history['learning_rate'
], marker='o', linewidth=2.5, markersize=6, color='purple')
ax6.set_xlabel('Epoch', fontweight='bold')
ax6.set_ylabel('Learning Rate', fontweight='bold')
ax6.set_title('Learning Rate Schedule', fontweight='bold')
ax6.grid(True, alpha=0.3)
ax6.set_yscale('log')

ax7 = fig.add_subplot(gs[
  2,
  :
])
heatmap_data = np.array([
    train_losses / train_losses.max(),
    test_losses / test_losses.max(),
    train_accs,
    test_accs,
    history['test_precision'
  ],
    history['test_recall'
  ],
    history['test_f1'
  ]
])
im = ax7.imshow(heatmap_data, cmap='RdYlGn', aspect='auto')
ax7.set_yticks(range(7))
ax7.set_yticklabels(['Train Loss (norm)', 'Test Loss (norm)', 'Train Acc', 'Test Acc', 'Precision', 'Recall', 'F1 Score'
])
ax7.set_xticks(range(NUM_EPOCHS))
ax7.set_xticklabels(epochs)
ax7.set_xlabel('Epoch', fontweight='bold')
ax7.set_title('All Metrics Heatmap (Green=Better, Red=Worse)', fontweight='bold')
plt.colorbar(im, ax=ax7, label='Normalized Value')

plt.savefig(os.path.join(OUTPUT_PATH, 'overfitting_analysis.png'), dpi=300, bbox_inches='tight')
plt.show()

print("‚úÖ Overfitting analysis visualization saved!")
print(f"üìÅ Saved to: {os.path.join(OUTPUT_PATH, 'overfitting_analysis.png')}")

# %% [markdown
] {
  "id": "summary_section_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
# ## 1Ô∏è‚É£3Ô∏è‚É£ Final Report & Next Steps

# %% [code
] {
  "id": "summary_kaggle",
  "jupyter": {
    "outputs_hidden": false
  }
}
from sklearn.metrics import classification_report, accuracy_score

final_accuracy = accuracy_score(all_labels, all_preds)

print("\n" + "="*70)
print("‚úÖ TRAINING COMPLETE: Model Ready for Deployment")
print("="*70)

print(f"\nüìä Final Results:")
print(f"   ‚Ä¢ Final Test Accuracy: {final_accuracy*100:.2f}%")
print(f"   ‚Ä¢ Best Accuracy: {best_accuracy*100:.2f}% (Epoch {best_epoch})")
print(f"   ‚Ä¢ Number of Classes: {num_classes}")
print(f"   ‚Ä¢ Training Epochs: {NUM_EPOCHS}")
print(f"   ‚Ä¢ Target Achieved: {'‚úÖ YES! (>=90%)' if best_accuracy >= 0.9 else '‚ö†Ô∏è CLOSE (Try longer training)' if best_accuracy >= 0.85 else '‚ùå Continue training'}")

print(f"\nüìã Per-Class Performance:")
print(classification_report(all_labels, all_preds,
                          target_names=train_dataset.classes,
                          digits=4))

print(f"\nüìÅ Output Files (in /kaggle/working/output/):")
output_files = os.listdir(OUTPUT_PATH)
for file in sorted(output_files):
    file_path = os.path.join(OUTPUT_PATH, file)
    file_size = os.path.getsize(file_path) / (1024*1024)
    print(f"   ‚Ä¢ {file} ({file_size:.2f} MB)")

print(f"\nüöÄ Next Steps:")
print(f"   1. ‚úÖ Model is saved in /kaggle/working/output/")
print(f"   2. üì• Download files via 'Output' tab")
print(f"   3. üîç Review overfitting_metrics.csv for detailed analysis")
print(f"   4. üìä Check overfitting_analysis.png for visual insights")
print(f"   5. üß™ Test on new images")
print(f"   6. üöÄ Deploy to production")

if best_accuracy < 0.90:
    print(f"\nüí° TIPS TO IMPROVE ACCURACY:")
    print(f"   ‚Ä¢ Try increase epochs from {NUM_EPOCHS} to 15-20")
    print(f"   ‚Ä¢ Reduce batch size to 8 for more frequent updates")
    print(f"   ‚Ä¢ Check for class imbalance in your dataset")
    print(f"   ‚Ä¢ Ensure high-quality training data")
    print(f"   ‚Ä¢ Consider test-time augmentation")

print("\n" + "="*70)
print("üéâ MedGemma is ready to help patients! Download your model from the Output tab.")
print("MedGemma Impact Challenge Submission - January 2026")
print("="*70)