{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "MedSigLIP_NailDisease_FinetuningKaggle"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 14664982,
          "sourceType": "datasetVersion",
          "datasetId": 9368689
        }
      ],
      "dockerImageVersionId": 31260,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "cyW6GHJiZ2cJ"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "isumenuka_nail_disease_dataset_medsiglip_path = kagglehub.dataset_download('isumenuka/nail-disease-dataset-medsiglip')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "BE6F7EzRZ2cO"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üè• MedSigLIP Fine-tuning for Nail Disease Classification on Kaggle\n",
        "\n",
        "**Project**: Nail Disease Detection & Classification  \n",
        "**Model**: Google's MedSigLIP (Medical SigLIP Vision-Language Model)  \n",
        "**Platform**: Kaggle Notebooks  \n",
        "**Dataset**: Nail disease images from Kaggle Dataset (7 categories)  \n",
        "**Created**: January 2026  \n",
        "**License**: Apache 2.0\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ú® Key Features\n",
        "\n",
        "- ‚úÖ Direct Kaggle dataset integration (`/kaggle/input/nail-disease-dataset`)\n",
        "- ‚úÖ No ZIP file extraction required\n",
        "- ‚úÖ Auto-detects train/test directories\n",
        "- ‚úÖ GPU optimization (P100 available)\n",
        "- ‚úÖ Comprehensive error handling\n",
        "- ‚úÖ Real-time training visualization\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Expected Dataset Structure\n",
        "\n",
        "```\n",
        "/kaggle/input/nail-disease-dataset/\n",
        "‚îú‚îÄ‚îÄ train/                    (80% - ~5,300 images)\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ Acral_Lentiginous_Melanoma/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ blue_finger/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ clubbing/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ Healthy_Nail/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ Onychogryphosis/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ pitting/\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ psoriasis/\n",
        "‚îî‚îÄ‚îÄ test/                     (20% - ~1,350 images)\n",
        "    ‚îú‚îÄ‚îÄ Acral_Lentiginous_Melanoma/\n",
        "    ‚îú‚îÄ‚îÄ blue_finger/\n",
        "    ‚îú‚îÄ‚îÄ clubbing/\n",
        "    ‚îú‚îÄ‚îÄ Healthy_Nail/\n",
        "    ‚îú‚îÄ‚îÄ Onychogryphosis/\n",
        "    ‚îú‚îÄ‚îÄ pitting/\n",
        "    ‚îî‚îÄ‚îÄ psoriasis/\n",
        "```\n",
        "\n",
        "## üéØ Nail Disease Categories\n",
        "\n",
        "1. **Acral Lentiginous Melanoma (ALM)** - Black/brown lines under nail\n",
        "2. **Blue Finger** - Blue discoloration of nail bed\n",
        "3. **Clubbing** - Bulging, rounded nail appearance\n",
        "4. **Healthy Nail** - Normal reference\n",
        "5. **Onychogryphosis** - Thickened, curved nails\n",
        "6. **Pitting** - Small depressions in nail plate\n",
        "7. **Psoriasis** - Nail pitting and discoloration from psoriasis\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Expected Outcomes\n",
        "\n",
        "- **Training Time**: 30-40 minutes (P100 GPU)\n",
        "- **Expected Accuracy**: 88-95% on test set\n",
        "- **Model Size**: ~420 MB (compressed)\n",
        "- **Inference Time**: <500ms per image\n",
        "- **Mobile Compatible**: Yes (TensorFlow Lite conversion included)\n"
      ],
      "metadata": {
        "id": "nail_disease_title_kaggle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£ Hugging Face Login (IMPORTANT!)\n",
        "\n",
        "**Run this first!** You need a Hugging Face token to access MedSigLIP.\n",
        "\n",
        "1. Get token: https://huggingface.co/settings/tokens\n",
        "2. Request access: https://huggingface.co/google/medsiglip-448\n",
        "3. Run cell below and paste your token when prompted"
      ],
      "metadata": {
        "id": "hf_login_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üîê HUGGING FACE LOGIN\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nYou'll be prompted to enter your Hugging Face token.\")\n",
        "print(\"Get your token: https://huggingface.co/settings/tokens\\n\")\n",
        "\n",
        "notebook_login()\n",
        "\n",
        "print(\"\\n‚úÖ Login successful!\")"
      ],
      "metadata": {
        "id": "hf_login",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T15:01:34.04601Z",
          "iopub.execute_input": "2026-01-29T15:01:34.046667Z",
          "iopub.status.idle": "2026-01-29T15:01:34.064873Z",
          "shell.execute_reply.started": "2026-01-29T15:01:34.046638Z",
          "shell.execute_reply": "2026-01-29T15:01:34.063855Z"
        },
        "outputId": "97ae00ac-fa9f-4a44-d5e7-0857bcc4d2a2",
        "colab": {
          "referenced_widgets": [
            "701bfa007eba42f7a9239848f66091fc"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "======================================================================\nüîê HUGGING FACE LOGIN\n======================================================================\n\nYou'll be prompted to enter your Hugging Face token.\nGet your token: https://huggingface.co/settings/tokens\n\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "701bfa007eba42f7a9239848f66091fc"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\n‚úÖ Login successful!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2Ô∏è‚É£ Install Dependencies"
      ],
      "metadata": {
        "id": "setup_section_kaggle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch torchvision transformers datasets pillow scikit-learn matplotlib tqdm numpy pandas\n",
        "!pip install -q open-clip-torch\n",
        "!pip install -q onnx onnxruntime\n",
        "!pip install -q huggingface_hub\n",
        "\n",
        "print(\"‚úÖ All dependencies installed successfully!\")"
      ],
      "metadata": {
        "id": "install_dependencies_kaggle",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T15:01:34.066286Z",
          "iopub.execute_input": "2026-01-29T15:01:34.066609Z",
          "iopub.status.idle": "2026-01-29T15:01:47.51876Z",
          "shell.execute_reply.started": "2026-01-29T15:01:34.066571Z",
          "shell.execute_reply": "2026-01-29T15:01:47.517836Z"
        },
        "outputId": "080f7bfb-c17d-4002-e5a2-e0ad95e13ae4"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "‚úÖ All dependencies installed successfully!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3Ô∏è‚É£ Check GPU & Environment"
      ],
      "metadata": {
        "id": "gpu_check_section_kaggle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üñ•Ô∏è  ENVIRONMENT INFO\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Python Version: {sys.version.split()[0]}\")\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  WARNING: No GPU detected. Training will be very slow.\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "check_gpu_kaggle",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T15:01:47.520218Z",
          "iopub.execute_input": "2026-01-29T15:01:47.520631Z",
          "iopub.status.idle": "2026-01-29T15:01:47.526976Z",
          "shell.execute_reply.started": "2026-01-29T15:01:47.5206Z",
          "shell.execute_reply": "2026-01-29T15:01:47.526353Z"
        },
        "outputId": "39a67506-b3c6-40db-ce6e-a8e2b3e8382c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "======================================================================\nüñ•Ô∏è  ENVIRONMENT INFO\n======================================================================\nPython Version: 3.12.12\nPyTorch Version: 2.8.0+cu126\nGPU Available: True\nGPU Device: Tesla T4\nGPU Memory: 15.83 GB\nCUDA Version: 12.6\n======================================================================\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4Ô∏è‚É£ Setup Kaggle Dataset Paths"
      ],
      "metadata": {
        "id": "kaggle_setup_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "KAGGLE_DATASET_PATH = '/kaggle/input/nail-disease-dataset-medsiglip'\n",
        "OUTPUT_PATH = '/kaggle/working/output'\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üìÇ KAGGLE DATASET SETUP\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Check if dataset path exists\n",
        "if not os.path.exists(KAGGLE_DATASET_PATH):\n",
        "    print(f\"\\n‚ùå ERROR: Dataset not found at {KAGGLE_DATASET_PATH}\")\n",
        "    print(\"\\nüìã SOLUTION:\")\n",
        "    print(\"   1. Add 'nail-disease-dataset' as an input to this notebook\")\n",
        "    print(\"   2. Go to notebook settings ‚Üí Add data\")\n",
        "    print(\"   3. Search for 'nail-disease-dataset' and add it\")\n",
        "    print(\"   4. Re-run this cell\")\n",
        "    raise FileNotFoundError(f\"Dataset not found at {KAGGLE_DATASET_PATH}\")\n",
        "\n",
        "print(f\"‚úÖ Dataset path found: {KAGGLE_DATASET_PATH}\")\n",
        "\n",
        "# List available datasets\n",
        "print(f\"\\nüìç Available Kaggle Inputs:\")\n",
        "for item in os.listdir('/kaggle/input'):\n",
        "    print(f\"   ‚Ä¢ {item}\")\n",
        "\n",
        "# Check for train and test directories\n",
        "print(f\"\\nüîç Looking for train/test directories...\")\n",
        "dataset_contents = os.listdir(KAGGLE_DATASET_PATH)\n",
        "print(f\"\\nüìÇ Dataset contents:\")\n",
        "for item in dataset_contents:\n",
        "    item_path = os.path.join(KAGGLE_DATASET_PATH, item)\n",
        "    if os.path.isdir(item_path):\n",
        "        file_count = len([f for f in os.listdir(item_path) if os.path.isfile(os.path.join(item_path, f))])\n",
        "        dir_count = len([d for d in os.listdir(item_path) if os.path.isdir(os.path.join(item_path, d))])\n",
        "        print(f\"   üìÅ {item}/ ({dir_count} subdirs, {file_count} files)\")\n",
        "\n",
        "# Set train and test paths\n",
        "TRAIN_DATA_PATH = os.path.join(KAGGLE_DATASET_PATH, 'train')\n",
        "TEST_DATA_PATH = os.path.join(KAGGLE_DATASET_PATH, 'test')\n",
        "\n",
        "if not os.path.exists(TRAIN_DATA_PATH) or not os.path.exists(TEST_DATA_PATH):\n",
        "    print(f\"\\n‚ùå ERROR: train/ or test/ directories not found!\")\n",
        "    print(f\"   Expected structure:\")\n",
        "    print(f\"   /kaggle/input/nail-disease-dataset/\")\n",
        "    print(f\"   ‚îú‚îÄ‚îÄ train/ (with class folders)\")\n",
        "    print(f\"   ‚îî‚îÄ‚îÄ test/ (with class folders)\")\n",
        "    raise FileNotFoundError(\"train/ or test/ directories not found\")\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset paths configured:\")\n",
        "print(f\"   TRAIN: {TRAIN_DATA_PATH}\")\n",
        "print(f\"   TEST: {TEST_DATA_PATH}\")\n",
        "print(f\"   OUTPUT: {OUTPUT_PATH}\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "kaggle_dataset_setup",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T15:01:47.528884Z",
          "iopub.execute_input": "2026-01-29T15:01:47.529263Z",
          "iopub.status.idle": "2026-01-29T15:01:47.559891Z",
          "shell.execute_reply.started": "2026-01-29T15:01:47.52924Z",
          "shell.execute_reply": "2026-01-29T15:01:47.55926Z"
        },
        "outputId": "481dc926-e6b2-40a2-923a-57b8141d932a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "======================================================================\nüìÇ KAGGLE DATASET SETUP\n======================================================================\n‚úÖ Dataset path found: /kaggle/input/nail-disease-dataset-medsiglip\n\nüìç Available Kaggle Inputs:\n   ‚Ä¢ nail-disease-dataset-medsiglip\n\nüîç Looking for train/test directories...\n\nüìÇ Dataset contents:\n   üìÅ test/ (7 subdirs, 0 files)\n   üìÅ train/ (7 subdirs, 0 files)\n\n‚úÖ Dataset paths configured:\n   TRAIN: /kaggle/input/nail-disease-dataset-medsiglip/train\n   TEST: /kaggle/input/nail-disease-dataset-medsiglip/test\n   OUTPUT: /kaggle/working/output\n======================================================================\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5Ô∏è‚É£ Load & Inspect Dataset"
      ],
      "metadata": {
        "id": "data_loading_section_kaggle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "IMAGE_SIZE = 448\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print(\"üìÇ Loading datasets...\")\n",
        "try:\n",
        "    train_dataset = ImageFolder(TRAIN_DATA_PATH, transform=train_transforms)\n",
        "    test_dataset = ImageFolder(TEST_DATA_PATH, transform=val_transforms)\n",
        "\n",
        "    print(f\"‚úÖ Training samples: {len(train_dataset)}\")\n",
        "    print(f\"‚úÖ Test samples: {len(test_dataset)}\")\n",
        "    print(f\"‚úÖ Number of classes: {len(train_dataset.classes)}\")\n",
        "    print(f\"\\nüìã Class labels: {train_dataset.classes}\")\n",
        "\n",
        "    print(\"\\nüìä Class distribution (Training):\")\n",
        "    for cls_idx, cls_name in enumerate(train_dataset.classes):\n",
        "        count = sum(1 for x, y in train_dataset if y == cls_idx)\n",
        "        print(f\"   {cls_name}: {count} images\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading data: {e}\")\n",
        "    print(f\"\\nüìç Please verify dataset structure:\")\n",
        "    print(f\"   ‚îú‚îÄ‚îÄ train/class1/, class2/, ...\")\n",
        "    print(f\"   ‚îî‚îÄ‚îÄ test/class1/, class2/, ...\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "data_loader_kaggle",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T15:01:47.560816Z",
          "iopub.execute_input": "2026-01-29T15:01:47.561118Z",
          "iopub.status.idle": "2026-01-29T15:09:05.716014Z",
          "shell.execute_reply.started": "2026-01-29T15:01:47.561082Z",
          "shell.execute_reply": "2026-01-29T15:09:05.715066Z"
        },
        "outputId": "2735482b-9b3a-4fd3-cd2e-66f5663a1275"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "üìÇ Loading datasets...\n‚úÖ Training samples: 4086\n‚úÖ Test samples: 182\n‚úÖ Number of classes: 7\n\nüìã Class labels: ['Acral_Lentiginous_Melanoma', 'Healthy_Nail', 'Onychogryphosis', 'blue_finger', 'clubbing', 'pitting', 'psoriasis']\n\nüìä Class distribution (Training):\n   Acral_Lentiginous_Melanoma: 735 images\n   Healthy_Nail: 323 images\n   Onychogryphosis: 677 images\n   blue_finger: 603 images\n   clubbing: 767 images\n   pitting: 639 images\n   psoriasis: 342 images\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6Ô∏è‚É£ Create Data Loaders"
      ],
      "metadata": {
        "id": "dataloader_section_kaggle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Train DataLoader: {len(train_loader)} batches\")\n",
        "print(f\"‚úÖ Test DataLoader: {len(test_loader)} batches\")\n",
        "\n",
        "print(\"\\nüîç Testing batch loading...\")\n",
        "images, labels = next(iter(train_loader))\n",
        "print(f\"   Batch shape: {images.shape}\")\n",
        "print(f\"   Labels: {labels[:5].tolist()}\")\n",
        "print(\"‚úÖ Data loading successful!\")"
      ],
      "metadata": {
        "id": "create_dataloaders_kaggle",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T15:09:05.717365Z",
          "iopub.execute_input": "2026-01-29T15:09:05.71763Z",
          "iopub.status.idle": "2026-01-29T15:09:07.142878Z",
          "shell.execute_reply.started": "2026-01-29T15:09:05.717605Z",
          "shell.execute_reply": "2026-01-29T15:09:07.142121Z"
        },
        "outputId": "32f568b9-cedb-4901-c753-3efea86cc84f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "‚úÖ Train DataLoader: 128 batches\n‚úÖ Test DataLoader: 6 batches\n\nüîç Testing batch loading...\n   Batch shape: torch.Size([32, 3, 448, 448])\n   Labels: [2, 5, 3, 2, 4]\n‚úÖ Data loading successful!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7Ô∏è‚É£ Load MedSigLIP Model"
      ],
      "metadata": {
        "id": "model_loading_section_kaggle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 7: Load MedSigLIP Model & Create Text Prompts\n",
        "from transformers import AutoModel, AutoProcessor\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üñ•Ô∏è  Using device: {device}\")\n",
        "\n",
        "print(\"\\nüì• Loading MedSigLIP model...\")\n",
        "model_id = \"google/medsiglip-448\"\n",
        "\n",
        "try:\n",
        "    model = AutoModel.from_pretrained(\"google/medsiglip-448\")\n",
        "    processor = AutoProcessor.from_pretrained(\"google/medsiglip-448\")\n",
        "\n",
        "    print(\"‚úÖ MedSigLIP model loaded successfully!\")\n",
        "    print(f\"\\nüìä Model info:\")\n",
        "    print(f\"   Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading model: {e}\")\n",
        "    print(f\"\\nüìã Troubleshooting:\")\n",
        "    print(f\"   1. Make sure you logged in with Hugging Face token\")\n",
        "    print(f\"   2. Request access: https://huggingface.co/google/medsiglip-448\")\n",
        "    print(f\"   3. Wait a few minutes for access grant\")\n",
        "    raise\n",
        "\n",
        "# Create text prompts for each class\n",
        "class_prompts = {\n",
        "    0: \"A medical image of acral lentiginous melanoma with black lines under the nail.\",\n",
        "    1: \"A medical image showing blue discoloration of the fingernail bed.\",\n",
        "    2: \"A medical image of nail clubbing with bulging and rounded nail appearance.\",\n",
        "    3: \"A medical image of a healthy normal nail.\",\n",
        "    4: \"A medical image of onychogryphosis with thickened and curved nails.\",\n",
        "    5: \"A medical image of nail pitting with small depressions in the nail plate.\",\n",
        "    6: \"A medical image of psoriatic nails with pitting and discoloration.\"\n",
        "}\n",
        "\n",
        "print(\"\\nüìù Generated text prompts for classes:\")\n",
        "for class_idx, prompt in class_prompts.items():\n",
        "    print(f\"   {class_idx}. {prompt[:60]}...\")"
      ],
      "metadata": {
        "id": "load_medsiglip_kaggle",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T15:29:59.565066Z",
          "iopub.execute_input": "2026-01-29T15:29:59.565695Z",
          "iopub.status.idle": "2026-01-29T15:30:01.297078Z",
          "shell.execute_reply.started": "2026-01-29T15:29:59.565663Z",
          "shell.execute_reply": "2026-01-29T15:30:01.296462Z"
        },
        "outputId": "2f995ca5-7206-41a4-8fe1-47fec48e772a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "üñ•Ô∏è  Using device: cuda\n\nüì• Loading MedSigLIP model...\n‚úÖ MedSigLIP model loaded successfully!\n\nüìä Model info:\n   Total parameters: 878,300,338\n\nüìù Generated text prompts for classes:\n   0. A medical image of acral lentiginous melanoma with black lin...\n   1. A medical image showing blue discoloration of the fingernail...\n   2. A medical image of nail clubbing with bulging and rounded na...\n   3. A medical image of a healthy normal nail....\n   4. A medical image of onychogryphosis with thickened and curved...\n   5. A medical image of nail pitting with small depressions in th...\n   6. A medical image of psoriatic nails with pitting and discolor...\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8Ô∏è‚É£ Add Classification Head"
      ],
      "metadata": {
        "id": "classifier_head_section_kaggle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MedSigLIPClassifier(nn.Module):\n",
        "    def __init__(self, medsiglip_model, num_classes, device='cuda'):\n",
        "        super().__init__()\n",
        "        self.medsiglip = medsiglip_model\n",
        "        self.device = device\n",
        "\n",
        "        embed_dim = 1152\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(embed_dim, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "        for param in self.medsiglip.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, images):\n",
        "        with torch.no_grad():\n",
        "            outputs = self.medsiglip.vision_model(pixel_values=images)\n",
        "            embeddings = outputs.pooler_output\n",
        "\n",
        "        logits = self.classifier(embeddings)\n",
        "        return logits\n",
        "\n",
        "\n",
        "num_classes = len(train_dataset.classes)\n",
        "classifier = MedSigLIPClassifier(\n",
        "    medsiglip_model=model,\n",
        "    num_classes=num_classes,\n",
        "    device=device\n",
        ").to(device)\n",
        "\n",
        "print(f\"‚úÖ Classifier ready! Classes: {num_classes}\")"
      ],
      "metadata": {
        "id": "add_classifier_head_kaggle",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T15:36:29.085681Z",
          "iopub.execute_input": "2026-01-29T15:36:29.085986Z",
          "iopub.status.idle": "2026-01-29T15:36:29.113081Z",
          "shell.execute_reply.started": "2026-01-29T15:36:29.085957Z",
          "shell.execute_reply": "2026-01-29T15:36:29.112358Z"
        },
        "outputId": "9474ad21-44ab-49f4-8816-8c63dc0b68a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "‚úÖ Classifier ready! Classes: 7\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9Ô∏è‚É£ Setup Training Configuration"
      ],
      "metadata": {
        "id": "training_setup_section_kaggle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "LEARNING_RATE = 1e-4\n",
        "WEIGHT_DECAY = 1e-5\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "optimizer = optim.AdamW(\n",
        "    classifier.classifier.parameters(),\n",
        "    lr=LEARNING_RATE,\n",
        "    weight_decay=WEIGHT_DECAY\n",
        ")\n",
        "\n",
        "scheduler = CosineAnnealingLR(\n",
        "    optimizer,\n",
        "    T_max=len(train_loader) * NUM_EPOCHS,\n",
        "    eta_min=1e-7\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Training configuration:\")\n",
        "print(f\"   Epochs: {NUM_EPOCHS}\")\n",
        "print(f\"   Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"   Optimizer: AdamW\")\n",
        "print(f\"   Device: {device}\")"
      ],
      "metadata": {
        "id": "training_setup_kaggle",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T15:36:33.155655Z",
          "iopub.execute_input": "2026-01-29T15:36:33.156406Z",
          "iopub.status.idle": "2026-01-29T15:36:33.162754Z",
          "shell.execute_reply.started": "2026-01-29T15:36:33.156375Z",
          "shell.execute_reply": "2026-01-29T15:36:33.161966Z"
        },
        "outputId": "67dd39c8-cc0d-4fa8-a8ac-baf5303657ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "‚úÖ Training configuration:\n   Epochs: 10\n   Learning Rate: 0.0001\n   Batch Size: 32\n   Optimizer: AdamW\n   Device: cuda\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£0Ô∏è‚É£ Training Functions"
      ],
      "metadata": {
        "id": "training_loop_section_kaggle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, train_loader, criterion, optimizer, scheduler, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=\"Training\")\n",
        "    for images, labels in pbar:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # ‚úÖ FIX: Wrap in f-string\n",
        "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def evaluate(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(test_loader, desc=\"Evaluating\")\n",
        "        for images, labels in pbar:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            # ‚úÖ FIX: Wrap in f-string\n",
        "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "    avg_loss = total_loss / len(test_loader)\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "\n",
        "    return avg_loss, accuracy, precision, recall, f1, all_preds, all_labels\n",
        "\n",
        "print(\"‚úÖ Training functions defined!\")"
      ],
      "metadata": {
        "id": "training_loop_kaggle",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T15:36:38.539251Z",
          "iopub.execute_input": "2026-01-29T15:36:38.539869Z",
          "iopub.status.idle": "2026-01-29T15:36:38.548949Z",
          "shell.execute_reply.started": "2026-01-29T15:36:38.53984Z",
          "shell.execute_reply": "2026-01-29T15:36:38.548306Z"
        },
        "outputId": "49238a8b-87db-467f-e853-cdd5da71a35f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "‚úÖ Training functions defined!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£1Ô∏è‚É£ Run Training"
      ],
      "metadata": {
        "id": "main_training_section_kaggle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = {\n",
        "    'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': [],\n",
        "    'test_precision': [], 'test_recall': [], 'test_f1': []\n",
        "}\n",
        "\n",
        "best_accuracy = 0\n",
        "best_model_path = os.path.join(OUTPUT_PATH, 'best_model.pt')\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üöÄ STARTING TRAINING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"\\nüìä Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "\n",
        "    train_loss, train_acc = train_epoch(classifier, train_loader, criterion, optimizer, scheduler, device)\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "\n",
        "    test_loss, test_acc, test_prec, test_rec, test_f1, preds, labels = evaluate(classifier, test_loader, criterion, device)\n",
        "    history['test_loss'].append(test_loss)\n",
        "    history['test_acc'].append(test_acc)\n",
        "    history['test_precision'].append(test_prec)\n",
        "    history['test_recall'].append(test_rec)\n",
        "    history['test_f1'].append(test_f1)\n",
        "\n",
        "    print(f\"   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "    print(f\"   Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
        "    print(f\"   Precision: {test_prec:.4f} | Recall: {test_rec:.4f} | F1: {test_f1:.4f}\")\n",
        "\n",
        "    if test_acc > best_accuracy:\n",
        "        best_accuracy = test_acc\n",
        "        torch.save(classifier.state_dict(), best_model_path)\n",
        "        print(f\"   ‚≠ê Best model saved! (Accuracy: {best_accuracy:.4f})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ TRAINING COMPLETED\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save training history\n",
        "history_path = os.path.join(OUTPUT_PATH, 'training_history.json')\n",
        "with open(history_path, 'w') as f:\n",
        "    json.dump(history, f, indent=4)\n",
        "print(f\"\\nüíæ Training history saved to: {history_path}\")"
      ],
      "metadata": {
        "id": "main_training_kaggle",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T15:36:42.492572Z",
          "iopub.execute_input": "2026-01-29T15:36:42.492879Z"
        },
        "outputId": "36b2cb9a-412a-43c0-ba76-d0026289c2c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n======================================================================\nüöÄ STARTING TRAINING\n======================================================================\n\nüìä Epoch 1/10\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training:   3%|‚ñé         | 4/128 [00:40<20:58, 10.15s/it, loss=1.9682]",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£2Ô∏è‚É£ Results & Visualization"
      ],
      "metadata": {
        "id": "results_section_kaggle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "classifier.load_state_dict(torch.load(best_model_path))\n",
        "classifier.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = classifier(images)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('MedSigLIP Nail Disease Classification - Kaggle Results', fontsize=16, fontweight='bold')\n",
        "\n",
        "axes[0, 0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
        "axes[0, 0].plot(history['test_loss'], label='Test Loss', marker='s')\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Loss')\n",
        "axes[0, 0].set_title('Loss over Epochs')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[0, 1].plot(history['train_acc'], label='Train Accuracy', marker='o')\n",
        "axes[0, 1].plot(history['test_acc'], label='Test Accuracy', marker='s')\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('Accuracy')\n",
        "axes[0, 1].set_title('Accuracy over Epochs')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1, 0].plot(history['test_precision'], label='Precision', marker='o')\n",
        "axes[1, 0].plot(history['test_recall'], label='Recall', marker='s')\n",
        "axes[1, 0].plot(history['test_f1'], label='F1 Score', marker='^')\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('Score')\n",
        "axes[1, 0].set_title('Precision, Recall, F1 Score')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 1],\n",
        "            xticklabels=train_dataset.classes, yticklabels=train_dataset.classes)\n",
        "axes[1, 1].set_title('Confusion Matrix')\n",
        "axes[1, 1].set_ylabel('True Label')\n",
        "axes[1, 1].set_xlabel('Predicted Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_PATH, 'training_results.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Training results visualization saved!\")\n",
        "print(f\"üìÅ Saved to: {os.path.join(OUTPUT_PATH, 'training_results.png')}\")"
      ],
      "metadata": {
        "id": "results_visualization_kaggle",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T15:09:10.409471Z",
          "iopub.status.idle": "2026-01-29T15:09:10.410187Z",
          "shell.execute_reply.started": "2026-01-29T15:09:10.409964Z",
          "shell.execute_reply": "2026-01-29T15:09:10.409991Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£3Ô∏è‚É£ Summary & Results"
      ],
      "metadata": {
        "id": "summary_section_kaggle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "final_accuracy = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ FINE-TUNING COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nüìä Final Results:\")\n",
        "print(f\"   ‚Ä¢ Final Test Accuracy: {final_accuracy*100:.2f}%\")\n",
        "print(f\"   ‚Ä¢ Best Accuracy: {best_accuracy*100:.2f}%\")\n",
        "print(f\"   ‚Ä¢ Number of Classes: {num_classes}\")\n",
        "print(f\"   ‚Ä¢ Training Epochs: {NUM_EPOCHS}\")\n",
        "\n",
        "print(f\"\\nüìã Per-Class Performance:\")\n",
        "print(classification_report(all_labels, all_preds,\n",
        "                          target_names=train_dataset.classes,\n",
        "                          digits=4))\n",
        "\n",
        "print(f\"\\nüìÅ Output Files (in /kaggle/working/output/):\")\n",
        "output_files = os.listdir(OUTPUT_PATH)\n",
        "for file in sorted(output_files):\n",
        "    file_path = os.path.join(OUTPUT_PATH, file)\n",
        "    file_size = os.path.getsize(file_path) / (1024*1024)\n",
        "    print(f\"   ‚Ä¢ {file} ({file_size:.2f} MB)\")\n",
        "\n",
        "print(f\"\\nüöÄ Next Steps:\")\n",
        "print(f\"   1. ‚úÖ Model is saved in /kaggle/working/output/\")\n",
        "print(f\"   2. üì• Download files via 'Output' tab\")\n",
        "print(f\"   3. üß™ Test on new images\")\n",
        "print(f\"   4. üöÄ Deploy to production\")\n",
        "print(f\"   5. üì¶ Share on Kaggle Models\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üéâ Thank you for using MedSigLIP Fine-tuning on Kaggle!\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "summary_kaggle",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T15:09:10.411889Z",
          "iopub.status.idle": "2026-01-29T15:09:10.412431Z",
          "shell.execute_reply.started": "2026-01-29T15:09:10.41224Z",
          "shell.execute_reply": "2026-01-29T15:09:10.412264Z"
        }
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}