{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nail_disease_title_kaggle"
      },
      "source": [
        "# Nail Disease Classification using MedSigLIP\n",
        "\n",
        "This notebook fine-tunes Google's MedSigLIP model for nail disease classification. I'm working on a mobile app project and needed a classifier that works well with medical images, so I decided to try MedSigLIP since it's specifically trained on medical data.\n",
        "\n",
        "**Dataset**: 7 categories of nail conditions (~6,650 images total)\n",
        "**Goal**: Get at least 90% accuracy on the test set\n",
        "**Strategy**: Fine-tune last 8 layers with aggressive augmentation\n",
        "\n",
        "---\n",
        "\n",
        "## What I'm doing here\n",
        "\n",
        "- Loading nail disease images directly from Kaggle dataset\n",
        "- Fine-tuning MedSigLIP (last 8 transformer blocks)\n",
        "- Using warm-up learning rate + cosine annealing\n",
        "- Training for 10 epochs with gradient accumulation\n",
        "- Tracking overfitting carefully with detailed metrics\n",
        "\n",
        "---\n",
        "\n",
        "## Dataset Structure\n",
        "\n",
        "The dataset should be organized like this:\n",
        "```\n",
        "/kaggle/input/nail-disease-dataset/\n",
        "├── train/ (~5,300 images)\n",
        "│   ├── Acral_Lentiginous_Melanoma/\n",
        "│   ├── blue_finger/\n",
        "│   ├── clubbing/\n",
        "│   ├── Healthy_Nail/\n",
        "│   ├── Onychogryphosis/\n",
        "│   ├── pitting/\n",
        "│   └── psoriasis/\n",
        "└── test/ (~1,350 images)\n",
        "    └── (same structure)\n",
        "```\n",
        "\n",
        "## Classes\n",
        "\n",
        "1. **Acral Lentiginous Melanoma** - Dark pigmentation under nail\n",
        "2. **Blue Finger** - Bluish discoloration\n",
        "3. **Clubbing** - Rounded, bulging nails\n",
        "4. **Healthy Nail** - Normal baseline\n",
        "5. **Onychogryphosis** - Thick, curved nails\n",
        "6. **Pitting** - Small dents in nail surface\n",
        "7. **Psoriasis** - Nail changes from psoriasis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf_login_section"
      },
      "source": [
        "## Step 1: Login to Hugging Face\n",
        "\n",
        "You'll need a Hugging Face token to download MedSigLIP.\n",
        "\n",
        "1. Get your token here: https://huggingface.co/settings/tokens\n",
        "2. Request model access: https://huggingface.co/google/medsiglip-448\n",
        "3. Run the cell below and paste your token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hf_login",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "print(\"Logging into Hugging Face...\")\n",
        "print(\"Get your token from: https://huggingface.co/settings/tokens\\n\")\n",
        "\n",
        "notebook_login()\n",
        "\n",
        "print(\"\\nLogin successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section_kaggle"
      },
      "source": [
        "## Step 2: Install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_dependencies_kaggle",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Installing everything we need\n",
        "!pip install -q torch torchvision transformers datasets pillow scikit-learn matplotlib tqdm numpy pandas\n",
        "!pip install -q open-clip-torch\n",
        "!pip install -q onnx onnxruntime\n",
        "!pip install -q huggingface_hub\n",
        "\n",
        "print(\"All packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpu_check_section_kaggle"
      },
      "source": [
        "## Step 3: Check GPU Availability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_gpu_kaggle",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "\n",
        "print(f\"Python: {sys.version.split()[0]}\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"\\nGPU Available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    print(f\"CUDA: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"WARNING: No GPU found. Training will be slow.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaggle_setup_section"
      },
      "source": [
        "## Step 4: Setup Dataset Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaggle_dataset_setup",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Paths for Kaggle environment\n",
        "KAGGLE_DATASET_PATH = '/kaggle/input/nail-disease-dataset-medsiglip'\n",
        "OUTPUT_PATH = '/kaggle/working/output'\n",
        "\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "print(\"Checking dataset location...\")\n",
        "\n",
        "# Verify dataset exists\n",
        "if not os.path.exists(KAGGLE_DATASET_PATH):\n",
        "    print(f\"ERROR: Dataset not found at {KAGGLE_DATASET_PATH}\")\n",
        "    print(\"\\nMake sure you've added the dataset to this notebook:\")\n",
        "    print(\"1. Go to notebook settings -> Add data\")\n",
        "    print(\"2. Search for 'nail-disease-dataset'\")\n",
        "    print(\"3. Add it and re-run this cell\")\n",
        "    raise FileNotFoundError(f\"Dataset not found\")\n",
        "\n",
        "print(f\"Dataset found: {KAGGLE_DATASET_PATH}\")\n",
        "\n",
        "# List what's in the input folder\n",
        "print(f\"\\nAvailable inputs:\")\n",
        "for item in os.listdir('/kaggle/input'):\n",
        "    print(f\"  - {item}\")\n",
        "\n",
        "# Check dataset structure\n",
        "print(f\"\\nDataset structure:\")\n",
        "for item in os.listdir(KAGGLE_DATASET_PATH):\n",
        "    item_path = os.path.join(KAGGLE_DATASET_PATH, item)\n",
        "    if os.path.isdir(item_path):\n",
        "        subdirs = len([d for d in os.listdir(item_path) if os.path.isdir(os.path.join(item_path, d))])\n",
        "        files = len([f for f in os.listdir(item_path) if os.path.isfile(os.path.join(item_path, f))])\n",
        "        print(f\"  {item}/ - {subdirs} folders, {files} files\")\n",
        "\n",
        "# Set train/test paths\n",
        "TRAIN_DATA_PATH = os.path.join(KAGGLE_DATASET_PATH, 'train')\n",
        "TEST_DATA_PATH = os.path.join(KAGGLE_DATASET_PATH, 'test')\n",
        "\n",
        "if not os.path.exists(TRAIN_DATA_PATH) or not os.path.exists(TEST_DATA_PATH):\n",
        "    print(f\"ERROR: Missing train/ or test/ folders\")\n",
        "    raise FileNotFoundError(\"Dataset structure incorrect\")\n",
        "\n",
        "print(f\"\\nAll paths configured:\")\n",
        "print(f\"  Train: {TRAIN_DATA_PATH}\")\n",
        "print(f\"  Test: {TEST_DATA_PATH}\")\n",
        "print(f\"  Output: {OUTPUT_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_loading_section_kaggle"
      },
      "source": [
        "## Step 5: Load and Explore Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_loader_kaggle",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Config\n",
        "IMAGE_SIZE = 448\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "# Data augmentation for training\n",
        "# Using moderate augmentation since medical images need to stay realistic\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.85, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.3),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1),\n",
        "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.5)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# No augmentation for validation\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print(\"Loading datasets...\")\n",
        "try:\n",
        "    train_dataset = ImageFolder(TRAIN_DATA_PATH, transform=train_transforms)\n",
        "    test_dataset = ImageFolder(TEST_DATA_PATH, transform=val_transforms)\n",
        "\n",
        "    print(f\"Training images: {len(train_dataset)}\")\n",
        "    print(f\"Test images: {len(test_dataset)}\")\n",
        "    print(f\"Classes: {len(train_dataset.classes)}\")\n",
        "    print(f\"\\nClass names: {train_dataset.classes}\")\n",
        "\n",
        "    # Check distribution\n",
        "    print(\"\\nClass distribution:\")\n",
        "    for cls_idx, cls_name in enumerate(train_dataset.classes):\n",
        "        count = sum(1 for x, y in train_dataset if y == cls_idx)\n",
        "        print(f\"  {cls_name}: {count} images\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading data: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dataloader_section_kaggle"
      },
      "source": [
        "## Step 6: Create Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_dataloaders_kaggle",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(f\"Test batches: {len(test_loader)}\")\n",
        "\n",
        "# Quick test\n",
        "images, labels = next(iter(train_loader))\n",
        "print(f\"\\nBatch shape: {images.shape}\")\n",
        "print(f\"Sample labels: {labels[:5].tolist()}\")\n",
        "print(\"Data loading works!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_loading_section_kaggle"
      },
      "source": [
        "## Step 7: Load MedSigLIP Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_medsiglip_kaggle",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoProcessor\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "print(\"\\nDownloading MedSigLIP model...\")\n",
        "model_id = \"google/medsiglip-448\"\n",
        "\n",
        "try:\n",
        "    model = AutoModel.from_pretrained(model_id)\n",
        "    processor = AutoProcessor.from_pretrained(model_id)\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"Model loaded! Total parameters: {total_params:,}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"\\nMake sure you:\")\n",
        "    print(\"1. Logged in with HF token\")\n",
        "    print(\"2. Requested access to google/medsiglip-448\")\n",
        "    print(\"3. Waited for approval (usually instant)\")\n",
        "    raise\n",
        "\n",
        "# Text prompts for each disease class\n",
        "# These help the model understand what it's looking for\n",
        "class_prompts = {\n",
        "    0: \"A medical image of acral lentiginous melanoma with black lines under the nail.\",\n",
        "    1: \"A medical image showing blue discoloration of the fingernail bed.\",\n",
        "    2: \"A medical image of nail clubbing with bulging and rounded nail appearance.\",\n",
        "    3: \"A medical image of a healthy normal nail.\",\n",
        "    4: \"A medical image of onychogryphosis with thickened and curved nails.\",\n",
        "    5: \"A medical image of nail pitting with small depressions in the nail plate.\",\n",
        "    6: \"A medical image of psoriatic nails with pitting and discoloration.\"\n",
        "}\n",
        "\n",
        "print(\"\\nText prompts ready for all classes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "classifier_head_section_kaggle"
      },
      "source": [
        "## Step 8: Build Classification Head\n",
        "\n",
        "I'm unfreezing the last 8 transformer blocks to let the model adapt to nail images better. The classifier head has dropout at multiple stages to prevent overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "add_classifier_head_kaggle",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class MedSigLIPClassifier(nn.Module):\n",
        "    def __init__(self, medsiglip_model, num_classes, device='cuda'):\n",
        "        super().__init__()\n",
        "        self.medsiglip = medsiglip_model\n",
        "        self.device = device\n",
        "\n",
        "        embed_dim = 1152  # MedSigLIP embedding size\n",
        "\n",
        "        # Multi-layer classifier with batch norm and dropout\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(embed_dim, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            \n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.35),\n",
        "            \n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            \n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            \n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "        # Freeze most of the vision model\n",
        "        for param in self.medsiglip.vision_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Unfreeze last 8 layers\n",
        "        if hasattr(self.medsiglip.vision_model, 'encoder'):\n",
        "            for param in self.medsiglip.vision_model.encoder.layers[-8:].parameters():\n",
        "                param.requires_grad = True\n",
        "                \n",
        "        # Also unfreeze the layer norm\n",
        "        if hasattr(self.medsiglip.vision_model, 'layer_norm'):\n",
        "            for param in self.medsiglip.vision_model.layer_norm.parameters():\n",
        "                param.requires_grad = True\n",
        "\n",
        "    def forward(self, images):\n",
        "        outputs = self.medsiglip.vision_model(pixel_values=images)\n",
        "        embeddings = outputs.pooler_output\n",
        "        logits = self.classifier(embeddings)\n",
        "        return logits\n",
        "\n",
        "\n",
        "num_classes = len(train_dataset.classes)\n",
        "classifier = MedSigLIPClassifier(\n",
        "    medsiglip_model=model,\n",
        "    num_classes=num_classes,\n",
        "    device=device\n",
        ").to(device)\n",
        "\n",
        "print(f\"Classifier built for {num_classes} classes\")\n",
        "print(f\"Architecture: 1152 -> 1024 -> 512 -> 256 -> 128 -> {num_classes}\")\n",
        "print(\"Last 8 vision layers unfrozen for fine-tuning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_setup_section_kaggle"
      },
      "source": [
        "## Step 9: Training Configuration\n",
        "\n",
        "Using AdamW with different learning rates for the classifier vs the vision model. The vision model gets a lower LR since it's already pretrained. I'm also using warmup to prevent early instability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "training_setup_kaggle",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "# Hyperparameters\n",
        "NUM_EPOCHS = 10\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY = 5e-4\n",
        "WARMUP_EPOCHS = 2\n",
        "GRADIENT_ACCUMULATION_STEPS = 2\n",
        "\n",
        "# Loss with label smoothing to prevent overconfidence\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.15)\n",
        "\n",
        "# Get unfrozen parameters from vision model\n",
        "unfrozen_params = [p for p in classifier.medsiglip.vision_model.encoder.layers[-8:].parameters() if p.requires_grad]\n",
        "if hasattr(classifier.medsiglip.vision_model, 'layer_norm'):\n",
        "    unfrozen_params.extend([p for p in classifier.medsiglip.vision_model.layer_norm.parameters() if p.requires_grad])\n",
        "\n",
        "classifier_params = list(classifier.classifier.parameters())\n",
        "\n",
        "# Different learning rates for different parts\n",
        "param_groups = [\n",
        "    {'params': classifier_params, 'lr': LEARNING_RATE},\n",
        "    {'params': unfrozen_params, 'lr': LEARNING_RATE * 0.1}  # Vision model needs lower LR\n",
        "]\n",
        "\n",
        "optimizer = optim.AdamW(param_groups, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS - WARMUP_EPOCHS, eta_min=1e-5)\n",
        "\n",
        "print(\"Training config:\")\n",
        "print(f\"  Epochs: {NUM_EPOCHS}\")\n",
        "print(f\"  Classifier LR: {LEARNING_RATE}\")\n",
        "print(f\"  Vision LR: {LEARNING_RATE * 0.1}\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  Warmup: {WARMUP_EPOCHS} epochs\")\n",
        "print(f\"  Gradient accumulation: {GRADIENT_ACCUMULATION_STEPS} steps\")\n",
        "print(f\"  Weight decay: {WEIGHT_DECAY}\")\n",
        "print(f\"  Label smoothing: 0.15\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_loop_section_kaggle"
      },
      "source": [
        "## Step 10: Training Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "training_loop_kaggle",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def train_epoch(model, train_loader, criterion, optimizer, device, accumulation_steps=1):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=\"Training\")\n",
        "    for step, (images, labels) in enumerate(pbar):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Scale loss for gradient accumulation\n",
        "        loss = loss / accumulation_steps\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights every N steps\n",
        "        if (step + 1) % accumulation_steps == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.classifier.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item() * accumulation_steps\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().detach().numpy())\n",
        "        all_labels.extend(labels.cpu().detach().numpy())\n",
        "\n",
        "        pbar.set_postfix({'loss': f'{loss.item()*accumulation_steps:.4f}'})\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def evaluate(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(test_loader, desc=\"Evaluating\")\n",
        "        for images, labels in pbar:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "    avg_loss = total_loss / len(test_loader)\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    return avg_loss, accuracy, precision, recall, f1, all_preds, all_labels\n",
        "\n",
        "print(\"Training functions ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "main_training_section_kaggle"
      },
      "source": [
        "## Step 11: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "main_training_kaggle",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "history = {\n",
        "    'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': [],\n",
        "    'test_precision': [], 'test_recall': [], 'test_f1': [], 'learning_rate': []\n",
        "}\n",
        "\n",
        "best_accuracy = 0\n",
        "best_epoch = 0\n",
        "patience_counter = 0\n",
        "max_patience = 5\n",
        "best_model_path = os.path.join(OUTPUT_PATH, 'best_model.pt')\n",
        "\n",
        "print(\"Starting training...\")\n",
        "print(\"="*50)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "\n",
        "    # Warmup schedule for first 2 epochs\n",
        "    if epoch < WARMUP_EPOCHS:\n",
        "        warmup_lr = LEARNING_RATE * (epoch + 1) / WARMUP_EPOCHS\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = warmup_lr * (1 if param_group['lr'] >= LEARNING_RATE * 0.5 else 0.1)\n",
        "        print(f\"Warmup LR: {warmup_lr:.6f}\")\n",
        "\n",
        "    train_loss, train_acc = train_epoch(classifier, train_loader, criterion, optimizer, device, GRADIENT_ACCUMULATION_STEPS)\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['learning_rate'].append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    test_loss, test_acc, test_prec, test_rec, test_f1, preds, labels = evaluate(classifier, test_loader, criterion, device)\n",
        "    history['test_loss'].append(test_loss)\n",
        "    history['test_acc'].append(test_acc)\n",
        "    history['test_precision'].append(test_prec)\n",
        "    history['test_recall'].append(test_rec)\n",
        "    history['test_f1'].append(test_f1)\n",
        "\n",
        "    print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
        "    print(f\"Test - Loss: {test_loss:.4f}, Acc: {test_acc:.4f}\")\n",
        "    print(f\"Metrics - Precision: {test_prec:.4f}, Recall: {test_rec:.4f}, F1: {test_f1:.4f}\")\n",
        "\n",
        "    # Step scheduler after warmup\n",
        "    if epoch >= WARMUP_EPOCHS:\n",
        "        scheduler.step()\n",
        "\n",
        "    # Save best model\n",
        "    if test_acc > best_accuracy:\n",
        "        best_accuracy = test_acc\n",
        "        best_epoch = epoch + 1\n",
        "        torch.save(classifier.state_dict(), best_model_path)\n",
        "        patience_counter = 0\n",
        "        print(f\"New best! Saved model (Acc: {best_accuracy:.4f})\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= max_patience:\n",
        "            print(f\"No improvement for {max_patience} epochs\")\n",
        "\n",
        "print(\"\\n" + "="*50)\n",
        "print(\"Training complete!\")\n",
        "print(f\"Best accuracy: {best_accuracy:.4f} at epoch {best_epoch}\")\n",
        "\n",
        "# Save history\n",
        "history_path = os.path.join(OUTPUT_PATH, 'training_history.json')\n",
        "with open(history_path, 'w') as f:\n",
        "    json.dump(history, f, indent=4)\n",
        "print(f\"Saved history to {history_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "results_section_kaggle"
      },
      "source": [
        "## Step 12: Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "results_visualization_kaggle",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Load best model\n",
        "classifier.load_state_dict(torch.load(best_model_path))\n",
        "classifier.eval()\n",
        "\n",
        "# Get predictions\n",
        "with torch.no_grad():\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = classifier(images)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Create plots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('Training Results - MedSigLIP Nail Disease Classifier', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Loss plot\n",
        "axes[0, 0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
        "axes[0, 0].plot(history['test_loss'], label='Test Loss', marker='s')\n",
        "axes[0, 0].axvline(x=best_epoch-1, color='red', linestyle='--', alpha=0.7, label=f'Best at epoch {best_epoch}')\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Loss')\n",
        "axes[0, 0].set_title('Training & Test Loss')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy plot\n",
        "axes[0, 1].plot(history['train_acc'], label='Train Accuracy', marker='o')\n",
        "axes[0, 1].plot(history['test_acc'], label='Test Accuracy', marker='s')\n",
        "axes[0, 1].axvline(x=best_epoch-1, color='red', linestyle='--', alpha=0.7, label=f'Best at epoch {best_epoch}')\n",
        "axes[0, 1].axhline(y=0.9, color='green', linestyle=':', alpha=0.5, label='90% goal')\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('Accuracy')\n",
        "axes[0, 1].set_title('Training & Test Accuracy')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Metrics plot\n",
        "axes[1, 0].plot(history['test_precision'], label='Precision', marker='o')\n",
        "axes[1, 0].plot(history['test_recall'], label='Recall', marker='s')\n",
        "axes[1, 0].plot(history['test_f1'], label='F1 Score', marker='^')\n",
        "axes[1, 0].axhline(y=0.9, color='green', linestyle=':', alpha=0.5, label='90% goal')\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('Score')\n",
        "axes[1, 0].set_title('Test Metrics')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 1],\n",
        "            xticklabels=train_dataset.classes, yticklabels=train_dataset.classes)\n",
        "axes[1, 1].set_title('Confusion Matrix')\n",
        "axes[1, 1].set_ylabel('True Label')\n",
        "axes[1, 1].set_xlabel('Predicted Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_PATH, 'training_results.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved visualization to training_results.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "overfitting_analysis_section"
      },
      "source": [
        "## Step 12A: Overfitting Analysis\n",
        "\n",
        "Checking how much the model is overfitting by comparing train vs test metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "overfitting_analysis_kaggle",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Calculate gaps between train and test\n",
        "train_losses = np.array(history['train_loss'])\n",
        "test_losses = np.array(history['test_loss'])\n",
        "train_accs = np.array(history['train_acc'])\n",
        "test_accs = np.array(history['test_acc'])\n",
        "\n",
        "loss_gap = test_losses - train_losses\n",
        "acc_gap = train_accs - test_accs\n",
        "overfitting_coeff = acc_gap / (train_accs + 1e-6)\n",
        "\n",
        "# Build metrics table\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Epoch': np.arange(1, NUM_EPOCHS + 1),\n",
        "    'Train_Loss': train_losses,\n",
        "    'Test_Loss': test_losses,\n",
        "    'Loss_Gap': loss_gap,\n",
        "    'Train_Acc': train_accs,\n",
        "    'Test_Acc': test_accs,\n",
        "    'Acc_Gap': acc_gap,\n",
        "    'Overfit_Coeff': overfitting_coeff,\n",
        "    'Precision': history['test_precision'],\n",
        "    'Recall': history['test_recall'],\n",
        "    'F1': history['test_f1'],\n",
        "    'LR': history['learning_rate']\n",
        "})\n",
        "\n",
        "print(\"Overfitting Analysis\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nPer-epoch metrics:\")\n",
        "print(metrics_df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\\nSummary:\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"Average loss gap: {loss_gap.mean():.4f}\")\n",
        "print(f\"Max loss gap: {loss_gap.max():.4f} (Epoch {loss_gap.argmax() + 1})\")\n",
        "print(f\"Average accuracy gap: {acc_gap.mean():.4f}\")\n",
        "print(f\"Final accuracy gap: {acc_gap[-1]:.4f}\")\n",
        "\n",
        "# Interpret overfitting level\n",
        "avg_coeff = overfitting_coeff.mean()\n",
        "print(f\"\\nOverfitting coefficient: {avg_coeff:.4f}\")\n",
        "if avg_coeff < 0.05:\n",
        "    print(\"Level: Minimal (excellent!)\")\n",
        "elif avg_coeff < 0.15:\n",
        "    print(\"Level: Mild (good)\")\n",
        "elif avg_coeff < 0.30:\n",
        "    print(\"Level: Moderate (acceptable)\")\n",
        "else:\n",
        "    print(\"Level: Severe (needs attention)\")\n",
        "\n",
        "print(f\"\\nFinal performance:\")\n",
        "print(f\"Train accuracy: {train_accs[-1]:.4f}\")\n",
        "print(f\"Test accuracy: {test_accs[-1]:.4f}\")\n",
        "print(f\"Best test accuracy: {test_accs.max():.4f} (Epoch {test_accs.argmax() + 1})\")\n",
        "\n",
        "# Save detailed metrics\n",
        "csv_path = os.path.join(OUTPUT_PATH, 'overfitting_metrics.csv')\n",
        "metrics_df.to_csv(csv_path, index=False)\n",
        "print(f\"\\nSaved detailed metrics to {csv_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "overfitting_viz_section"
      },
      "source": [
        "## Step 12B: Overfitting Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "overfitting_viz_kaggle",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Create detailed overfitting plots\n",
        "fig = plt.figure(figsize=(18, 12))\n",
        "gs = fig.add_gridspec(3, 3, hspace=0.35, wspace=0.3)\n",
        "\n",
        "fig.suptitle('Overfitting Analysis', fontsize=18, fontweight='bold', y=0.995)\n",
        "\n",
        "epochs = np.arange(1, NUM_EPOCHS + 1)\n",
        "\n",
        "# Loss gap\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "colors = ['red' if gap > loss_gap.mean() else 'green' for gap in loss_gap]\n",
        "ax1.bar(epochs, loss_gap, color=colors, alpha=0.7)\n",
        "ax1.axhline(y=loss_gap.mean(), color='red', linestyle='--', linewidth=2, label=f'Avg: {loss_gap.mean():.4f}')\n",
        "ax1.set_xlabel('Epoch', fontweight='bold')\n",
        "ax1.set_ylabel('Loss Gap', fontweight='bold')\n",
        "ax1.set_title('Loss Gap Per Epoch\\n(Higher = More Overfitting)', fontweight='bold')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy gap\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "ax2.bar(epochs, acc_gap, color='coral', alpha=0.7)\n",
        "ax2.axhline(y=acc_gap.mean(), color='darkred', linestyle='--', linewidth=2, label=f'Avg: {acc_gap.mean():.4f}')\n",
        "ax2.set_xlabel('Epoch', fontweight='bold')\n",
        "ax2.set_ylabel('Accuracy Gap', fontweight='bold')\n",
        "ax2.set_title('Accuracy Gap Per Epoch\\n(Lower = Better)', fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Overfitting coefficient\n",
        "ax3 = fig.add_subplot(gs[0, 2])\n",
        "ax3.plot(epochs, overfitting_coeff, marker='o', linewidth=2, markersize=8, color='purple')\n",
        "ax3.axhline(y=0.05, color='green', linestyle=':', linewidth=2, alpha=0.5, label='Minimal (0.05)')\n",
        "ax3.axhline(y=0.15, color='orange', linestyle=':', linewidth=2, alpha=0.5, label='Moderate (0.15)')\n",
        "ax3.set_xlabel('Epoch', fontweight='bold')\n",
        "ax3.set_ylabel('Coefficient', fontweight='bold')\n",
        "ax3.set_title('Overfitting Coefficient', fontweight='bold')\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Train vs test loss with gap shading\n",
        "ax4 = fig.add_subplot(gs[1, 0])\n",
        "ax4.plot(epochs, train_losses, marker='o', label='Train', linewidth=2.5, markersize=6)\n",
        "ax4.plot(epochs, test_losses, marker='s', label='Test', linewidth=2.5, markersize=6)\n",
        "ax4.fill_between(epochs, train_losses, test_losses, alpha=0.2, color='red', label='Gap')\n",
        "ax4.set_xlabel('Epoch', fontweight='bold')\n",
        "ax4.set_ylabel('Loss', fontweight='bold')\n",
        "ax4.set_title('Train vs Test Loss', fontweight='bold')\n",
        "ax4.legend()\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "# Train vs test accuracy\n",
        "ax5 = fig.add_subplot(gs[1, 1])\n",
        "ax5.plot(epochs, train_accs, marker='o', label='Train', linewidth=2.5, markersize=6, color='green')\n",
        "ax5.plot(epochs, test_accs, marker='s', label='Test', linewidth=2.5, markersize=6, color='blue')\n",
        "ax5.fill_between(epochs, train_accs, test_accs, alpha=0.2, color='red')\n",
        "ax5.axhline(y=0.9, color='green', linestyle=':', alpha=0.5, label='90% goal')\n",
        "ax5.set_xlabel('Epoch', fontweight='bold')\n",
        "ax5.set_ylabel('Accuracy', fontweight='bold')\n",
        "ax5.set_title('Train vs Test Accuracy', fontweight='bold')\n",
        "ax5.legend()\n",
        "ax5.grid(True, alpha=0.3)\n",
        "\n",
        "# Learning rate schedule\n",
        "ax6 = fig.add_subplot(gs[1, 2])\n",
        "ax6.plot(epochs, history['learning_rate'], marker='o', linewidth=2.5, markersize=6, color='purple')\n",
        "ax6.set_xlabel('Epoch', fontweight='bold')\n",
        "ax6.set_ylabel('Learning Rate', fontweight='bold')\n",
        "ax6.set_title('LR Schedule', fontweight='bold')\n",
        "ax6.grid(True, alpha=0.3)\n",
        "ax6.set_yscale('log')\n",
        "\n",
        "# Metrics heatmap\n",
        "ax7 = fig.add_subplot(gs[2, :])\n",
        "heatmap_data = np.array([\n",
        "    train_losses / train_losses.max(),\n",
        "    test_losses / test_losses.max(),\n",
        "    train_accs,\n",
        "    test_accs,\n",
        "    history['test_precision'],\n",
        "    history['test_recall'],\n",
        "    history['test_f1']\n",
        "])\n",
        "im = ax7.imshow(heatmap_data, cmap='RdYlGn', aspect='auto')\n",
        "ax7.set_yticks(range(7))\n",
        "ax7.set_yticklabels(['Train Loss (norm)', 'Test Loss (norm)', 'Train Acc', 'Test Acc', 'Precision', 'Recall', 'F1'])\n",
        "ax7.set_xticks(range(NUM_EPOCHS))\n",
        "ax7.set_xticklabels(epochs)\n",
        "ax7.set_xlabel('Epoch', fontweight='bold')\n",
        "ax7.set_title('All Metrics Heatmap (Green=Good, Red=Bad)', fontweight='bold')\n",
        "plt.colorbar(im, ax=ax7, label='Value')\n",
        "\n",
        "plt.savefig(os.path.join(OUTPUT_PATH, 'overfitting_analysis.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved overfitting analysis to overfitting_analysis.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary_section_kaggle"
      },
      "source": [
        "## Step 13: Final Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "summary_kaggle",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "final_accuracy = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "print(\"\\n" + "="*70)\n",
        "print(\"Training Complete!\")\n",
        "print(\"="*70)\n",
        "\n",
        "print(f\"\\nFinal Results:\")\n",
        "print(f\"  Test Accuracy: {final_accuracy*100:.2f}%\")\n",
        "print(f\"  Best Accuracy: {best_accuracy*100:.2f}% (Epoch {best_epoch})\")\n",
        "print(f\"  Classes: {num_classes}\")\n",
        "print(f\"  Epochs: {NUM_EPOCHS}\")\n",
        "\n",
        "if best_accuracy >= 0.9:\n",
        "    print(\"  Goal achieved: YES (>=90%)\")\n",
        "elif best_accuracy >= 0.85:\n",
        "    print(\"  Close to goal (>=85%)\")\n",
        "else:\n",
        "    print(\"  Needs more training\")\n",
        "\n",
        "print(f\"\\nPer-class metrics:\")\n",
        "print(classification_report(all_labels, all_preds,\n",
        "                          target_names=train_dataset.classes,\n",
        "                          digits=4))\n",
        "\n",
        "print(f\"\\nOutput files (in {OUTPUT_PATH}):\")\n",
        "for file in sorted(os.listdir(OUTPUT_PATH)):\n",
        "    file_path = os.path.join(OUTPUT_PATH, file)\n",
        "    file_size = os.path.getsize(file_path) / (1024*1024)\n",
        "    print(f\"  {file} ({file_size:.2f} MB)\")\n",
        "\n",
        "print(f\"\\nNext steps:\")\n",
        "print(\"  1. Download model from Output tab\")\n",
        "print(\"  2. Review overfitting metrics CSV\")\n",
        "print(\"  3. Check visualization PNGs\")\n",
        "print(\"  4. Test on new nail images\")\n",
        "print(\"  5. Deploy to mobile app\")\n",
        "\n",
        "if best_accuracy < 0.90:\n",
        "    print(f\"\\nTips to improve:\")\n",
        "    print(\"  - Train for more epochs\")\n",
        "    print(\"  - Unfreeze more layers\")\n",
        "    print(\"  - Try different augmentations\")\n",
        "    print(\"  - Check for class imbalance\")\n",
        "    print(\"  - Verify data quality\")\n",
        "\n",
        "print(\"\\n" + "="*70)\n",
        "print(\"Thanks for using this notebook!\")\n",
        "print(\"="*70)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "notebookc4efb879ae",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 9371763,
          "sourceId": 14669652,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31260,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}