# ğŸ¯ MedGemma Fine-Tuning Branch

## ğŸ“‹ Branch Overview

This branch (`medgemma-finetuning`) contains everything you need to fine-tune Google's **MedGemma** model on your 10,000-row nail disease dataset.

### ğŸ† What's Included

```
medgemma-finetuning/
â”œâ”€â”€ fine_tune_with_hugging_face-1.ipynb  â¬…ï¸ Your training notebook
â”œâ”€â”€ nail_diseases.csv                   â¬…ï¸ Your 10,000 samples
â”œâ”€â”€ README.md                           â¬…ï¸ Main documentation
â”œâ”€â”€ SETUP_GUIDE.md                      â¬…ï¸ Step-by-step setup
â”œâ”€â”€ requirements.txt                    â¬…ï¸ Python dependencies
â”œâ”€â”€ .gitignore                          â¬…ï¸ Git configuration
â””â”€â”€ BRANCH_INFO.md                      â¬…ï¸ This file
```

---

## âš¡ Quick Start (Choose One)

### ğŸ”µ **Option 1: Google Colab** (RECOMMENDED)

**Time**: 1-2 hours | **Cost**: Free | **Difficulty**: Easy

```bash
1. Download: fine_tune_with_hugging_face-1.ipynb
2. Open: https://colab.research.google.com/
3. Upload notebook
4. Upload nail_diseases.csv to Google Drive
5. Update CSV path in Cell 5
6. Run all cells (Ctrl+F9)
7. Download results
```

**GPU**: T4 (12GB VRAM)

### ğŸŸ£ **Option 2: Kaggle**

**Time**: 30 mins - 1 hour | **Cost**: Free | **Difficulty**: Medium

```bash
1. Create Kaggle dataset from nail_diseases.csv
2. Create new Kaggle Notebook
3. Copy fine_tune_with_hugging_face-1.ipynb content
4. Enable GPU in Settings
5. Update CSV path in Cell 5
6. Run all cells
7. Download results
```

**GPU**: P100 or T4 (40GB VRAM - faster!)

### ğŸ’» **Option 3: Local Machine**

**Time**: 1-3 hours | **Cost**: Your GPU | **Difficulty**: Hard

```bash
# Clone and setup
git clone https://github.com/isumenuka/medsiglip-nail-disease-finetuning
cd medsiglip-nail-disease-finetuning
git checkout medgemma-finetuning

# Install dependencies
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Run notebook
jupyter notebook fine_tune_with_hugging_face-1.ipynb

# Update CSV path and run all cells
```

**GPU**: Your NVIDIA GPU (8GB+ VRAM)

---

## ğŸ“‚ Key Files

### **fine_tune_with_hugging_face-1.ipynb**

ğŸ€ **Your Training Notebook** (19 cells)

| Cell | Purpose | Time |
|------|---------|------|
| 1-4 | Setup & GPU check | 5 min |
| 5-7 | Load & prepare data | 2 min |
| 8-12 | Load model & config | 5 min |
| **13** | **ğŸš€ TRAIN MODEL** | **30 min - 2 hrs** |
| 14-19 | Evaluate & save | 15 min |

### **nail_diseases.csv**

ğŸ **Your Data** (10,000 rows)

- 15 clinical columns
- 7 disease categories
- Ready to use!

### **README.md**

ğŸ“– **Main Documentation**

- Overview & features
- Dataset structure
- Notebook guide
- Configuration options
- References

### **SETUP_GUIDE.md**

ğŸœ **Step-by-Step Setup**

- Colab setup (5 steps)
- Kaggle setup (6 steps)
- Local setup (6 steps)
- Troubleshooting
- Performance tips

### **requirements.txt**

ğŸ“„ **Python Packages**

```bash
pip install -r requirements.txt
```

Includes:
- PyTorch, Transformers
- PEFT, TRL (fine-tuning)
- pandas, scikit-learn
- TensorBoard

---

## ğŸ Getting Started

### Step 1: Choose Your Environment

- ğŸ”µ **Colab**: Easiest, start here if unsure
- ğŸŸ£ **Kaggle**: Better GPU, faster training
- ğŸ’» **Local**: Full control, own GPU

### Step 2: Read Setup Guide

Open `SETUP_GUIDE.md` for your chosen environment

### Step 3: Prepare Files

- Download notebook
- Prepare CSV file
- Have GPU ready

### Step 4: Run Notebook

- Follow cells 1-19 in order
- Monitor training (Cell 13)
- Download results

### Step 5: Use Trained Model

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

# Load fine-tuned model
model = AutoModelForCausalLM.from_pretrained('./medgemma_nails_finetuned')
tokenizer = AutoTokenizer.from_pretrained('./medgemma_nails_finetuned')

# Use for inference
inputs = tokenizer("Clinical findings: ...", return_tensors="pt")
outputs = model.generate(**inputs)
```

---

## ğŸ“ˆ Expected Results

### Training Metrics

```
Training Loss:  4.5 â†’ 0.08 âœ…
Validation Loss: 0.032 â†’ 0.020 âœ…
Accuracy: ~85-92% âœ…
```

### Output Files

```
medgemma_nails_finetuned/
â”œâ”€â”€ adapter_model.bin (50-100 MB) âœ…
â”œâ”€â”€ adapter_config.json âœ…
â””â”€â”€ tokenizer files âœ…

logs/events.out.tfevents.* (TensorBoard logs)
training_summary.json (metadata)
```

### Time Estimates

| Environment | GPU | Time |
|-------------|-----|------|
| Colab | T4 | 1-2 hours |
| Kaggle | P100 | 30 min - 1 hour |
| Kaggle | T4 | 1-2 hours |
| Local | RTX 3090 | 15-30 min |
| Local | RTX 4090 | 10-20 min |

---

## âš ï¸ Common Issues

### âŒ "CUDA out of memory"

**Fix**: In Cell 11, reduce batch size:
```python
per_device_train_batch_size = 2  # instead of 4
```

### âŒ "CSV not found"

**Fix**: Update path in Cell 5 for your environment

### âŒ "Model not loading"

**Fix**: Authenticate with Hugging Face:
```python
from huggingface_hub import login
login()
```

### âŒ "GPU not detected"

**Fix**:
- Colab: Enable GPU in Runtime menu
- Kaggle: Enable GPU in Settings
- Local: Install CUDA toolkit

â†’ See `SETUP_GUIDE.md` for detailed troubleshooting

---

## ğŸ“š Resources

### In This Branch
- ğŸ“– [README.md](README.md) - Main documentation
- ğŸœ [SETUP_GUIDE.md](SETUP_GUIDE.md) - Setup instructions
- ğŸ“‹ [fine_tune_with_hugging_face-1.ipynb](fine_tune_with_hugging_face-1.ipynb) - Training notebook

### External Resources
- [MedGemma Docs](https://developers.google.com/health-ai)
- [Hugging Face](https://huggingface.co/docs/transformers)
- [LoRA Paper](https://arxiv.org/abs/2106.09685)
- [TRL Library](https://github.com/huggingface/trl)

---

## ğŸ‘€ What's Next?

### Immediate (Next 5 minutes)
- [ ] Review this file
- [ ] Choose your environment
- [ ] Read SETUP_GUIDE.md

### Today (Next 1-3 hours)
- [ ] Download notebook & CSV
- [ ] Follow setup steps
- [ ] Start training
- [ ] Download results

### This Week
- [ ] Test inference on new cases
- [ ] Evaluate model performance
- [ ] Deploy to production
- [ ] Share results

---

## ğŸ™‹ Support

**Have questions?**

1. ğŸœ Check `SETUP_GUIDE.md` first
2. ğŸ“– See `README.md` for details
3. ğŸ“€ Open GitHub issue
4. ğŸ¤” Check notebook comments

---

## âœ… Branch Status

- **Status**: âœ… Ready to Use
- **Created**: January 30, 2026
- **Updated**: 9:59 PM IST
- **Model**: MedGemma 4B/27B
- **Data**: 10,000 nail disease samples
- **License**: HAI-DEF + MIT

---

## ğŸš€ Ready?

ğŸ‘‰ **Start with**: [SETUP_GUIDE.md](SETUP_GUIDE.md)

---

**Let's train MedGemma! ğŸ‘**
